{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3745307-e926-4218-a6fc-9c12175805ac",
   "metadata": {},
   "source": [
    "## 1. 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53b81a4-2477-4262-8006-8e6e80dde05f",
   "metadata": {},
   "source": [
    "runpod에서 a100 GPU 1개 sxm 대여해주시고 container disk는 50기가 바이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63702f92-6c10-4a90-9cb9-e3e950bfccc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==2.4.0 in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (4.14.1)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0) (12.9.86)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.0) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.0) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers==4.45.1 in /usr/local/lib/python3.10/dist-packages (4.45.1)\n",
      "Requirement already satisfied: datasets==3.0.1 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
      "Requirement already satisfied: accelerate==0.34.2 in /usr/local/lib/python3.10/dist-packages (0.34.2)\n",
      "Requirement already satisfied: trl==0.11.1 in /usr/local/lib/python3.10/dist-packages (0.11.1)\n",
      "Requirement already satisfied: peft==0.13.0 in /usr/local/lib/python3.10/dist-packages (0.13.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.1) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.1) (0.34.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.1) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.1) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.1) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.1) (2025.7.34)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.1) (2.32.4)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.1) (0.5.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.1) (0.20.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.1) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==3.0.1) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets==3.0.1) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==3.0.1) (2.3.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets==3.0.1) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets==3.0.1) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets==3.0.1) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==3.0.1) (3.12.15)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.34.2) (5.9.6)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.34.2) (2.4.0)\n",
      "Requirement already satisfied: tyro>=0.5.11 in /usr/local/lib/python3.10/dist-packages (from trl==0.11.1) (0.9.27)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.0.1) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.0.1) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.0.1) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.0.1) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.0.1) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.0.1) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.0.1) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.0.1) (1.20.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.1) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.1) (1.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.1) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.1) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.1) (2022.12.7)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.34.2) (12.9.86)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl==0.11.1) (0.17.0)\n",
      "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl==0.11.1) (14.1.0)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl==0.11.1) (1.7.2)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl==0.11.1) (4.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==3.0.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==3.0.1) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==3.0.1) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==3.0.1) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.11.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.11.1) (2.16.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.34.2) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate==0.34.2) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.11.1) (0.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install \"torch==2.4.0\"\n",
    "%pip install \"transformers==4.45.1\" \"datasets==3.0.1\" \"accelerate==0.34.2\" \"trl==0.11.1\" \"peft==0.13.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98eaf62e-8aee-4331-803e-20d92e6cf689",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import LoraConfig\n",
    "from trl import SFTConfig, SFTTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00e07c5-04d3-48fb-8a30-2113838c4384",
   "metadata": {},
   "source": [
    "빠른 학습을 위해 학습 데이터와 테스트 데이터를 2:8 비율로 분할합니다. 이 값을 변경하고자 하는 분은 test_ratio의 값을 변경하세요.\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "623cc097-4d59-4927-aa5d-d3ebd4e8d582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 데이터 수: 4599\n",
      "학습 데이터 수: 3219 (70.0%)\n",
      "테스트 데이터 수: 1380 (30.0%)\n"
     ]
    }
   ],
   "source": [
    "# 1. 허깅페이스 허브에서 데이터셋 로드\n",
    "from datasets import load_dataset\n",
    "import random\n",
    "\n",
    "dataset = load_dataset(\"iamjoon/esg-survey-reasoning_datasets\", split=\"train\")\n",
    "\n",
    "# 2. OpenAI format으로 데이터 변환을 위한 함수 \n",
    "def format_data(sample):\n",
    "    # OpenAI format으로 변환\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": sample['reasoning_system_prompt'],\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": sample[\"user_prompt\"],\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": sample[\"reasoning_assistant\"].replace('\\n\\n답변:', '\\n답변:')\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    "\n",
    "# 3. 전체 데이터에 OpenAI 포맷 전처리 적용\n",
    "formatted_dataset = dataset.map(format_data)\n",
    "\n",
    "# 4. 데이터를 7:2 비율로 학습/테스트 분할 (HuggingFace 내장 메서드 사용)\n",
    "split_dataset = formatted_dataset.train_test_split(test_size=0.3, seed=42)\n",
    "train_dataset = split_dataset['train']\n",
    "test_dataset = split_dataset['test']\n",
    "\n",
    "# 5. 결과 확인\n",
    "print(f\"전체 데이터 수: {len(formatted_dataset)}\")\n",
    "print(f\"학습 데이터 수: {len(train_dataset)} ({len(train_dataset)/len(formatted_dataset)*100:.1f}%)\")\n",
    "print(f\"테스트 데이터 수: {len(test_dataset)} ({len(test_dataset)/len(formatted_dataset)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d01634b1-25ad-46ae-9d19-8923fcd3c536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 학습 데이터 샘플 ===\n",
      "[SYSTEM]\n",
      "당신은 주어진 질문에 대해서 검색 결과, 질문, 보기를 바탕으로 답변해야 합니다.\n",
      "답변할 때는 근거:를 먼저 작성하고 답변:을 작성하십시오.\n",
      "검색 결과를 바탕으로 답변할 수 없는 경우에는 근거:에 검색 결과에 질문에 대한 답을 알 수 있는 내용이 없다고 설명하고 답변: 알 수 없음이라고 적으세요. 반드시 '알 수 없음'이라고 적어야 합니다.\n",
      "\n",
      "### 예시 ###\n",
      "근거: 삼양홀딩스는 직원들의 복리후생과 업무환경 개선에 많은 노력을 기울이고 있습니다. 사내에서 아침, 점심, 저녁을 무료로 제공하는 구내 식당과 피트니스 센터 운영을 통해 임직원의 건강을 지원하고 있으며, 카페테리아 및 다양한 편의시설을 제공하여 여유와 휴식을 취할 수 있는 환경을 마련하고 있습니다 (문서 0). 또한, 삼양홀딩스는 직원들이 일과 생활의 균형을 유지할 수 있는 유연근무제를 도입하여 직원들이 가장 편리한 시간에 근무할 수 있도록 하고 있습니다 (문서 0). 이러한 점들을 고려할 때, 삼양홀딩스는 쾌적한 근무환\n",
      "--------------------------------------------------\n",
      "[USER]\n",
      "질문: C3-2-2. 지배구조 요소와 관련하여 아래 항목 중 현재 재직하고 있는 회사에 해당되는 응답을 선택해주세요._1)(상장기업만 응답) 공정공시제도를 준수하고 있는가?\n",
      "\n",
      "보기:\n",
      "['1) 전혀그렇지않다', '2) 약간그렇지않다', '3) 보통이다', '4) 약간그렇다', '5) 매우그렇다']\n",
      "--------------------------------------------------\n",
      "[ASSISTANT]\n",
      "근거: 검색 결과에서는 동국제강이 공정공시제도를 준수하고 있는지에 대한 직접적인 정보가 제공되지 않았습니다. 동국제강의 환경 및 경영 실적, 지속가능 경영 방침 등에 대한 정보만 포함되어 있습니다.\n",
      "답변: 알 수 없음.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 6. 샘플 데이터 확인\n",
    "print(\"\\n=== 학습 데이터 샘플 ===\")\n",
    "for message in train_dataset[0]['messages']:\n",
    "    print(f\"[{message['role'].upper()}]\")\n",
    "\n",
    "    # 상위 500개 문자열만 출력\n",
    "    print(message['content'][:500])\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "951b09bf-2a95-485e-9c2c-7a52e1050552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 테스트 데이터 샘플 ===\n",
      "[SYSTEM]\n",
      "당신은 주어진 질문에 대해서 검색 결과, 질문, 보기를 바탕으로 답변해야 합니다.\n",
      "답변할 때는 근거:를 먼저 작성하고 답변:을 작성하십시오.\n",
      "검색 결과를 바탕으로 답변할 수 없는 경우에는 근거:에 검색 결과에 질문에 대한 답을 알 수 있는 내용이 없다고 설명하고 답변: 알 수 없음이라고 적으세요. 반드시 '알 수 없음'이라고 적어야 합니다.\n",
      "\n",
      "### 예시 ###\n",
      "근거: 삼양홀딩스는 직원들의 복리후생과 업무환경 개선에 많은 노력을 기울이고 있습니다. 사내에서 아침, 점심, 저녁을 무료로 제공하는 구내 식당과 피트니스 센터 운영을 통해 임직원의 건강을 지원하고 있으며, 카페테리아 및 다양한 편의시설을 제공하여 여유와 휴식을 취할 수 있는 환경을 마련하고 있습니다 (문서 0). 또한, 삼양홀딩스는 직원들이 일과 생활의 균형을 유지할 수 있는 유연근무제를 도입하여 직원들이 가장 편리한 시간에 근무할 수 있도록 하고 있습니다 (문서 0). 이러한 점들을 고려할 때, 삼양홀딩스는 쾌적한 근무환\n",
      "--------------------------------------------------\n",
      "[USER]\n",
      "질문: C3-1-1. 지배구조 요소와 관련하여 아래 항목 중 현재 재직하고 있는 회사에 해당되는 응답을 선택해주세요._6)자금 집행과 관리 주체를 분리하여 체계적으로 운영하고 있는가?\n",
      "\n",
      "보기:\n",
      "['1) 전혀그렇지않다', '2) 약간그렇지않다', '3) 보통이다', '4) 약간그렇다', '5) 매우그렇다']\n",
      "--------------------------------------------------\n",
      "[ASSISTANT]\n",
      "근거: 대웅제약은 회사 내에서 체계적인 리스크 관리 정책을 운영하고 있으며, 주요 위험 요소를 사전에 식별하고 대응함으로써 부정적 영향을 최소화하고 있습니다. 각 리스크 유형에 대한 관리는 해당 부서가 주도하며, 대표이사가 전체 리스크 상황을 파악하고 필요한 조치를 결정합니다. 이를 통해 안정적인 경영을 위한 체계적인 자금 집행과 관리가 이루어지고 있음을 알 수 있습니다 (문서 3).\n",
      "답변: '5) 매우그렇다'\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== 테스트 데이터 샘플 ===\")\n",
    "for message in test_dataset[0]['messages']:\n",
    "    print(f\"[{message['role'].upper()}]\")\n",
    "\n",
    "    # 상위 500개 문자열만 출력\n",
    "    print(message['content'][:500])\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "038167a1-0a6f-4b9c-8aa9-e4e753d36076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datasets.arrow_dataset.Dataset'>\n",
      "<class 'datasets.arrow_dataset.Dataset'>\n"
     ]
    }
   ],
   "source": [
    "# 리스트 형태에서 다시 Dataset 객체로 변경\n",
    "print(type(train_dataset))\n",
    "print(type(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6eef45da-7f4f-4bc0-b322-46390c21ebf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e15f9a3455a4b079bf28fcc804b3d6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1380 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터셋 저장\n",
    "test_dataset.save_to_disk(\"test_dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94383df4-9c95-47ab-b686-e32f8ce4f28c",
   "metadata": {},
   "source": [
    "## 2. 모델 로드 및 템플릿 적용\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "520b546c-f82f-4a44-951d-ea85dec73a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa537aa0c97d4b3a8d8f46de7d4ae861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 허깅페이스 모델 ID\n",
    "model_id = \"NCSOFT/Llama-VARCO-8B-Instruct\" \n",
    "\n",
    "# Load model and tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7aca009-8f0e-4579-b018-6fbcb2f2ad5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "당신은 주어진 질문에 대해서 검색 결과, 질문, 보기를 바탕으로 답변해야 합니다.\n",
      "답변할 때는 근거:를 먼저 작성하고 답변:을 작성하십시오.\n",
      "검색 결과를 바탕으로 답변할 수 없는 경우에는 근거:에 검색 결과에 질문에 대한 답을 알 수 있는 내용이 없다고 설명하고 답변: 알 수 없음이라고 적으세요. 반드시 '알 수 없음'이라고 적어야 합니다.\n",
      "\n",
      "### 예시 ###\n",
      "근거: 삼양홀딩스는 직원들의 복리후생과 업무환경 개선에 많은 노력을 기울이고 있습니다. 사내에서 아침, 점심, 저녁을 무료로 제공하는 구내 식당과 피트니스 센터 운영을 통해 임직원의 건강을 지원하고 있으며, 카페테리아 및 다양한 편의시설을 제공하여 여유와 휴식을 취할 수 있는 환경을 마련하고 있습니다 (문서 0). 또한, 삼양홀딩스는 직원들이 일과 생활의 균형을 유지할 수 있는 유연근무제를 도입하여 직원들이 가장 편리한 시간에 근무할 수 있도록 하고 있습니다 (문서 0). 이러한 점들을 고려할 때, 삼양홀딩스는 쾌적한 근무환경을 제공하고 있다고 평가할 수 있습니다.\n",
      "답변: '5) 매우그렇다\n",
      "\n",
      "검색 결과:\n",
      "<document 0>\n",
      "---\n",
      "ABOUT THIS REPORT\n",
      "본 보고서는 고객, 직원, 주주, 투자자 등 이해관계자들에게 동국제강의 \n",
      "환경경영 정보를 제공하기 위하여 발행하였습니다. 동국제강은 철강\n",
      "기업으로서 ‘자원순환 사회’ 및 ‘저탄소 사회’ 실현에 공헌하는 것을 환경\n",
      "과제로 삼고 있으며, 이러한 활동과 성과에 대한 정보를 중심으로 구성\n",
      "하고 있습니다.\n",
      "보고범위\n",
      "동국제강 본사 및 국내 사업장(인천공장, 포항공장, 부산공장, 당진공장, \n",
      "신평공장)의 활동과 성과를 담고 있습니다.\n",
      "보고기간\n",
      "2020년 1월 1일 ~ 2020년 12월 31일 동안의 활동 내용을 주로 담고 \n",
      "있으며, 환경개선 효과를 비교하기 위하여 과거 수 개년 동안의 실적과 \n",
      "향후 목표를 함께 수록하였습니다.\n",
      "본 보고서는 지속가능경영보고서의 국제표준 가이드라인인 GRI(Global \n",
      "Reporting Initiative) Standards, TCFD 등의 환경부문에 대한 기준을 \n",
      "반영하여 작성하였습니다. 보고서 내 재무 성과는 한국채택국제회계기\n",
      "준(K-IFRS)으로 작성하였습니다.\n",
      "서울특별시 중구 을지로5길 19(수하동, 페럼타워)\n",
      "문의 02-317-1114   \n",
      "홈페이지 www.dongkuk.com\n",
      "철을 되살리다\n",
      "생명을 되살리다\n",
      "---\n",
      "</document 0>\n",
      "\n",
      "<document 1>\n",
      "---\n",
      "28\n",
      "ENVIRONMENT REPORT 2021\n",
      "BETTER LIFE WITH STEEL \n",
      "01 \n",
      "SCR 투자\n",
      " -\n",
      "동국제강은 정부의 친환경정책에 적극적으로 동참하여, 철강 생산과정에서 발생하는 질소산화물의 배출을 저감하고\n",
      "자 2020년 부산에 소재한 신평공장의 가열로에 SCR설비를 도입하여 질소산화물 배출을 약 80% 저감시키는 등 SCR \n",
      "설비의 효과를 검증한 바 있습니다. 이에 추가적으로 포항공장 형강생산라인의 가열로에 SCR설비 1기를, 부산공장의 \n",
      "용융아연도금(CGL) 생산라인에 4기의 SCR 설비를 도입하기로 결정하였습니다. 투자금액은 37억  원 수준이며 이를 \n",
      "통하여 질소산화물 저감 목표를 달성토록 할 것입니다. \n",
      "  대기관리권역법 관련 투자액 (단위: 백만 원)\n",
      "구분 부산공장 인천공장 포항공장 당진공장 계\n",
      "SCR 3,300 - 548 - 3,848\n",
      "TMS 1,920 430 355 320 3,025\n",
      "계 5,220 430 903 320 6,873\n",
      "02 \n",
      "굴뚝 TMS 투자\n",
      " -\n",
      "대기오염물질 배출량을 실시간으로 모니터링하는 TMS(Tele-Monitoring System) 시스템 구축하여, 배출농도를 관할\n",
      "기관과 함께 법적 기준치 이하로 관리하고 있습니다. 동국제강은 올해도 18억 원을 투자하여 16개소에 TMS 시스템 구\n",
      "축을 완료할 계획이며, 내년까지 총 25개소로 확대할 예정입니다.\n",
      "  대기오염물질 배출량 (단위: 톤)\n",
      "구분 2018 2019 2020 2021 계획\n",
      "먼지 81 91 72 80\n",
      "황산화물 25 42 311 228\n",
      "질소산화물 1,030 1,080 1,028 972\n",
      "  대기오염 물질 배출 집약도 (단위: kg/t-생산량)\n",
      "구분 2018 2019 2020 2021 계획\n",
      "먼지 0.013 0.015 0.012 0.014\n",
      "황산화물 0.004 0.007 0.053 0.039\n",
      "질소산화물 0.160 0.178 0.176 0.167\n",
      "원격제어\n",
      "유선\n",
      "(전용선)\n",
      "무선\n",
      "(CDMA)인터넷\n",
      "수도권\n",
      "관제센터\n",
      "호남권\n",
      "관제센터\n",
      "영남권\n",
      "관제센터\n",
      "중부권\n",
      "관제센터\n",
      "사업장 측정기기\n",
      "자료 수집장치\n",
      "자료 전송장치\n",
      "자료 관리시스템\n",
      "TMS 시스템 운영 체계\n",
      "* 포항공장 : 신평공장 투자액 포함\n",
      "* SCR(Selective Catalytic Reduction)설비 : 조업 과정에서 발생하는 질소산화물을 선택적 촉매 환원법에 의해 수증기, 질소 등 무해한 가스 성분으로 바꾸어 주는 대기오염 방지 설비 \n",
      "종합환경\n",
      "관제센터 관할시·도환경부\n",
      "한국\n",
      "환경공단\n",
      "최근 국내로 유입되는 중국발 미세먼지 등의 영향으로 시민들이 일상생활에서 체감하는 대기환경의 중요성이 갈수록 \n",
      "커지고 있습니다. 이에 정부는 대기총량규제의 확대 적용 등 국내 대기오염물질 저감을 위하여 관련 규제를 강화하여 \n",
      "나가고 있습니다. \n",
      "동국제강은 철강생산 과정에서 발생하는 질소산화물(NOx), 황산화물(SOx), 먼지 등 대기오염물질의 배출을 줄이고 \n",
      "대기환경을 개선하기 위하여 다양한 노력을 기울이고 있습니다.\n",
      "체계적 대기오염물질 관리를 위하여 핵심 환경경영지표(KPI)로 대기오염물질 배출 원단위를 설정하고 있으며, 이는 \n",
      "조강 1톤 생산 시 굴뚝으로 배출되는 질소산화물, 황산화물 및 먼지의 각각의 배출량으로 산정됩니다. 동국제강은 이렇\n",
      "게 산정된 배출 원단위를 이해관계자에게 투명하게 공개하며 사회적 기업으로서 책임을 다하고자 노력하고 있습니다.\n",
      "대기오염물질 관리\n",
      "---\n",
      "</document 1>\n",
      "\n",
      "<document 2>\n",
      "---\n",
      "23\n",
      "ENVIRONMENT REPORT 2021\n",
      "BETTER LIFE WITH STEEL \n",
      "전기로는 저탄소 사회 실현을 위한 \n",
      "효과적인 제강생산 방법입니다.\n",
      "동국제강이 \n",
      "저탄소 사회를 만들어 갑니다.\n",
      "철강 생산과정에서 배출되는 CO2 가운데, 90% 이상은 고로 공정으로부터 배출되고 있습니다. 조강 \n",
      "1톤 생산 시 배출되는 CO2 양을 비교하면, 전기로 공법에서 CO2 배출량은 고로 공법의 약 ¼ 수준으로 \n",
      "조사되고 있습니다. 고로 공법에서는 철광석에서 철을 추출할 때, 산화철로부터 석탄(코크스)을 이용\n",
      "하여 산소를 빼앗는 ‘환원’이 필요하며, 그때 대량의 CO2를 배출합니다. 한편 전기로 공법에서는 철 스\n",
      "크랩을 전기로 용해함으로써 철을 제조하는데, 이 전기를 발전소에서 발전할 때 발생하는 CO2가 전기\n",
      "로 공법 CO2 배출량의 대부분을 차지합니다. 현 시점의 전력 구성에 있어서도 전기로 공법에서의 CO2\n",
      "배출량은 고로 공법에 비하여 압도적으로 적으며, 차후 신재생 에너지 등 비화석 에너지의 전력 보급에 \n",
      "의하여 전력의 탈탄소화가 진전되면 전기로 공법에 의한 CO2 배출량은 더욱 저감될 것입니다. 게다가 \n",
      "원료의 수송 프로세스에서 발생하는 CO2에 대하여서도, 대부분 국내에서 철 스크랩을 조달하여 재활\n",
      "용하는 전기로 업체가, 주원료의 대부분을 해외로부터 수입하는 고로 업체보다 단연 압도적입니다.\n",
      "국제 사회는 저탄소 사회 구현을 위하여 철강 산업 구조의 변화와 혁신을 추진하고 있습니다. 전략의 \n",
      "핵심은 고탄소 배출 공정인 고로 공정을 전기로 공정으로 전환하는 데 있으며, EU 및 미국 등 선진국을 \n",
      "중심으로 공정의 전환을 적극적으로 추진 중입니다. IEA(국제에너지기구)의 조사 결과에 따르면, 각국\n",
      "의 공정 전환 계획에 의거한 글로벌 철강업계의 전기로의 비중은 2019년 29%에서 2050년엔 57%까\n",
      "지 확대될 것으로 전망하였습니다. 이러한 추세를 보더라도 동국제강의 주요 제강 공법인 전기로 공법\n",
      "은 미래지향적인 공법임을 인식할 수 있습니다. 이에 동국제강은 당사의 전기로 공법을 통한 철강 제품 \n",
      "생산을 확대하는 것이야말로 저탄소 사회 실현에 기여하는 것이라는 사명감을 가지고 지속가능한 기\n",
      "업을 만들기 위하여 노력하겠습니다. \n",
      "글로벌 전기로 공법 \n",
      "확대 전망\n",
      "동국제강 전기로 생산에 따른 \n",
      "CO2 발생 저감 효과(2020년) \n",
      "고로 공법과 전기로 공법의 \n",
      "CO2 배출 흐름 비교\n",
      "고로 공법과 전기로 공법의 \n",
      "조강 1톤당 CO2 배출량 비교\n",
      "2019\n",
      "29%\n",
      "71%\n",
      "전기로 비중 확대\n",
      "+28%\n",
      "전기로고로\n",
      "1.5\n",
      "7.3\n",
      "CO2\n",
      "5.8백만 톤\n",
      "\u001a  고로(BOF)  \n",
      "\u001a  전기로(EAF)\n",
      "* Source : IEA, Iron & Steel Technology Roadmap(2020.10)\n",
      "* 산정 기준 : STEP(현재 각국 시행 중인 정책 및 목표 반영 시나리오) 및\n",
      " SDS(2070년 탄소중립 목표 달성에 필요한 정책 반영 시나리오\n",
      "* Source : 동경제철 환경보고서\n",
      "(전기로 10개 업체 및 고로 4개 업체의 일본 환경성 제출자료 기반)\n",
      "* 계산식 : 동국제강의 전기로 공법에 의한 조강 생산량 x \n",
      "(고로 1톤당 CO2 배출량 – 전기로 1톤당 CO2 배출량)\n",
      "(CO2 백만 톤)\n",
      "구분 CO2 배출량\n",
      "(천 톤 CO2)\n",
      "조강 생산량\n",
      "(만 톤)\n",
      "1톤당 CO2배출량\n",
      "(톤 CO2)\n",
      "전기로 업체 4,747 1,058 0.4\n",
      "고로 업체 165,064 7,738 1.9\n",
      "1.9tCO2\n",
      "0.4tCO2\n",
      "고로 공법\n",
      "전기로 공법\n",
      "고로 전기로\n",
      "철의 순환 과정\n",
      "1.9(C02톤/철 1톤)\n",
      "0.4(C02톤/철 1톤)\n",
      "0.003(C02톤/철 1톤)\n",
      "0.003(C02톤/철 1톤)\n",
      "국내\n",
      "빌딩\n",
      "가전\n",
      "자동차\n",
      "브라질에서 0.37(C02톤/철 1톤)\n",
      "호주에서 0.11(C02톤/철 1톤)\n",
      "해외\n",
      "철광석\n",
      "  고로     전기로\n",
      "2050\n",
      "57%\n",
      "43%\n",
      "---\n",
      "</document 2>\n",
      "\n",
      "<document 3>\n",
      "---\n",
      "29\n",
      "ENVIRONMENT REPORT 2021\n",
      "BETTER LIFE WITH STEEL \n",
      "03\n",
      "비산먼지 관리\n",
      " -\n",
      "동국제강은 원료 입고 및 생산공정에서 발생하는 비산먼지 제거를 위하여 철 스크랩을 1차적으로 옥내 보관을 실시하\n",
      "고 있으며, 옥외 야적장 및 고철 부두에는 전면 살수설비를 설치하여 비산먼지 발생을 최소화하고 있습니다. 또한, 수\n",
      "송과정에서 발생하는 비산먼지 저감을 위하여 도로 청소 차량을 운영하며, 부원료 이송 과정의 비산먼지는 밀폐하여 \n",
      "외부로 배출되지 않도록 관리하고 있습니다. 이 밖에도 방진설비 도입 및 정부가 주도하는 계절관리제 참여 등 다양한 \n",
      "활동을 통하여 비산먼지 관리를 철저히 하고 있습니다.\n",
      "04\n",
      "냄새 관리\n",
      " -\n",
      "주거시설이 인접한 인천 및 부산공장은 지역주민들의 쾌적한 대기환경 조성을 위해 냄새저감 설비 가동 및 실시간 \n",
      "모니터링을 실시하여 조업 시 발생하는 산업용 냄새를 최소화하여 관리하고 있습니다.\n",
      "  탈취 설비 현황\n",
      "구 분 설 비 설치 개소 2021년 투자금액\n",
      "인천공장 액상 탈취 설비 120톤 제강 0.32억 원\n",
      "부산공장 RTO*  全 CCL 8.23억 원\n",
      "* RTO : 축열식연소산화장치(Regenerative Thermal Oxidizer), VOC를 소각하여 악취물질 저감\n",
      "05\n",
      "정부 및 지방자치단체와의 협약\n",
      " -\n",
      "동국제강은 각 사업장이 위치한 지자체 및 정부부처와 오염물질 배출저감 자발적 협약을 맺고 대기오염 및 미세먼지 \n",
      "저감을 위하여 최선의 노력을 기울이고 있습니다.\n",
      "  환경 관련 주요 협약\n",
      "설치 개소 협약기간 협약기관 사업장\n",
      "미세먼지 저감 자발적 협약 2017.07.10. ~ 2021.12.31. 환경부 인천공장\n",
      "대기오염물질 자발적감축협약 2021.04.14. ~ 2022.12.31. 수도권대기환경청 인천공장\n",
      "화물차 미세먼지 저감 자발적 협약 2021.06.25. 부 수도권대기환경청 인천공장\n",
      "생태복원 MOU 협약 2018.12.05. ~ 2023.12.31. 지자체 포항공장\n",
      "대기오염물질 자발적감축협약 2017.07.10. ~ 2021.12.31 . 당진시청 당진공장\n",
      "미세먼지 특별대책위원회 2019. 11. 부 부산시 부산공장\n",
      "---\n",
      "</document 3>\n",
      "\n",
      "<document 4>\n",
      "---\n",
      "27\n",
      "ENVIRONMENT REPORT 2021\n",
      "BETTER LIFE WITH STEEL \n",
      "1  환경을 경영의 필수요소로 인식하고, 모든 단계에서 우선적으로 고려한다.\n",
      "2  국내외 환경 제반 법규와 협약을 준수하고 고객의 니즈를 만족시키는 수준 높은 기준을 설정하고 이행한다.\n",
      "3  경영활동 전반에 걸쳐 자원의 효율적 사용을 추구하며, 지속적인 개선을 통하여 온실가스 발생을 줄이도록 노력한다.\n",
      "4  환경 비상사태의 잠재적 발생 가능성을 파악하고 조직적인 대응책을 마련한다.\n",
      "5  이를 위하여 목표를 수립·실천하며, 이해관계자에게 본 방침을 공표하고 환경경영의 선진화에 노력한다.\n",
      "02\n",
      "환경경영 방침\n",
      " -\n",
      "동국제강은 지속가능한 친환경 저탄소 경제 구현을 위하여 다음 사항들을 실천합니다.\n",
      "04\n",
      "환경투자 실적\n",
      " -\n",
      "동국제강은 매년 환경에 대한 투자를 확대해가고 있습니다. 최근에는 미세먼지 저감에 대한 사회적 책임을 갖고 어려\n",
      "운 경영여건 속에서도 대기 관련 투자를 대폭 확대하였습니다. 2020년 환경투자비용은 전체 투자비의 11%인 82억 \n",
      "원이었으며, 전년 대비 82% 확대하였습니다.\n",
      "  환경투자 실적 및 목표 (단위: 억 원)\n",
      "구 분 2018 2019 2020  2021 계획\n",
      "총 투자비 438 418 759 1,291\n",
      "환경 투자비 14 45 82 115\n",
      "- 대기 1.8 6.4 55.1 84.9\n",
      "- 수질 5.9 38.0 1.5 5.2\n",
      "- 기타 6.0 0.7 25.4 25.0\n",
      "05\n",
      "환경경영 시스템\n",
      " -\n",
      "생산활동 중 발생 가능한 환경오염을 예방하고, 피해를 최소화를 위하여 시스템 기반으로 철저히 관리하고 있습니\n",
      "다. 환경경영시스템 국제규격 ISO14001에 따른 환경관리 항목을 체계적으로 관리하며, 현장 DB와 동국형 프로세스\n",
      "(DKMS)를 접목하여 전사 실시간 공유가 가능한 Web 시스템을 구축하였습니다.\n",
      "03\n",
      "환경경영 추진 조직\n",
      " -\n",
      "각 사업장의 안전환경팀은 전반적인 활동의 실행 주체로서 환경 이슈를 신속하게 대응하고 있으며, 주기적인 전사 \n",
      "회의 체계를 통하여 조직적인 관리를 해나가고 있습니다.\n",
      "  환경 관련 주요 회의\n",
      "구  분 내  용\n",
      "안전환경 실무자 회의 전사 환경안전 관련 이슈 점검 회의(공장 오프라인 회의)\n",
      "온실가스 협의체 분기별 전사 배출량 모니터링, 감축기술 공유 및 주요 이슈 점검 회의\n",
      "안전환경위원회 전사 환경/안전/보건 통합관리, 정부 환경정책 법규 대응 등\n",
      "* JFE 등 국내외 주요 철강사와 선진 환경안전 관리기법 공유를 위한 교류회의 수시 진행 중\n",
      "CEO\n",
      "COO\n",
      "인천공장장 포항공장장 당진공장장 부산공장장\n",
      "인천공장 \n",
      "안전환경팀\n",
      "포항공장\n",
      "안전환경팀\n",
      "당진공장\n",
      "안전환경팀\n",
      "부산공장\n",
      " 안전환경팀\n",
      "동반협력실장\n",
      "안전환경기획팀\n",
      " 자원 관리\n",
      "•에너지경영시스템 도입\n",
      "• 에너지, 온실가스 통합 관리체계 구축\n",
      "에너지 통합 관리\n",
      "• 폐자원, 수자원, 오염물질 관리\n",
      "기후변화 대응\n",
      "• 탄소경영 리스크 관리\n",
      "• 기후변화 리스크 대응\n",
      "구 분 인증 기간 인증기관 사업장\n",
      "ISO 14001\n",
      "2020.09.24. ~ 2023.09.23. BSI 인천공장\n",
      "2018.04.03. ~ 2024.04.02. BSI 포항공장\n",
      "2019.09.14. ~ 2022.09.13. BSI 당진공장\n",
      "2021.03.15. ~ 2024.03.14. KSA 부산공장\n",
      "---\n",
      "</document 4>\n",
      "\n",
      "<document 5>\n",
      "---\n",
      "30\n",
      "ENVIRONMENT REPORT 2021\n",
      "BETTER LIFE WITH STEEL \n",
      "동국제강은 자원순환 사회 실현에 기여하기 위하여 제품 생산과정에서 발생되는 부산물을 자원으로 재활용하고 폐기\n",
      "물 발생을 최소화하기 위한 노력을 이어가고 있습니다. 압연과정에서 발생되는 고철은 전량 전기로 조업 과정에 재투입\n",
      "하여 원재료로 활용하고 있으며, 제강과정에서 발생하는 대표적인 부산물인 제강 슬래그는 친환경 제품으로 인증받아 \n",
      "도로용 포장 골재 등의 새로운 자원으로 재활용하고 있습니다. 그 밖의 부산물인 철가루 형태의 밀 스케일(Mill Scale)과 \n",
      "제강 분진도 재활용 처리하여 자원순환에 이바지하고 있습니다.\n",
      "또한, 일부 재활용되지 않는 폐기물에 대해선 매립, 소각 처리를 최소화하기 위해 ‘부산물 자원화율’을 핵심경영지표\n",
      "(KPI)로 선정하여 관리하고 있습니다. 이러한 노력으로 부산물 자원화율은 2018년 98.4%에서 2020년 98.0%까지 \n",
      "지속적으로 유지하고 있습니다. \n",
      "  부산물 자원화 실적  (단위: 만 톤)\n",
      "구 분 2018 2019 2020\n",
      "발 생 63.5 78.8 57.6\n",
      "재활용/판매 62.5 77.8 56.5\n",
      "자원화율 98.4% 98.7% 98.0%\n",
      "* 발생고철 제외된 양으로 재산정\n",
      "  부산물 발생 비율(2020년 기준)   부산물의 용도별 재활용 현황\n",
      "재활용 용도 비 중\n",
      "성·복토용 골재 70%\n",
      "고로 부원료 12%\n",
      "아연 회수 10%\n",
      "기타 6%\n",
      "부산물 발생량\n",
      "57.6만톤\n",
      "분진    10% \n",
      "폐내화물\n",
      "2%\n",
      "산화철   5% \n",
      "매립·소각\n",
      "2%\n",
      "제강 슬래그\n",
      "68%\n",
      "아연(Zinc : Zn)의 Recycling\n",
      "제강 슬래그 재활용\n",
      "전기로(EAF)는 아연(Zinc)을 재활용하는 데 가장 널리 사용되는 공정입니다. 전기로 공정 중 발생되는 분진의 주성분\n",
      "은 철분과 아연이며, 이 분진의 약 30%를 차지하는 아연은 추출과 제련 과정을 거쳐 다시 아연도금강판을 생산하는 \n",
      "철강도금공장으로 돌아옵니다. 생산된 아연도금강판은 차량, 가전제품 등에 사용되고 수명을 다하여 고철이 되면 다\n",
      "시 전기로 공정을 통하여 재탄생됩니다. \n",
      "제강 슬래그는 도로 포장용 골재로 재활용되고 있습니다. 도로 기층은 통상적으로 모래, 자갈, 암석 같은 천연 자원들\n",
      "을 가공하여 사용하지만 동국제강의 전기로 설비에서 발생되는 부산물인 제강 슬래그가 이를 대체함으로써 천연골재 \n",
      "사용 감소에 따라 환경 훼손 방지에 기여하고 있습니다. \n",
      "     아연 Recycling에서 동국제강의 역할\n",
      "기타  13% \n",
      "환경부 친환경 제품 인증\n",
      "제강 슬래그\n",
      "도로포장 골재에서 \n",
      "제강 슬래그 재활용 범위 :\n",
      "‘기층+보조기층’ 천연골재 대체재 \n",
      "대체\n",
      "க\n",
      "க\n",
      "ӝக\n",
      "ઑӝக\n",
      "૑க\n",
      "전기로\n",
      "인천/포항\n",
      "공장\n",
      "아연도금\n",
      "강판공장\n",
      "부산공장\n",
      "아연추출공장 아연제련공장\n",
      "아연Zn분진\n",
      "고철 아연도금강판\n",
      "수요가\n",
      "부산물 재활용\n",
      "---\n",
      "</document 5>\n",
      "\n",
      "<document 6>\n",
      "---\n",
      "06\n",
      "ENVIRONMENT REPORT 2021\n",
      "BETTER LIFE WITH STEEL \n",
      "회사소개 \n",
      "Dongkuk Profile\n",
      "최고 경쟁력의\n",
      "Global \n",
      "Steel Company\n",
      "1954년 이 땅의 뼈대부터 다시 세워야 하였던 그때, \n",
      "무엇보다 철강이 바로 서야 한다는 사명감으로\n",
      "동국제강은 국내 최초 민간 철강기업을 세웠습니다. \n",
      "67년이 지난 지금, 동국제강은 \n",
      "세계시장을 선도하는 리더로 우뚝 섰습니다.\n",
      "철은 강합니다. \n",
      "철은 아름답습니다.\n",
      "강병(强兵)    \n",
      "원칙과 신뢰를 기반으로 \n",
      "책임경영을 완수하고 의사 결정의 신속성과 \n",
      "직원의 경쟁력을 키워\n",
      "부국(富國)   \n",
      "몰입과 창의적 소통으로 \n",
      "미래를 준비하자\n",
      "경영방침\n",
      "일반현황\n",
      "회사명 동국제강 주식회사\n",
      "설립일 1954년 7월 7일\n",
      "대표이사 장세욱 부회장, 김연극 사장\n",
      "사업내용 철강/냉연강판 제조 및 판매\n",
      "자본금 5,892억 원\n",
      "종업원 수 2,544명\n",
      "발행주식 총 수 95,432,737주\n",
      "자산 5조 2,495억 원\n",
      "본사 소재지 서울특별시 중구 을지로5길 19 \n",
      "(수하동, 페럼타워)\n",
      "미래경영\n",
      "인재경영\n",
      "스피드경영\n",
      "책임경영윤리경영\n",
      "富國\n",
      "强兵\n",
      "부\n",
      "국\n",
      "강\n",
      "병\n",
      "---\n",
      "</document 6>\n",
      "\n",
      "<document 7>\n",
      "---\n",
      "31\n",
      "ENVIRONMENT REPORT 2021\n",
      "BETTER LIFE WITH STEEL \n",
      "01 \n",
      "수자원 재활용\n",
      " -\n",
      "동국제강은 물 자원의 중요성을 인식하고 폐수 재활용 향상 및 방류수 수질 관리를 주요 관리영역으로 선정하여 관\n",
      "리하고 있습니다. 동국제강의 포항·인천공장은 폐수 무방류 배출 시설을 갖추고 있으며 사용되는 용수의 100%를 재\n",
      "활용하고 있습니다.\n",
      "  공장별 용수 재활용률(2020년 기준) (단위: 만 톤)\n",
      "구 분 공급량 재활용량 재활용률\n",
      "인천공장 179 179 100%\n",
      "포항공장 139 139 100%\n",
      "당진공장 22 3 14%\n",
      "부산공장 229 67 29%\n",
      "신평공장 3.2 3.2 100%\n",
      "  공장별 수질오염물질 배출농도(2020년 기준)\n",
      "  오폐수 방류량 및 수질오염물질 배출농도\n",
      "구 분 2018 2019 2020 2021 계획\n",
      "오폐수 방류량\n",
      "(만 톤)\n",
      "당진 1.2 1.3 1.2 1.3\n",
      "부산 258 201 186 1 85\n",
      "배출농도\n",
      "(mg/ℓ)\n",
      "당진\n",
      "BOD - 2.5 1.9 1.2\n",
      "COD 7.9 6.9 8.2 6\n",
      "부유물질 5 9.3 17.6 7.4\n",
      "PH 7.3 7.5 7.8 7.9\n",
      "부산\n",
      "BOD 2.8 3.4 5.4 4.1\n",
      "COD 19 21 26 18\n",
      "부유물질 4.4 2.3 3.5 2.1\n",
      "PH 7.4 6.9 7.1 7.4\n",
      "비점오염원 저감시설\n",
      "당진공장의 공업용수 및 생활용수의 경우, 하수종\n",
      "말처리장으로 유입처리되나, 일반우수관의 경우\n",
      "에는 바다로 방류될 수 밖에 없습니다. 당진공장은 \n",
      "해양생태계 보존에 어떠한 악영향도 끼치지 않기 \n",
      "위하여 도로 노면의 오염물질이 우천 시 바다로 직\n",
      "방류되는 것을 방지하고자 ‘비점오염원저감시설’\n",
      "을 통과하여 배출하고 있습니다. 해당 저감시설 내 \n",
      "여재는 매년 교체하며, 우천 시에 시설점검, 연 1회 \n",
      "수질분석 등을 실시하고 있습니다.\n",
      "비점저감시설은 총 5개소 (지하 위치) \n",
      "*/\n",
      "065ਬҕҙ੗тக\n",
      "க\n",
      "க\n",
      "஝\n",
      "੗тக\n",
      "க\n",
      "஝\n",
      "੗тக\n",
      "부산공장\n",
      "생물화학적 \n",
      "산소요구량(BOD)\n",
      "화학적 \n",
      "산소요구량(COD)\n",
      "부유물질량\n",
      "80.0\n",
      "4.2\n",
      "90.0\n",
      "15.7\n",
      "80.0\n",
      "1.9\n",
      "당진공장\n",
      "생물화학적 \n",
      "산소요구량(BOD)\n",
      "화학적 \n",
      "산소요구량(COD)\n",
      "부유물질량\n",
      "50.0 40.0\n",
      "8.2 2.11.9\n",
      "80.0\n",
      "* 당진공장은 사외 하수처리장 최종 처리 후 방류\n",
      "* 부산공장은 직접 운영하는 폐수처리장에서 환경 기준치 이하 관리 후 방류\n",
      "\u001a  법적기준\n",
      "\u001a  2020년 실적\n",
      "02\n",
      "생물다양성 보존\n",
      " -\n",
      "부산공장은 인근 해역의 수질에 미치는 영향을 최소화하기 위하여 자체 폐수처리시설을 운영하고 있으며, 폐수는 1차 \n",
      "물리·화학적 처리를 거치고, 유기물이 함유된 폐수는 생물학적 처리를 통하여 2차 처리 됩니다. 1, 2차 처리된 폐수는 \n",
      "최종폐수처리시설을 거쳐 법적 기준치 이하로 방류됩니다. 당진공장의 경우에는 사외 하수종말처리장으로 유입처리\n",
      "되고 있으며, 각 사업장은 수질오염물질의 배출농도를 법적 허용기준의 50% 이하 수준으로 목표를 수립하여 관리하\n",
      "고 있습니다.\n",
      "수자원 관리\n",
      "---\n",
      "</document 7>\n",
      "\n",
      "<document 8>\n",
      "---\n",
      "33\n",
      "ENVIRONMENT REPORT 2021\n",
      "BETTER LIFE WITH STEEL \n",
      "기후변화 \n",
      "Climate Change\n",
      "기후변화는 이미 오래전부터 전 세계가 당면한 과제이며, 기후변화 대응에 적극적인 노력을 기울이지 않을 경우 사업\n",
      "에 지대한 영향을 미칠 만큼 중요한 이슈가 되어가고 있습니다. EU는 2019년 12월 Green Deal 정책을 발표하였고, \n",
      "2050년까지 탄소중립Carbon Neutral 실현과 더불어 탄소국경세Carbon Border Tax를 도입하여 탄소 다량 배출 국가\n",
      "를 압박하고 탈석탄 및 재생에너지 보급 확대를 위한 인센티브 제도를 개편하는 등 각종 규제안을 마련하고 있습니다. \n",
      "이러한 국제적 흐름에 동참하여 한국 정부도 작년 ‘2050 탄소중립’을 선언하였으며, 동국제강을 포함한 국내 철강업\n",
      "계도 ‘그린철강위원회’ 출범을 통하여 공동으로 탄소중립 목표 달성 기여를 위하여 노력하고 있습니다. 동국제강은 이\n",
      "와 별개로 기후변화 문제에 효율적으로 대처하기 위하여 관련 이슈를 파악한 후 위험성을 분석하고 대응 전략을 수립\n",
      "하여 실행하고 있습니다. 온실가스 협의체를 통하여 기후변화 대응 활동을 분기별로 협의하고, 온실가스 인벤토리를 \n",
      "구축하여 매월 모든 사업장의 온실가스(Scope 1, Scope 2) 배출량을 관리하고 있습니다.\n",
      "01 \n",
      "기후변화 대응 체계 및 조직\n",
      " -\n",
      "동국제강은 동반협력실 산하의 ‘온실가스 협의체’를 구성하여 전사차원의 에너지 경영방침을 수립하여 실행하고 있습\n",
      "니다.02 \n",
      "기후변화 리스크 및 기회요인 분석\n",
      " -\n",
      "동국제강은 기후변화를 기업의 주요 경영 이슈로 판단하고, 글로벌 기후변화 문제에 적극 대처하고자 합니다. 기후변화 \n",
      "리스크 및 기회요인을 규제적 측면, 물리적 측면 등으로 분류하고, 각 이슈에 대한 대응방안을 수립하였습니다.\n",
      "  이슈 파악 및 리스크 대응 방안\n",
      "리스크 대응방안 기회요인\n",
      "규제적\n",
      "측면\n",
      "온실가스 배출권 거래 배출량 저감 및 배출권 거래제 대응체계 구축\n",
      "• 온실가스 배출권 확보\n",
      "• 프리미엄 제품 판매 확대\n",
      "• 친환경 신사업 진출\n",
      "• 에너지 효율 증대로 원가절감\n",
      "• 친환경 인증 및 판매처 확대\n",
      "• 친환경 철강 기업 이미지 제고\n",
      "탄소세 국가별 정책 모니터링 및 대응체계 구축\n",
      "자원순환 기본법 부산물 자원화 확대 및 철 스크랩 사용 증대\n",
      "물리적\n",
      "측면\n",
      "기상이변 직접 피해 사업장별 자연재해 예방 시스템 구현 \n",
      "기상이변 간접 피해 공급망 피해 대응 구매 및 판매처 다변화\n",
      "기타 기업 평판 이해관계자 커뮤니케이션 강화\n",
      "CEO\n",
      "동반협력실장\n",
      "온실가스 협의체\n",
      "인천공장\n",
      "안전환경팀\n",
      "포항공장\n",
      "안전환경팀\n",
      "당진공장\n",
      "안전환경팀\n",
      "부산공장\n",
      "안전환경팀\n",
      "안전환경기획팀\n",
      "---\n",
      "</document 8>\n",
      "\n",
      "<document 9>\n",
      "---\n",
      "13\n",
      "ENVIRONMENT REPORT 2021\n",
      "BETTER LIFE WITH STEEL \n",
      "경영실적\n",
      "Management Performance\n",
      "01 \n",
      "2020년 경영환경 및 당사 대응\n",
      " -\n",
      "전 세계 코로나19 확산으로 경제활동에 차질이 발생하였으며, 이는 글로벌 철강산업에도 악영향을 주었\n",
      "습니다. 중국을 제외한 글로벌 철강 수요량은 2019년 대비 13% 감소하였으며, 철광석 가격은 2019년 대\n",
      "비 2.3배 급등하였습니다. 수급 불균형으로 인한 글로벌 철강산업의 침체기 속에서도 동국제강은 전기로 \n",
      "이점을 활용한 수요시장에 대한 유연한 공장가동 대응과 고수익 제품 판매 확대를 통하여 안정적인 수익\n",
      "을 창출하였습니다.\n",
      "전기로 \n",
      "탄력적 가동\n",
      "하반기 가전컬러 \n",
      "판매 확대\n",
      "고수익 제품 \n",
      "판매 확대\n",
      "철광석 가격\n",
      "(달러/톤)\n",
      "210\n",
      "160\n",
      "110\n",
      "60\n",
      "835\n",
      "2016\n",
      "859\n",
      "2017\n",
      "874\n",
      "2018\n",
      "859\n",
      "2019\n",
      "745\n",
      "2020\n",
      "글로벌 철강 수요\n",
      "(백만 톤)\n",
      "---\n",
      "</document 9><|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "질문: C3-2-2. 지배구조 요소와 관련하여 아래 항목 중 현재 재직하고 있는 회사에 해당되는 응답을 선택해주세요._1)(상장기업만 응답) 공정공시제도를 준수하고 있는가?\n",
      "\n",
      "보기:\n",
      "['1) 전혀그렇지않다', '2) 약간그렇지않다', '3) 보통이다', '4) 약간그렇다', '5) 매우그렇다']<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "근거: 검색 결과에서는 동국제강이 공정공시제도를 준수하고 있는지에 대한 직접적인 정보가 제공되지 않았습니다. 동국제강의 환경 및 경영 실적, 지속가능 경영 방침 등에 대한 정보만 포함되어 있습니다.\n",
      "답변: 알 수 없음.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 템플릿 적용\n",
    "text = tokenizer.apply_chat_template(\n",
    "    train_dataset[0][\"messages\"], tokenize=False, add_generation_prompt=False\n",
    ")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab6edd1-951a-4950-be9a-8d2096d2752d",
   "metadata": {},
   "source": [
    "## 3. LoRA와 SFTConfig 설정\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ad8216d-baaa-4aaa-b172-ca992c9f4bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "        lora_alpha=32,\n",
    "        lora_dropout=0.1,\n",
    "        r=8,\n",
    "        bias=\"none\",\n",
    "        target_modules=[\"q_proj\", \"v_proj\"],\n",
    "        task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7395e400-be31-4e70-afaa-b90a0573cc0a",
   "metadata": {},
   "source": [
    "- lora_alpha: LoRA(Low-Rank Adaptation)에서 사용하는 스케일링 계수를 설정합니다. LoRA의 가중치 업데이트가 모델에 미치는 영향을 조정하는 역할을 하며, 일반적으로 학습 안정성과 관련이 있습니다.\n",
    "- lora_dropout: LoRA 적용 시 드롭아웃 확률을 설정합니다. 드롭아웃은 과적합(overfitting)을 방지하기 위해 일부 뉴런을 랜덤하게 비활성화하는 정규화 기법입니다. 0.1로 설정하면 학습 중 10%의 뉴런이 비활성화.\n",
    "- r: LoRA의 랭크(rank)를 설정합니다. 이는 LoRA가 학습할 저차원 공간의 크기를 결정합니다. 작은 값일수록 계산 및 메모리 효율이 높아지지만 모델의 학습 능력이 제한될 수 있습니다.\n",
    "- bias: LoRA 적용 시 편향(bias) 처리 방식을 지정합니다. \"none\"으로 설정하면 편향이 LoRA에 의해 조정되지 않습니다. \"all\" 또는 \"lora_only\"와 같은 값으로 변경하여 편향을 조정할 수도 있습니다.\n",
    "- target_modules: LoRA를 적용할 특정 모듈(레이어)의 이름을 리스트로 지정합니다. 예제에서는 \"q_proj\"와 \"v_proj\"를 지정하여, 주로 Self-Attention 메커니즘의 쿼리와 값 프로젝션 부분에 LoRA를 적용합니다.\n",
    "- task_type: LoRA가 적용되는 작업 유형을 지정합니다. \"CAUSAL_LM\"은 Causal Language Modeling, 즉 시퀀스 생성 작업에 해당합니다. 다른 예로는 \"SEQ2SEQ_LM\"(시퀀스-투-시퀀스 언어 모델링) 등이 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbe8e9bc-92e7-41ae-b03b-253357969160",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = SFTConfig(\n",
    "    output_dir=\"llama3-8b-esg-survey-model\",           # 저장될 디렉토리와 저장소 ID\n",
    "    num_train_epochs=3,                      # 학습할 총 에포크 수 \n",
    "    per_device_train_batch_size=1,           # GPU당 배치 크기\n",
    "    gradient_accumulation_steps=4,           # 그래디언트 누적 스텝 수\n",
    "    gradient_checkpointing=True,             # 메모리 절약을 위한 체크포인팅\n",
    "    optim=\"adamw_torch_fused\",               # 최적화기\n",
    "    logging_steps=10,                        # 로그 기록 주기\n",
    "    save_strategy=\"steps\",                   # 저장 전략\n",
    "    save_steps=50,                           # 저장 주기\n",
    "    bf16=True,                              # bfloat16 사용\n",
    "    learning_rate=1e-4,                     # 학습률\n",
    "    max_grad_norm=0.3,                      # 그래디언트 클리핑\n",
    "    warmup_ratio=0.03,                      # 워밍업 비율\n",
    "    lr_scheduler_type=\"constant\",           # 고정 학습률\n",
    "    push_to_hub=False,                      # 허브 업로드 안 함\n",
    "    remove_unused_columns=False,\n",
    "    dataset_kwargs={\"skip_prepare_dataset\": True},\n",
    "    report_to=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6ff34d-0256-4a1a-a1d6-728c6a74097f",
   "metadata": {},
   "source": [
    "- `output_dir`: 학습 결과가 저장될 디렉토리 또는 모델 저장소의 이름을 지정합니다. 이 디렉토리에 학습된 모델 가중치, 설정 파일, 로그 파일 등이 저장됩니다.\n",
    "\r\n",
    "- `num_train_epochs`: 모델을 학습시키는 총 에포크(epoch) 수를 지정합니다. 에포크는 학습 데이터 전체를 한 번 순회한 주기를 의미합니다. 예를 들어, `3`으로 설정하면 데이터셋을 3번 학습합니.\r\n",
    "\r\n",
    "- `per_device_train_batch_size`: GPU 한 대당 사용되는 배치(batch)의 크기를 설정합니다. 배치 크기는 모델이 한 번에 처리하는 데이터 샘플의 수를 의미합니다. 작은 크기는 메모리 사용량이 적지만 학습 시간이 증가할 수 있니다.\r\n",
    "\r\n",
    "- `gradient_accumulation_steps`: 그래디언트를 누적할 스텝(step) 수를 지정합니다. 이 값이 `2`로 설정된 경우, 두 스텝마다 그래디언트를 업데이트합니다. 배치 크기를 가상으로 늘리는 효과가 있으며, GPU 메모리 부족 문제를 해결할 때 용합니다.\r\n",
    "\r\n",
    "- `gradient_checkpointing`: 그래디언트 체크포인팅을 활성화하여 메모리를 절약합니다. 이 옵션은 계산 그래프를 일부 저장하지 않고 다시 계산하여 메모리를 절약하지만, 속도가 약간 느려질수 있습니다.\r\n",
    "\r\n",
    "- `optim`: 학습 시 사용할 최적화 알고리즘을 설정합니다. `adamw_torch_fused`는 PyTorch의 효율적인 AdamW 최적기를 사용합니다.\r\n",
    "\r\n",
    "- `logging_steps`: 로그를 기록하는 주기를 스텝 단위로 지정합니다. 예를 들어, `10`으로 설정하면 매 10 스텝마 로그를 기록합니다.\r\n",
    "\r\n",
    "- `save_strategy`: 모델을 저장하는 전략을 설정합니다. `\"steps\"`로 설정된 경우, 지정된 스마다 모델이 저장됩니다.\r\n",
    "\r\n",
    "- `save_steps`: 모델을 저장하는 주기를 스텝 단위로 설정합니다. 예를 들어, `50`으로 설정하면 매 50스텝마다 모델을 저장합니다.\r\n",
    "\r\n",
    "- `bf16`: `bfloat16` 정밀도를 사용하도록 설정합니다. `bfloat16`은 FP32와 유사한 범위를 제공하면서 모리와 계산 효율성을 높입니다.\r\n",
    "\r\n",
    "- `learning_rate`: 학습률을 지정합니다. 학습률은 모델의 가중치가 한 번의 업데이트에서 얼마나 크게 변할지를 결정합니다. 일반적으로 작은 값을 용하여 안정적인 학습을 유도합니다.\r\n",
    "\r\n",
    "- `max_grad_norm`: 그래디언트 클리핑의 임계값을 설정합니다. 이 값보다 큰 그래디언트가 발생하면, 임계값으로 정하여 폭발적 그래디언트를 방지합니다.\r\n",
    "\r\n",
    "- `warmup_ratio`: 학습 초기 단계에서 학습률을 선형으로 증가시키는 워밍업 비율을 지정합니다 학습의 안정성을 높이기 위해 사용됩니다.\r\n",
    "\r\n",
    "- `lr_scheduler_type`: 학습률 스케줄러의 유형을 설정합니다. `\"costant\"`는 학습률을 일정하게 유지합니다.\r\n",
    "\r\n",
    "- `push_to_hub`: 학습된 모델을 허브에 업로드할지 여부를 설정합니. `False`로 설정하면 업로드하지 않습니다.\r\n",
    "\r\n",
    "- `remove_unused_columns`: 사용되지 않는 열을 제거할지 여부를 설정합니다.`True`로 설정하면 메모리를 절약할 수 있습니다.\r\n",
    "\r\n",
    "- `dataset_kwargs`: 데이터셋 로딩 시 추가적인 설정을 전달합니다. 예제에서는 `skip_prepare_dataset True`로 설정하여 데이터셋 준비 단계를 건너뜁니다.\r\n",
    "\r\n",
    "- `report_to`: 학습 로그를 보고할 대상을 지정합니다. `None`으로 설정되면 로그가 기록되지 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589f0a2f-639b-4b89-852a-7a0bbcbe1203",
   "metadata": {},
   "source": [
    "## 4. 학습 중 전처리 함수: collate_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9526becf-24c6-49b9-b503-75f31f64ae0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    new_batch = {\n",
    "        \"input_ids\": [],\n",
    "        \"attention_mask\": [],\n",
    "        \"labels\": []\n",
    "    }\n",
    "\n",
    "    for example in batch:\n",
    "        messages = example[\"messages\"]\n",
    "\n",
    "        # LLaMA 3 채팅 템플릿 적용 (시작 토큰 포함)\n",
    "        prompt = \"<|begin_of_text|>\"\n",
    "        for msg in messages:\n",
    "            role = msg[\"role\"]\n",
    "            content = msg[\"content\"].strip()\n",
    "            prompt += f\"<|start_header_id|>{role}<|end_header_id|>\\n{content}<|eot_id|>\"\n",
    "\n",
    "        # 마지막 assistant 메시지는 응답으로 간주하고 레이블에 포함\n",
    "        text = prompt.strip()\n",
    "\n",
    "        # 토큰화\n",
    "        tokenized = tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            max_length=max_seq_length,\n",
    "            padding=False,\n",
    "            return_tensors=None,\n",
    "        )\n",
    "\n",
    "        input_ids = tokenized[\"input_ids\"]\n",
    "        attention_mask = tokenized[\"attention_mask\"]\n",
    "        labels = [-100] * len(input_ids)\n",
    "\n",
    "        # assistant 응답의 시작 위치 찾기\n",
    "        assistant_header = \"<|start_header_id|>assistant<|end_header_id|>\\n\"\n",
    "        assistant_tokens = tokenizer.encode(assistant_header, add_special_tokens=False)\n",
    "        eot_token = \"<|eot_id|>\"\n",
    "        eot_tokens = tokenizer.encode(eot_token, add_special_tokens=False)\n",
    "\n",
    "        # 레이블 범위 지정\n",
    "        i = 0\n",
    "        while i <= len(input_ids) - len(assistant_tokens):\n",
    "            if input_ids[i:i + len(assistant_tokens)] == assistant_tokens:\n",
    "                start = i + len(assistant_tokens)\n",
    "                end = start\n",
    "                while end <= len(input_ids) - len(eot_tokens):\n",
    "                    if input_ids[end:end + len(eot_tokens)] == eot_tokens:\n",
    "                        break\n",
    "                    end += 1\n",
    "                for j in range(start, end):\n",
    "                    labels[j] = input_ids[j]\n",
    "                for j in range(end, end + len(eot_tokens)):\n",
    "                    labels[j] = input_ids[j]  # <|eot_id|> 토큰도 포함\n",
    "                break\n",
    "            i += 1\n",
    "\n",
    "        new_batch[\"input_ids\"].append(input_ids)\n",
    "        new_batch[\"attention_mask\"].append(attention_mask)\n",
    "        new_batch[\"labels\"].append(labels)\n",
    "\n",
    "    # 패딩 처리\n",
    "    max_length = max(len(ids) for ids in new_batch[\"input_ids\"])\n",
    "    for i in range(len(new_batch[\"input_ids\"])):\n",
    "        pad_len = max_length - len(new_batch[\"input_ids\"][i])\n",
    "        new_batch[\"input_ids\"][i].extend([tokenizer.pad_token_id] * pad_len)\n",
    "        new_batch[\"attention_mask\"][i].extend([0] * pad_len)\n",
    "        new_batch[\"labels\"][i].extend([-100] * pad_len)\n",
    "\n",
    "    for k in new_batch:\n",
    "        new_batch[k] = torch.tensor(new_batch[k])\n",
    "\n",
    "    return new_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181ea71f-f642-4aed-ba4d-d142535571c4",
   "metadata": {},
   "source": [
    "- 라마 챗 템플릿\n",
    "\n",
    "```\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\r\n",
    "\r\n",
    "You are a helpful AI assistant for travel tips and recommendations.<|eot_id|><|start_header_id|>user<|end_header_id|>\r\n",
    "\r\n",
    "What can you help me with?<|eot_id|><|start_header_id|>assistant<|end_header_id|>|>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f337c79-37a9-4f68-8f4d-586a687422e4",
   "metadata": {},
   "source": [
    "collate_fn(batch) 함수는 자연어 처리 모델 학습을 위해 데이터를 전처리하는 역할을 수행합니다. 이 함수는 배치 내의 데이터를 처리하여 모델이 사용할 수 있는 입력 형식으로 변환합니다.\n",
    "\n",
    "먼저, 각 샘플의 메시지에서 개행 문자를 제거하고 필요한 정보만 남깁니다. 정리된 메시지로 텍스트를 구성하고 이를 토큰화하여 input_ids와 attention_mask를 생성합니다. 이후 assistant 답변 부분을 찾아 해당 범위에 레이블을 설정합니다. 이 범위를 제외한 나머지 위치는 -100으로 설정하여 손실 계산에서 제외되도록 합니다.\n",
    "\n",
    "최종적으로, 배치 내 모든 샘플의 길이를 동일하게 맞추기 위해 패딩 작업을 수행합니다. 이 과정에서 입력 데이터에는 패딩 토큰 ID를 추가하고, 어텐션 마스크에는 0을 추가하며, 레이블에는 -100을 추가합니다. 모든 데이터는 PyTorch 텐서로 변환되어 반환됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "397d4044-d709-4492-ab4b-63ed3ec11d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "처리된 배치 데이터:\n",
      "입력 ID 형태: torch.Size([1, 8305])\n",
      "어텐션 마스크 형태: torch.Size([1, 8305])\n",
      "레이블 형태: torch.Size([1, 8305])\n"
     ]
    }
   ],
   "source": [
    "# 최대 길이\n",
    "max_seq_length=16384\n",
    "\n",
    "# collate_fn 테스트 (배치 크기 1로)\n",
    "example = train_dataset[0]\n",
    "batch = collate_fn([example])\n",
    "\n",
    "print(\"\\n처리된 배치 데이터:\")\n",
    "print(\"입력 ID 형태:\", batch[\"input_ids\"].shape)\n",
    "print(\"어텐션 마스크 형태:\", batch[\"attention_mask\"].shape)\n",
    "print(\"레이블 형태:\", batch[\"labels\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "633a4b4e-6192-4231-a33e-3e1b35cc06fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력에 대한 정수 인코딩 결과:\n",
      "[128000, 128006, 9125, 128007, 198, 65895, 83628, 34804, 56773, 125441, 109760, 19954, 122115, 115036, 99901, 11, 109760, 11, 64432, 106647, 82818, 120378, 43139, 111964, 110513, 109670, 627, 109659, 104449, 48936, 54718, 16969, 106589, 93292, 25, 18918, 125921, 114839, 101360, 111964, 25, 18359, 114839, 16582, 119978, 627, 109070, 78326, 99901, 18918, 82818, 120378, 43139, 111964, 48936, 29833, 108838, 50152, 102772, 106589, 93292, 25, 19954, 115036, 99901, 19954, 109760, 19954, 102597, 108386, 18359, 102066, 29833, 65621, 109842, 13094, 47782, 105954, 114942, 101360, 111964, 25, 102066, 29833, 127409, 110917, 103607, 34609, 51402, 13, 64857, 30446, 30426, 364, 111012, 29833, 127409, 6, 110917, 103607, 32179, 90759, 109670, 382, 14711, 96717, 30426, 66387, 104152, 93292, 25, 107455, 101927, 124800, 113081, 119524, 105164, 55421, 106001, 107067, 29102, 102252, 77535, 54780, 107022, 100981, 127812, 74623, 101151, 19954, 110187, 102058, 116688, 55216, 102275, 109816, 103924, 13, 33229, 96318, 57575, 126474, 11, 106313, 102612, 11, 102678, 127675, 18359, 112830, 17835, 108273, 44005, 59877, 96318, 108459, 65895, 54780, 104064, 29726, 123479, 121820, 34961, 107065, 18359, 110155, 105813, 102436, 123645, 124694, 18359, 109682, 101360, 117097, 11, 103236, 104249, 102953, 106953, 101824, 118696, 105613, 21028, 30426, 102546, 18359, 108273, 83290, 84618, 101314, 81673, 114602, 118156, 107545, 48936, 29833, 65621, 118909, 18359, 96677, 103304, 101360, 103924, 320, 52688, 27796, 220, 15, 570, 112887, 11, 107455, 101927, 124800, 113081, 119524, 105164, 55421, 102823, 84656, 54780, 120376, 21028, 102319, 254, 102193, 18359, 124208, 48936, 29833, 65621, 101003, 101347, 104152, 100981, 38187, 18918, 101703, 44966, 83290, 105164, 55421, 102823, 107120, 105613, 29102, 24486, 106243, 19954, 106589, 100981, 48936, 29833, 123644, 107973, 103924, 320, 52688, 27796, 220, 15, 570, 122016, 106313, 105880, 125714, 48936, 54718, 11, 107455, 101927, 124800, 113081, 119524, 3396, 122, 234, 82068, 24486, 106589, 100981, 127812, 18359, 108273, 101360, 127423, 116090, 48936, 29833, 103924, 627, 109659, 104449, 25, 364, 20, 8, 121520, 49706, 104977, 13447, 271, 109070, 78326, 99901, 512, 27, 6190, 220, 15, 397, 11192, 76630, 10245, 45176, 198, 101948, 109849, 118135, 116534, 11, 105164, 55421, 11, 56773, 55430, 11, 107896, 26799, 26799, 78102, 117210, 126951, 26799, 114026, 101604, 100654, 38187, 102296, 21028, 720, 127812, 66406, 101090, 61139, 18918, 108273, 67525, 46810, 83290, 97096, 101066, 111320, 39331, 13, 101604, 100654, 38187, 102296, 34804, 112521, 102296, 198, 119398, 43139, 27796, 3451, 26799, 55421, 106869, 66338, 109642, 529, 101824, 3451, 101464, 109208, 44690, 109642, 529, 102326, 102335, 19954, 100994, 116135, 44005, 107387, 118909, 198, 54780, 38187, 17835, 107455, 35495, 117097, 11, 122016, 114291, 54780, 102132, 54780, 19954, 102597, 61139, 18918, 122169, 43139, 114702, 198, 101360, 103924, 627, 115202, 108860, 82001, 198, 58189, 100654, 38187, 102296, 104414, 56154, 101824, 120380, 115888, 41953, 7, 32428, 101584, 79225, 41953, 11, 99969, 103866, 79225, 41953, 11, 118089, 79225, 41953, 11, 103153, 86351, 79225, 41953, 11, 720, 22254, 58260, 237, 231, 79225, 41953, 112574, 114291, 54780, 102132, 54780, 18918, 110038, 35495, 103924, 627, 115202, 117534, 198, 2366, 15, 100392, 220, 16, 100551, 220, 16, 33177, 4056, 220, 2366, 15, 100392, 220, 717, 100551, 220, 2148, 33177, 113401, 21028, 114291, 109842, 18359, 56773, 17835, 110038, 35495, 720, 105625, 104429, 11, 118909, 60861, 101151, 122035, 18918, 116443, 67525, 46810, 83290, 104219, 93292, 29833, 74623, 100392, 113401, 21028, 102326, 82068, 54780, 720, 104762, 102252, 103504, 102260, 18918, 106999, 29833, 50764, 111320, 39331, 627, 101948, 109849, 118135, 67890, 102130, 116669, 66406, 101090, 115202, 27796, 21028, 115878, 102260, 102611, 36609, 113286, 109317, 32428, 480, 4403, 47844, 720, 71231, 38756, 8, 35653, 11, 350, 9847, 35, 122733, 118909, 64189, 52688, 19954, 102597, 111902, 18359, 720, 101738, 101090, 83290, 114839, 111320, 39331, 13, 109849, 27796, 67236, 102888, 100981, 102132, 54780, 16969, 104008, 109126, 104727, 100654, 38187, 62841, 101015, 21121, 198, 102611, 17155, 12, 2843, 11706, 8, 43139, 114839, 111320, 39331, 627, 115978, 124658, 72043, 89359, 117615, 22035, 17835, 20, 106103, 220, 777, 7, 24140, 16582, 58189, 11, 106960, 104221, 101109, 103430, 340, 112343, 220, 2437, 12, 16718, 12, 5037, 19, 5996, 127514, 118026, 8604, 962, 647, 123736, 916, 198, 107837, 18359, 98243, 108281, 29102, 13447, 198, 77535, 126546, 98243, 108281, 29102, 13447, 198, 11192, 524, 6190, 220, 15, 1363, 27, 6190, 220, 16, 397, 11192, 1591, 198, 31460, 60939, 45176, 220, 2366, 16, 198, 33, 1372, 4292, 61094, 4874, 27597, 2818, 720, 1721, 720, 38409, 107896, 26799, 198, 18722, 58189, 100654, 38187, 102296, 34804, 118951, 21028, 108280, 127812, 30381, 107011, 19954, 103607, 110616, 104182, 101604, 113825, 83290, 11, 112521, 102296, 124919, 121199, 57575, 113610, 44005, 105689, 44690, 86157, 57390, 101438, 21028, 74769, 71023, 18359, 102678, 103655, 101360, 198, 26799, 220, 2366, 15, 100392, 118089, 19954, 101228, 58232, 24486, 30027, 58260, 237, 231, 79225, 41953, 21028, 36609, 55055, 17835, 19954, 77800, 102546, 71682, 18918, 101703, 44966, 83290, 105689, 44690, 86157, 57390, 101438, 74769, 71023, 18359, 106943, 220, 1490, 4, 102678, 103655, 119995, 16969, 78102, 77800, 720, 102546, 71682, 21028, 122035, 18918, 86422, 102249, 24486, 82818, 103924, 13, 23955, 19954, 69508, 104182, 99969, 103866, 79225, 41953, 106612, 102296, 77535, 86157, 109317, 21028, 36609, 55055, 17835, 19954, 77800, 102546, 71682, 220, 16, 106647, 11, 118089, 79225, 41953, 21028, 720, 27797, 123061, 54059, 101347, 49085, 101136, 3100, 3910, 8, 124919, 109317, 19954, 220, 19, 124991, 77800, 58952, 71682, 18918, 101703, 44966, 67525, 17835, 121469, 111320, 39331, 13, 107896, 26799, 101136, 106446, 34804, 220, 1806, 108609, 220, 102467, 29833, 102611, 112373, 117012, 720, 102233, 83290, 105689, 44690, 86157, 57390, 101438, 102678, 103655, 103504, 102260, 18918, 104685, 33931, 101665, 50764, 96102, 123263, 13, 720, 220, 62060, 21121, 106974, 103131, 101577, 101661, 106434, 107896, 26799, 106446, 320, 101353, 82001, 25, 107696, 73653, 102467, 340, 89359, 80816, 118089, 79225, 41953, 121772, 79225, 41953, 99969, 103866, 79225, 41953, 103153, 86351, 79225, 41953, 95303, 198, 38409, 220, 18, 11, 3101, 482, 220, 22287, 482, 220, 18, 11, 24951, 198, 51, 4931, 220, 16, 11, 18485, 220, 14245, 220, 17306, 220, 9588, 220, 18, 11, 18070, 198, 101015, 220, 20, 11, 8610, 220, 14245, 220, 23305, 220, 9588, 220, 21, 11, 25747, 198, 2437, 720, 108214, 127038, 251, 350, 4931, 107896, 26799, 198, 18722, 67945, 21121, 58368, 113360, 101438, 103194, 74769, 71023, 104690, 18359, 102326, 108076, 43139, 55170, 84136, 34961, 107004, 44005, 350, 4931, 4233, 10274, 5364, 31414, 287, 744, 8, 117022, 59877, 106734, 83290, 11, 74769, 71023, 119182, 118450, 93851, 48936, 198, 120072, 54780, 106999, 107849, 82068, 111902, 60798, 23955, 16582, 17835, 104019, 101360, 103924, 13, 101604, 100654, 38187, 102296, 34804, 104350, 34983, 49085, 220, 972, 108609, 102467, 18359, 107896, 26799, 83290, 220, 845, 60861, 44690, 19954, 350, 4931, 117022, 59877, 198, 106734, 18359, 107123, 64356, 48936, 119623, 112373, 11, 67236, 100392, 102704, 107152, 220, 914, 60861, 44690, 17835, 103686, 67945, 48936, 126088, 80052, 627, 220, 62060, 21121, 58368, 113360, 101438, 103194, 74769, 71023, 104690, 320, 101353, 82001, 25, 101497, 97, 340, 89359, 80816, 220, 679, 23, 220, 679, 24, 220, 2366, 15, 220, 2366, 16, 119623, 198, 113624, 22035, 220, 5932, 220, 5925, 220, 5332, 220, 1490, 198, 104911, 86157, 57390, 101438, 220, 914, 220, 2983, 220, 15134, 220, 14261, 198, 103194, 44690, 86157, 57390, 101438, 220, 16, 11, 14649, 220, 16, 11, 13837, 220, 16, 11, 22000, 220, 24425, 198, 220, 62060, 21121, 58368, 113360, 103738, 103194, 74769, 71023, 104441, 103168, 49085, 320, 101353, 82001, 25, 21647, 5640, 12, 77535, 86157, 104690, 340, 89359, 80816, 220, 679, 23, 220, 679, 24, 220, 2366, 15, 220, 2366, 16, 119623, 198, 113624, 22035, 220, 15, 13, 16368, 220, 15, 13, 16037, 220, 15, 13, 11531, 220, 15, 13, 15901, 198, 104911, 86157, 57390, 101438, 220, 15, 13, 8759, 220, 15, 13, 11194, 220, 15, 13, 25210, 220, 15, 13, 21602, 198, 103194, 44690, 86157, 57390, 101438, 220, 15, 13, 6330, 220, 15, 13, 11256, 220, 15, 13, 10967, 220, 15, 13, 11515, 198, 55421, 102079, 38187, 32179, 198, 101314, 101151, 198, 7, 66965, 27797, 101151, 340, 100981, 101151, 198, 3100, 47815, 8, 32428, 34961, 110971, 198, 24140, 49085, 103131, 198, 101106, 38187, 110816, 198, 48424, 101963, 103131, 198, 101106, 38187, 110816, 198, 101090, 101963, 103131, 198, 101106, 38187, 110816, 198, 101711, 64189, 103131, 198, 101106, 38187, 110816, 198, 113735, 41953, 118408, 30381, 21121, 21121, 198, 109581, 29833, 102201, 41953, 60798, 198, 109581, 57519, 102937, 41953, 60798, 198, 109581, 104019, 30426, 111989, 198, 51, 4931, 117022, 107065, 106906, 101015, 198, 9, 99969, 103866, 79225, 41953, 551, 30027, 58260, 237, 231, 79225, 41953, 107896, 26799, 106446, 110097, 198, 9, 77800, 7, 65492, 32544, 70504, 59200, 8, 102546, 71682, 551, 66610, 101096, 125156, 57575, 113610, 44005, 105689, 44690, 86157, 57390, 123402, 87138, 82068, 116649, 231, 101518, 104613, 55421, 101661, 19954, 120561, 29833, 102249, 21121, 11, 105689, 44690, 78102, 101480, 34983, 24486, 36609, 25941, 102132, 80816, 43139, 82818, 116407, 32179, 56773, 16969, 62060, 21121, 58368, 113360, 75908, 22035, 58952, 71682, 720, 102757, 100660, 127812, 198, 101106, 38187, 110816, 93851, 48936, 30426, 14260, 49085, 127812, 64189, 198, 112699, 198, 127812, 79225, 101353, 198, 104156, 104152, 120380, 17835, 101003, 44966, 107205, 112780, 102133, 101412, 42529, 113624, 22035, 122733, 115754, 43139, 45618, 101607, 102823, 84656, 57002, 124534, 57575, 106906, 103655, 44005, 62060, 21121, 127812, 21028, 115489, 115602, 112219, 24140, 50764, 720, 106153, 119073, 103924, 13, 23955, 19954, 118951, 16969, 62060, 21121, 110998, 104690, 105633, 38187, 21028, 103686, 67945, 115839, 78102, 120380, 62060, 21121, 58368, 113360, 101438, 103194, 102678, 103655, 18359, 46810, 83290, 106434, 111850, 38187, 18918, 102258, 57390, 83290, 720, 61415, 20565, 35495, 103924, 13, 720, 58189, 100654, 38187, 102296, 34804, 112521, 102296, 77535, 86157, 125156, 57575, 113610, 44005, 105689, 44690, 86157, 57390, 101438, 79027, 87, 705, 110133, 86157, 57390, 101438, 3844, 46, 87, 705, 117892, 22035, 78102, 62060, 21121, 58368, 113360, 101438, 103194, 21028, 74769, 71023, 18359, 109720, 109816, 720, 67945, 21121, 127812, 18359, 74623, 101151, 67525, 46810, 83290, 118696, 102058, 116688, 55216, 102275, 109816, 103924, 627, 50643, 101015, 82068, 62060, 21121, 58368, 113360, 101438, 103194, 104019, 18918, 46810, 83290, 125959, 102612, 118909, 66406, 101090, 22035, 102260, 17155, 1932, 8, 17835, 62060, 21121, 58368, 113360, 101438, 103194, 74769, 71023, 102467, 101353, 121255, 66980, 101360, 117097, 11, 127063, 720, 93917, 102296, 220, 16, 122752, 124919, 45618, 100487, 112, 127038, 251, 43139, 74769, 71023, 107205, 105689, 44690, 86157, 57390, 101438, 11, 110133, 86157, 57390, 101438, 101824, 117892, 22035, 21028, 127141, 21028, 74769, 71023, 104690, 43139, 105178, 30381, 114409, 13, 101604, 100654, 38187, 102296, 34804, 23955, 104977, 198, 58901, 105178, 30381, 53400, 74769, 71023, 102467, 101353, 121255, 117210, 126951, 26799, 102244, 107896, 80732, 102893, 117177, 108859, 109642, 82068, 119864, 43139, 27796, 110080, 94801, 18359, 50467, 101360, 26799, 102058, 29854, 101360, 103924, 627, 67945, 21121, 58368, 113360, 101438, 103194, 104019, 198, 11192, 524, 6190, 220, 16, 1363, 27, 6190, 220, 17, 397, 11192, 1419, 198, 31460, 60939, 45176, 220, 2366, 16, 198, 33, 1372, 4292, 61094, 4874, 27597, 2818, 720, 66965, 122211, 16969, 102678, 109208, 44690, 109642, 102326, 102335, 18359, 107472, 720, 111966, 54780, 103684, 63171, 102296, 77535, 86157, 107316, 80052, 627, 58189, 100654, 38187, 102296, 13094, 720, 101464, 109208, 44690, 109642, 18918, 118667, 117403, 22720, 627, 107837, 102296, 124919, 121199, 57575, 74769, 71023, 107205, 7432, 17, 36609, 127230, 11, 220, 1954, 4, 106751, 34804, 101254, 17835, 100994, 30381, 43139, 103551, 74769, 71023, 116039, 103924, 13, 66610, 102296, 720, 16, 122752, 124919, 45618, 74769, 71023, 107205, 7432, 17, 104870, 18359, 116443, 108302, 11, 57519, 122211, 100994, 101661, 57575, 7432, 17, 74769, 71023, 104690, 34804, 101254, 17835, 100994, 101661, 21028, 106943, 220, 42973, 29833, 102611, 43139, 720, 93917, 56154, 116039, 103924, 13, 101254, 17835, 100994, 101661, 107031, 112521, 104176, 102080, 57575, 112521, 18359, 58935, 71023, 48936, 54718, 11, 105178, 57390, 107837, 123103, 118859, 109208, 7, 102525, 82233, 25941, 122369, 106359, 198, 83290, 105178, 123935, 102558, 120, 31495, 245, 16969, 3451, 66338, 55421, 529, 13094, 108289, 108859, 11, 55925, 106745, 62060, 104690, 21028, 7432, 17, 18918, 74769, 71023, 61938, 13, 62398, 104790, 57519, 122211, 100994, 101661, 107031, 112521, 101266, 198, 82233, 39519, 102, 18359, 57519, 122211, 107032, 34983, 79053, 43139, 115954, 112521, 18359, 63171, 93917, 127369, 11, 23955, 57519, 106647, 97096, 66965, 44690, 57575, 97096, 66965, 48936, 54718, 113610, 44005, 7432, 17, 20565, 57519, 21121, 198, 17835, 100994, 101661, 7432, 17, 74769, 71023, 104690, 21028, 127002, 18359, 103213, 22035, 61938, 13, 103055, 45618, 101838, 21028, 57519, 29854, 114702, 19954, 127887, 49085, 57519, 122211, 100994, 101661, 125904, 7432, 17, 198, 103588, 71023, 104690, 34804, 101254, 17835, 100994, 101661, 19954, 75086, 83290, 125590, 49085, 104182, 103607, 104429, 11, 103213, 102252, 101327, 58232, 77535, 91586, 105078, 22035, 78102, 75086, 57390, 102080, 91586, 105078, 22035, 21028, 57519, 29854, 64432, 102662, 19954, 720, 21028, 83290, 57519, 29854, 21028, 120326, 109208, 44690, 57390, 20565, 102464, 66965, 65219, 33390, 57519, 122211, 100994, 101661, 19954, 101787, 24486, 7432, 17, 74769, 71023, 104690, 34804, 127992, 102678, 103655, 113191, 123263, 13, 100027, 113631, 720, 55421, 64356, 21028, 29833, 102937, 108360, 42529, 25941, 57575, 113610, 44005, 7432, 17, 19954, 62060, 83290, 27796, 49085, 11, 127002, 120380, 57575, 112521, 80307, 45780, 223, 105, 39519, 102, 18359, 66610, 104684, 83290, 102888, 105991, 198, 27797, 44005, 57519, 122211, 107022, 50643, 20565, 11, 56773, 55421, 64356, 21028, 127002, 18359, 123102, 123103, 29833, 44966, 44005, 101254, 17835, 107022, 50643, 107988, 103123, 101347, 125590, 49085, 82068, 80052, 627, 100654, 38187, 109642, 16969, 102678, 109208, 44690, 109642, 59877, 102335, 18359, 46810, 83290, 112521, 102296, 124763, 124007, 21028, 124476, 81673, 48555, 223, 83628, 18359, 58935, 86351, 101360, 103924, 13, 57519, 112469, 21028, 720, 7459, 113, 102612, 34804, 46230, 58260, 225, 226, 44690, 74769, 71023, 100994, 30381, 32428, 101254, 17835, 100994, 112813, 57519, 122211, 100994, 30381, 43139, 57519, 66338, 44005, 103659, 117097, 11, 10013, 101824, 107449, 78102, 101585, 86351, 100654, 18359, 720, 101711, 102612, 43139, 100994, 30381, 21028, 57519, 66338, 18359, 103607, 110616, 104182, 58935, 86351, 72043, 80052, 13, 18657, 32, 7, 100654, 38187, 19954, 105078, 22035, 21121, 89359, 112574, 127614, 99901, 19954, 103386, 100968, 33390, 11, 106603, 100654, 198, 21028, 100994, 30381, 57519, 66338, 119623, 19954, 101787, 93292, 24486, 107285, 17835, 110452, 112521, 102296, 101096, 101015, 21028, 57519, 122211, 21028, 75086, 101711, 34804, 220, 679, 24, 100392, 220, 1682, 4, 57575, 220, 10866, 15, 100392, 108733, 220, 3226, 4, 101154, 198, 22035, 103686, 67945, 113191, 111590, 57519, 105115, 111320, 39331, 13, 122016, 58935, 42529, 18918, 64432, 102913, 114038, 101604, 100654, 38187, 102296, 21028, 120138, 63171, 102296, 100994, 28617, 67361, 57519, 122211, 100994, 101661, 198, 34804, 101412, 54542, 22035, 104762, 103684, 100994, 101661, 94801, 18359, 59777, 77437, 48936, 29833, 103924, 13, 23955, 19954, 101604, 100654, 38187, 102296, 34804, 103153, 115296, 57519, 122211, 100994, 101661, 18359, 102681, 24486, 112521, 102296, 112785, 720, 77535, 86157, 18359, 103686, 67945, 44005, 105512, 90759, 104508, 17835, 102678, 109208, 44690, 109642, 102326, 102335, 19954, 55216, 58126, 44005, 72208, 113781, 33229, 80732, 103655, 18359, 120693, 67890, 102130, 116669, 24486, 55216, 198, 101096, 18359, 108098, 21121, 46810, 83290, 102058, 29854, 16582, 115284, 13, 720, 84391, 17835, 110452, 57519, 122211, 100994, 101661, 720, 111372, 67945, 57519, 105115, 198, 58189, 100654, 38187, 102296, 57519, 122211, 124919, 19954, 122453, 720, 8445, 17, 113610, 102678, 103655, 122035, 7, 2366, 15, 100392, 8, 720, 35495, 17835, 100994, 101661, 54780, 57519, 122211, 100994, 101661, 21028, 720, 8445, 17, 74769, 71023, 122040, 64254, 116443, 198, 35495, 17835, 100994, 101661, 54780, 57519, 122211, 100994, 101661, 21028, 720, 93917, 102296, 220, 16, 122752, 65895, 7432, 17, 74769, 71023, 104690, 116443, 198, 679, 24, 198, 1682, 14062, 6028, 14062, 66965, 122211, 75086, 101711, 103686, 67945, 198, 10, 1591, 14062, 66965, 122211, 35495, 17835, 198, 16, 13, 20, 198, 22, 13, 18, 198, 8445, 17, 198, 20, 13, 23, 106113, 73653, 101497, 97, 198, 214, 220, 101254, 17835, 7, 4782, 37, 8, 2355, 214, 220, 57519, 122211, 10953, 8440, 340, 9, 8922, 551, 18657, 32, 11, 16979, 612, 12783, 12053, 9728, 2235, 7, 2366, 15, 13, 605, 340, 9, 105178, 30381, 111902, 551, 49456, 7, 35859, 80979, 106603, 100654, 127245, 72043, 32428, 126950, 101824, 103504, 102260, 64857, 101090, 45618, 61415, 29102, 58368, 8, 101824, 198, 96712, 7, 12060, 15, 100392, 120878, 44690, 101711, 102365, 103504, 102260, 104685, 33931, 19954, 126168, 126950, 64857, 101090, 45618, 61415, 29102, 58368, 198, 9, 8922, 551, 101604, 127463, 107837, 118909, 115202, 27796, 198, 7, 66965, 122211, 220, 605, 60861, 107022, 50643, 101824, 101254, 17835, 220, 19, 60861, 107022, 50643, 21028, 107715, 118909, 33931, 126052, 109581, 126470, 340, 9, 95303, 86157, 77437, 551, 101604, 100654, 38187, 102296, 21028, 57519, 122211, 100994, 101661, 19954, 101787, 24486, 66610, 102296, 124919, 104690, 865, 720, 7, 35495, 17835, 220, 16, 122752, 65895, 7432, 17, 74769, 71023, 104690, 1389, 57519, 122211, 220, 16, 122752, 65895, 7432, 17, 74769, 71023, 104690, 340, 3100, 46, 17, 107696, 73653, 101497, 97, 340, 89359, 80816, 7432, 17, 74769, 71023, 104690, 198, 7, 101584, 101497, 97, 7432, 17, 340, 93917, 102296, 124919, 104690, 198, 7, 73653, 101497, 97, 340, 16, 122752, 65895, 7432, 17, 103588, 71023, 104690, 198, 7, 122752, 7432, 17, 340, 66965, 122211, 107022, 50643, 220, 19, 11, 23619, 220, 16, 11, 24824, 220, 15, 13, 19, 198, 35495, 17835, 107022, 50643, 220, 10680, 11, 20478, 220, 22, 11, 25527, 220, 16, 13, 24, 198, 16, 13, 24, 83, 8445, 17, 198, 15, 13, 19, 83, 8445, 17, 198, 35495, 17835, 100994, 101661, 198, 66965, 122211, 100994, 101661, 198, 35495, 17835, 57519, 122211, 198, 107837, 21028, 106248, 66338, 125156, 198, 16, 13, 24, 3100, 2437, 122752, 14, 107837, 220, 16, 122752, 340, 15, 13, 19, 3100, 2437, 122752, 14, 107837, 220, 16, 122752, 340, 15, 13, 6268, 3100, 2437, 122752, 14, 107837, 220, 16, 122752, 340, 15, 13, 6268, 3100, 2437, 122752, 14, 107837, 220, 16, 122752, 340, 100654, 96318, 198, 116964, 113081, 198, 20565, 66965, 198, 127447, 101532, 198, 102914, 51440, 103194, 57575, 220, 15, 13, 1806, 3100, 2437, 122752, 14, 107837, 220, 16, 122752, 340, 48424, 55430, 57575, 220, 15, 13, 806, 3100, 2437, 122752, 14, 107837, 220, 16, 122752, 340, 34983, 104065, 198, 107837, 104176, 102080, 198, 220, 101254, 17835, 257, 57519, 122211, 198, 10866, 15, 198, 3226, 14062, 3391, 14062, 11192, 524, 6190, 220, 17, 1363, 27, 6190, 220, 18, 397, 11192, 1682, 198, 31460, 60939, 45176, 220, 2366, 16, 198, 33, 1372, 4292, 61094, 4874, 27597, 2818, 720, 2839, 198, 71682, 86157, 113624, 22035, 104019, 198, 18722, 58189, 100654, 38187, 102296, 34804, 102467, 64356, 39250, 35495, 101824, 124919, 79225, 30381, 57575, 113610, 44005, 75086, 86157, 113624, 22035, 63171, 93292, 18918, 46810, 83290, 112521, 80307, 45780, 223, 105, 39519, 102, 18359, 220, 16, 101532, 104182, 127959, 96318, 64432, 101106, 18359, 125744, 16582, 198, 35495, 117097, 11, 127959, 104065, 108332, 82068, 41953, 101824, 101254, 107837, 86503, 103097, 102772, 57519, 33390, 104657, 24140, 102546, 71682, 18918, 115426, 83290, 75086, 86157, 113624, 22035, 113610, 18359, 82273, 44690, 57390, 101360, 103924, 13, 112887, 11, 29833, 198, 102937, 121199, 57575, 113610, 44005, 75086, 86157, 113624, 22035, 102678, 103655, 18359, 46810, 83290, 101703, 17835, 105519, 44690, 103213, 104690, 18359, 107065, 108859, 11, 86503, 55421, 64356, 23955, 102937, 125156, 21028, 75086, 86157, 113624, 107054, 114528, 125986, 83290, 720, 104065, 64189, 17835, 74769, 71023, 119222, 51796, 108438, 104019, 101360, 103924, 13, 23955, 22817, 244, 109018, 75908, 86351, 102546, 71682, 101703, 44966, 101824, 118951, 20565, 56773, 49085, 44005, 95303, 104834, 106974, 38187, 116768, 78102, 118696, 720, 125561, 18359, 102681, 83290, 75086, 86157, 113624, 22035, 104019, 18918, 112521, 101464, 101709, 107973, 103924, 627, 2371, 198, 103222, 226, 108307, 104019, 198, 18722, 55430, 93292, 30426, 102546, 13094, 59777, 107519, 24486, 121772, 101824, 118089, 79225, 124788, 109299, 55430, 101607, 106001, 3396, 122, 234, 82068, 24486, 62060, 21121, 127812, 66610, 111490, 106958, 116990, 226, 108307, 101464, 103655, 58952, 71682, 36609, 58189, 101824, 102326, 108076, 720, 101555, 84136, 34961, 107004, 18359, 125744, 83290, 66610, 101096, 45618, 113610, 44005, 124763, 27797, 116990, 226, 108307, 18918, 82273, 44690, 57390, 83290, 104019, 101360, 103924, 627, 220, 120326, 114039, 58952, 71682, 103055, 104911, 198, 89359, 101968, 58952, 75086, 115426, 74623, 44690, 220, 2366, 16, 100392, 107896, 26799, 101136, 106446, 198, 32428, 101584, 79225, 41953, 24814, 94, 57002, 120326, 114039, 58952, 71682, 220, 4364, 122752, 63171, 102296, 220, 15, 13, 843, 108609, 102467, 198, 64189, 86157, 79225, 41953, 432, 5319, 9, 220, 105228, 356, 3218, 220, 23, 13, 1419, 108609, 102467, 198, 9, 432, 5319, 551, 110683, 55055, 77437, 101347, 44690, 86157, 57390, 41953, 60798, 7, 3561, 75989, 66726, 51715, 307, 3213, 705, 93621, 18918, 101228, 101930, 83290, 115809, 114039, 101438, 103194, 102678, 103655, 198, 2304, 198, 124767, 101824, 120081, 26799, 60798, 125287, 81673, 21028, 114080, 103168, 198, 18722, 58189, 100654, 38187, 102296, 34804, 106603, 115888, 114784, 100087, 24486, 67890, 26799, 50643, 101824, 118951, 64189, 102657, 81673, 74177, 113360, 101438, 103194, 74769, 71023, 101464, 103655, 65677, 102133, 82068, 114080, 103168, 18359, 34085, 118, 35495, 62060, 21121, 58368, 113360, 101824, 101412, 42529, 113624, 22035, 720, 101464, 103655, 18359, 46810, 83290, 82273, 101151, 21028, 102058, 116688, 55216, 102275, 109816, 103924, 627, 220, 118909, 106434, 120138, 114080, 103168, 198, 102546, 60798, 74623, 44690, 114080, 103168, 117534, 114080, 103168, 120072, 115888, 41953, 198, 57139, 42529, 113624, 22035, 102678, 103655, 65677, 102133, 82068, 114080, 103168, 220, 679, 22, 13, 2589, 13, 605, 13, 4056, 220, 2366, 16, 13, 717, 13, 2148, 13, 118909, 64189, 121772, 79225, 41953, 198, 67945, 21121, 58368, 113360, 101438, 103194, 65677, 102133, 82068, 103655, 106734, 109567, 103168, 220, 2366, 16, 13, 2371, 13, 975, 13, 4056, 220, 2366, 17, 13, 717, 13, 2148, 13, 116992, 103131, 67945, 21121, 127812, 102039, 121772, 79225, 41953, 198, 57390, 101438, 101532, 101412, 42529, 113624, 22035, 102678, 103655, 65677, 102133, 82068, 114080, 103168, 220, 2366, 16, 13, 2705, 13, 914, 13, 86503, 116992, 103131, 67945, 21121, 127812, 102039, 121772, 79225, 41953, 198, 77535, 87472, 98934, 55421, 11672, 52, 114080, 103168, 220, 679, 23, 13, 717, 13, 2304, 13, 4056, 220, 2366, 18, 13, 717, 13, 2148, 13, 67890, 26799, 50643, 99969, 103866, 79225, 41953, 198, 67945, 21121, 58368, 113360, 101438, 103194, 65677, 102133, 82068, 103655, 106734, 109567, 103168, 220, 679, 22, 13, 2589, 13, 605, 13, 4056, 220, 2366, 16, 13, 717, 13, 2148, 662, 103153, 86351, 30426, 102039, 103153, 86351, 79225, 41953, 198, 57139, 42529, 113624, 22035, 120295, 67945, 107011, 117526, 220, 679, 24, 13, 220, 806, 13, 86503, 118089, 30426, 118089, 79225, 41953, 198, 11192, 524, 6190, 220, 18, 1363, 27, 6190, 220, 19, 397, 11192, 1544, 198, 31460, 60939, 45176, 220, 2366, 16, 198, 33, 1372, 4292, 61094, 4874, 27597, 2818, 720, 16, 220, 118909, 18359, 44215, 101090, 21028, 76628, 24140, 36811, 44690, 17835, 59777, 77437, 101360, 11, 107036, 103123, 101015, 57575, 101834, 101151, 104182, 125714, 52976, 627, 17, 220, 120380, 104065, 118909, 63171, 101738, 107849, 105633, 81673, 114080, 103168, 18359, 108683, 24140, 101360, 116534, 21028, 118563, 102668, 18918, 122900, 119995, 16969, 29833, 102611, 118957, 111902, 18359, 66980, 101360, 23955, 101066, 52976, 627, 18, 220, 44215, 101090, 125561, 57519, 101738, 19954, 105701, 110218, 65677, 123645, 111516, 106304, 82068, 41820, 18359, 58935, 89359, 108859, 11, 67890, 102130, 103684, 74623, 126712, 102681, 83290, 106083, 101272, 20565, 25941, 113610, 18359, 109720, 13094, 108438, 102058, 29854, 52976, 627, 19, 220, 118909, 75086, 57002, 56154, 87472, 21028, 109562, 58232, 82068, 113610, 96451, 111490, 56069, 106356, 101360, 66610, 102436, 103684, 62060, 110685, 107011, 18359, 96677, 103304, 52976, 627, 20, 220, 117012, 46810, 83290, 103504, 102260, 18918, 29833, 102365, 14260, 101272, 101584, 108859, 11, 117210, 126951, 26799, 102244, 104414, 75908, 108308, 18359, 100994, 102260, 101360, 118909, 66406, 101090, 21028, 101585, 86351, 57390, 19954, 102058, 29854, 52976, 627, 2437, 198, 127812, 66406, 101090, 75908, 108308, 198, 18722, 58189, 100654, 38187, 102296, 34804, 67890, 102130, 116669, 24486, 108280, 127812, 102678, 109208, 44690, 119567, 59877, 102335, 18359, 46810, 83290, 106788, 126840, 105880, 102326, 101584, 61938, 627, 2371, 198, 127812, 105292, 26799, 102326, 82068, 198, 18722, 58189, 100654, 38187, 102296, 34804, 102293, 100392, 118909, 19954, 102597, 107896, 113798, 103686, 67945, 34983, 20565, 35495, 103924, 13, 119929, 102772, 101412, 42529, 113624, 22035, 102678, 103655, 19954, 102597, 109642, 82068, 110080, 94801, 18359, 116253, 35495, 123851, 198, 94772, 44215, 101090, 58126, 101868, 105220, 121048, 62060, 21121, 106434, 107896, 113798, 62060, 117960, 103686, 67945, 111320, 39331, 13, 220, 2366, 15, 100392, 118909, 105292, 26799, 71682, 27797, 34804, 110078, 107896, 26799, 71682, 21028, 220, 806, 4, 32428, 220, 6086, 108609, 720, 55421, 113743, 104429, 11, 57519, 100392, 62060, 71682, 220, 6086, 4, 103686, 67945, 111320, 39331, 627, 220, 118909, 105292, 26799, 102326, 82068, 101824, 103504, 102260, 320, 101353, 82001, 25, 80402, 113, 102467, 340, 89359, 101968, 220, 679, 23, 220, 679, 24, 220, 2366, 15, 220, 220, 2366, 16, 119623, 198, 110998, 107896, 26799, 71682, 220, 20596, 220, 19770, 220, 26439, 220, 16, 11, 17335, 198, 127812, 107896, 26799, 71682, 220, 975, 220, 1774, 220, 6086, 220, 7322, 198, 12, 62060, 21121, 220, 16, 13, 23, 220, 21, 13, 19, 220, 2131, 13, 16, 220, 5833, 13, 24, 198, 12, 29833, 103194, 220, 20, 13, 24, 220, 1987, 13, 15, 220, 16, 13, 20, 220, 20, 13, 17, 198, 12, 112922, 220, 21, 13, 15, 220, 15, 13, 22, 220, 914, 13, 19, 220, 914, 13, 15, 198, 2304, 198, 127812, 66406, 101090, 117022, 198, 18722, 77535, 86157, 125561, 72043, 113610, 125502, 118909, 58368, 113360, 18359, 96717, 101482, 101360, 11, 125461, 18918, 82273, 44690, 117216, 46810, 83290, 117022, 126470, 43139, 112521, 101464, 101709, 104019, 101360, 36439, 36630, 84136, 198, 13447, 13, 118909, 66406, 101090, 30426, 111989, 115878, 105633, 102079, 22705, 6860, 1721, 19954, 122453, 118909, 106974, 107744, 88708, 18359, 106906, 101015, 104182, 104019, 108859, 11, 103055, 41953, 6078, 81673, 101604, 100654, 102193, 108360, 42529, 25941, 198, 5549, 42, 4931, 124338, 108712, 88708, 83290, 57519, 56154, 102326, 108076, 100994, 101314, 20565, 125502, 5000, 117022, 18359, 59877, 106734, 111320, 39331, 627, 2839, 198, 127812, 66406, 101090, 58935, 86351, 66610, 102436, 198, 18722, 101930, 115888, 41953, 21028, 116281, 127812, 107560, 34804, 57519, 101738, 103684, 114291, 21028, 86888, 56773, 50643, 121803, 118909, 23955, 108093, 18918, 101327, 102130, 102893, 62060, 110685, 101360, 117097, 11, 56773, 21121, 103684, 57519, 56154, 720, 114294, 106906, 101015, 18918, 102681, 83290, 66610, 102436, 103684, 104019, 18918, 61816, 61415, 20565, 35495, 103924, 627, 220, 118909, 106434, 120138, 99105, 21028, 198, 89359, 220, 101968, 67236, 220, 107032, 198, 101193, 66965, 127812, 102326, 100981, 26799, 99105, 21028, 57519, 56154, 118909, 101193, 66965, 106434, 23955, 108093, 106313, 109070, 99105, 21028, 7, 79225, 41953, 39623, 107235, 109317, 99105, 21028, 340, 102837, 101272, 20565, 25941, 114080, 21028, 50643, 101968, 21121, 102517, 57519, 56154, 74769, 71023, 104690, 55170, 84136, 34961, 107004, 11, 103185, 106734, 127561, 100994, 101314, 101824, 120138, 23955, 108093, 106313, 109070, 99105, 21028, 198, 101193, 66965, 127812, 117526, 57519, 56154, 118909, 14, 101193, 66965, 14, 42771, 101868, 127042, 106974, 11, 118951, 118909, 30381, 107011, 107849, 105633, 62060, 110685, 78102, 198, 9, 622, 11673, 78102, 120380, 104065, 120138, 112521, 102296, 56154, 81673, 101585, 86351, 118909, 101193, 66965, 104019, 21121, 101661, 100994, 101314, 18918, 107472, 101999, 99029, 114294, 29833, 30426, 111809, 72043, 198, 79596, 198, 8445, 46, 198, 32428, 101584, 79225, 41953, 41953, 99969, 103866, 79225, 41953, 41953, 103153, 86351, 79225, 41953, 41953, 118089, 79225, 41953, 41953, 198, 32428, 101584, 79225, 41953, 720, 101193, 66965, 127812, 107560, 198, 101796, 103866, 79225, 41953, 198, 101193, 66965, 127812, 107560, 198, 65895, 86351, 79225, 41953, 198, 101193, 66965, 127812, 107560, 198, 64189, 86157, 79225, 41953, 198, 116281, 127812, 107560, 198, 58189, 101738, 109567, 29854, 101272, 41953, 198, 101193, 66965, 66338, 116853, 107656, 107560, 198, 65677, 55421, 104019, 198, 6806, 19954, 105078, 22035, 66406, 101090, 30426, 111989, 101703, 44966, 198, 6806, 91586, 105078, 22035, 11, 106083, 101272, 20565, 25941, 127042, 104019, 50643, 101015, 59877, 106734, 198, 19954, 105078, 22035, 127042, 104019, 198, 6806, 118562, 26799, 55421, 11, 29833, 26799, 55421, 11, 74177, 113360, 101438, 103194, 104019, 198, 21121, 102252, 104449, 57390, 62060, 110685, 198, 6806, 120878, 44690, 66406, 101090, 58083, 115777, 104019, 198, 6806, 55216, 102252, 104449, 57390, 58083, 115777, 62060, 110685, 198, 89359, 101968, 119502, 118433, 119502, 120072, 115888, 41953, 198, 25141, 220, 6860, 1721, 198, 2366, 15, 13, 2545, 13, 1187, 13, 4056, 220, 2366, 18, 13, 2545, 13, 1419, 13, 426, 14137, 121772, 79225, 41953, 198, 679, 23, 13, 2371, 13, 2839, 13, 4056, 220, 2366, 19, 13, 2371, 13, 2437, 13, 426, 14137, 99969, 103866, 79225, 41953, 198, 679, 24, 13, 2545, 13, 975, 13, 4056, 220, 2366, 17, 13, 2545, 13, 1032, 13, 426, 14137, 103153, 86351, 79225, 41953, 198, 2366, 16, 13, 2839, 13, 868, 13, 4056, 220, 2366, 19, 13, 2839, 13, 975, 13, 735, 7934, 118089, 79225, 41953, 198, 11192, 524, 6190, 220, 19, 1363, 27, 6190, 220, 20, 397, 11192, 966, 198, 31460, 60939, 45176, 220, 2366, 16, 198, 33, 1372, 4292, 61094, 4874, 27597, 2818, 720, 58189, 100654, 38187, 102296, 34804, 65677, 55421, 106869, 66338, 109642, 102326, 102335, 19954, 55216, 58126, 67525, 46810, 83290, 112785, 124919, 121199, 57575, 113610, 107205, 118089, 123402, 65677, 55421, 43139, 102888, 105991, 27797, 101360, 118562, 21121, 198, 101438, 113610, 18359, 82273, 44690, 57390, 67525, 107472, 102058, 116688, 121856, 20565, 35495, 103924, 13, 125590, 101347, 121199, 57575, 113610, 107205, 101254, 107837, 34804, 57519, 104690, 57519, 122211, 66610, 101096, 125156, 19954, 102888, 105292, 44966, 198, 83290, 102467, 58232, 64356, 17835, 120952, 101360, 117097, 11, 63171, 102296, 121199, 57575, 113610, 44005, 116865, 103684, 118089, 101438, 32428, 63171, 102296, 112640, 54542, 49706, 16969, 108280, 127812, 112785, 43139, 119502, 107094, 54059, 720, 116353, 27797, 99969, 41953, 113907, 58232, 122733, 116453, 65677, 55421, 43139, 102888, 105991, 27797, 101360, 103924, 13, 55925, 22817, 244, 21028, 118089, 101438, 32428, 112521, 20565, 102268, 106612, 87472, 21028, 114528, 101266, 107213, 33177, 3269, 484, 25635, 8, 54780, 720, 38187, 102296, 101968, 86351, 49085, 102888, 105991, 27797, 82158, 83290, 65677, 55421, 106869, 66338, 19954, 23955, 101974, 22035, 101360, 103924, 627, 121509, 24486, 11, 116686, 102888, 105991, 27797, 119222, 110661, 118562, 21121, 101438, 19954, 112107, 101151, 102293, 102365, 11, 101228, 101930, 82158, 18918, 82273, 44690, 57390, 67525, 106958, 3451, 64189, 86157, 101438, 65677, 55421, 57390, 106304, 529, 18359, 125959, 102612, 66406, 101090, 22035, 102260, 198, 17155, 1932, 8, 17835, 101585, 30381, 83290, 104019, 101360, 103924, 13, 122016, 102058, 29854, 43139, 118089, 101438, 65677, 55421, 57390, 106304, 34804, 220, 679, 23, 100392, 220, 3264, 13, 19, 4, 57575, 220, 2366, 15, 100392, 220, 3264, 13, 15, 4, 102704, 720, 22035, 102130, 104182, 124208, 101360, 103924, 13, 720, 220, 118089, 101438, 65677, 55421, 57390, 102326, 82068, 220, 320, 101353, 82001, 25, 63207, 101497, 97, 340, 89359, 101968, 220, 679, 23, 220, 679, 24, 220, 2366, 15, 198, 102133, 48918, 220, 5495, 13, 20, 220, 2495, 13, 23, 220, 3226, 13, 21, 198, 58232, 105991, 27797, 14, 103079, 101518, 220, 5538, 13, 20, 220, 2813, 13, 23, 220, 3487, 13, 20, 198, 26799, 55421, 57390, 106304, 220, 3264, 13, 19, 4, 220, 3264, 13, 22, 4, 220, 3264, 13, 15, 14062, 9, 113610, 35495, 107837, 63171, 104065, 53400, 104870, 43139, 102888, 86157, 30381, 198, 220, 118089, 101438, 113610, 75086, 106304, 7, 2366, 15, 100392, 111902, 8, 256, 118089, 101438, 21028, 107032, 114976, 102888, 105991, 27797, 103055, 104911, 198, 58232, 105991, 27797, 107032, 49085, 75086, 72043, 198, 33931, 14260, 98934, 101665, 27797, 113907, 58232, 220, 2031, 14062, 35495, 17835, 86503, 55421, 64356, 220, 717, 14062, 54059, 101347, 99105, 24140, 220, 605, 14062, 118561, 220, 21, 14062, 64189, 86157, 101438, 113610, 104690, 198, 3226, 13, 21, 73653, 122752, 198, 80816, 86351, 262, 220, 605, 4, 720, 125986, 96318, 57390, 101438, 198, 17, 14062, 86157, 57390, 107837, 256, 220, 20, 4, 720, 101518, 102365, 14260, 44690, 101930, 198, 17, 14062, 38187, 102296, 112640, 54542, 49706, 198, 2614, 14062, 54059, 101347, 28955, 2910, 551, 127265, 112574, 81685, 198, 38187, 102296, 112640, 54542, 49706, 102888, 105991, 27797, 198, 66965, 122211, 10953, 8440, 114484, 49508, 101347, 28955, 2910, 122369, 102888, 105991, 27797, 44005, 103659, 107120, 66653, 238, 29102, 41820, 107205, 100994, 30381, 80052, 13, 57519, 122211, 100994, 30381, 72043, 113610, 107205, 101968, 86351, 21028, 56773, 33931, 80816, 198, 34804, 112521, 80816, 54780, 49508, 101347, 112373, 11, 23955, 101968, 86351, 21028, 106943, 220, 966, 4, 18918, 103213, 22035, 44005, 49508, 101347, 34804, 58935, 71023, 54780, 63171, 103304, 104219, 112813, 101429, 110218, 106327, 49508, 101347, 49085, 101136, 102296, 103079, 18359, 124919, 44005, 720, 107837, 102296, 49085, 101136, 79225, 41953, 43139, 110110, 36092, 113, 22720, 13, 124919, 53400, 49508, 101347, 49085, 101136, 102296, 103079, 34804, 103213, 104690, 11, 36609, 66965, 38187, 101696, 78102, 19954, 41820, 116039, 29833, 126546, 50467, 83290, 101254, 107837, 13094, 98243, 33390, 50467, 198, 30426, 57519, 122211, 100994, 112813, 102681, 83290, 102888, 109208, 77535, 114409, 13, 720, 38187, 102296, 112640, 54542, 49706, 16969, 101703, 17835, 99969, 41953, 27797, 113907, 58232, 17835, 102888, 105991, 27797, 116039, 103924, 13, 101703, 17835, 55216, 102156, 34804, 102681, 57002, 104182, 55170, 54542, 11, 65677, 111282, 11, 117452, 102080, 105718, 107340, 101347, 65677, 55421, 65950, 198, 18359, 36609, 79225, 83290, 41820, 118768, 101604, 100654, 38187, 102296, 21028, 57519, 122211, 58952, 71682, 57575, 113610, 107205, 118089, 101438, 32428, 63171, 102296, 112640, 54542, 49706, 20565, 117012, 62060, 50643, 79053, 43139, 115954, 107340, 101347, 112542, 58232, 720, 56154, 27797, 103185, 44690, 19954, 106725, 118909, 116231, 120, 111270, 75908, 22035, 19954, 55216, 58126, 101360, 103924, 13, 720, 257, 49508, 101347, 81685, 57575, 101604, 100654, 38187, 102296, 21028, 103135, 48936, 198, 118561, 220, 220, 1032, 4, 720, 127812, 64189, 108280, 127812, 112785, 119502, 198, 38187, 102296, 112640, 54542, 49706, 198, 116353, 101796, 41953, 113907, 58232, 57575, 720, 38187, 102296, 112640, 54542, 49706, 102888, 105991, 27797, 115483, 82001, 6394, 14336, 21121, 102156, 10, 42771, 93917, 21121, 102156, 529, 107340, 101347, 112542, 58232, 62060, 50643, 58232, 720, 67945, 50643, 198, 20627, 243, 198, 20627, 243, 198, 143, 251, 20627, 243, 198, 41814, 239, 143, 251, 20627, 243, 198, 73319, 239, 20627, 243, 198, 66965, 122211, 198, 32428, 101584, 14, 101796, 103866, 198, 79225, 41953, 198, 54059, 101347, 49085, 101136, 198, 102296, 103079, 79225, 41953, 198, 64189, 86157, 79225, 41953, 198, 54059, 101347, 103948, 71023, 79225, 41953, 49508, 101347, 38187, 103304, 79225, 41953, 198, 54059, 101347, 57, 77, 80816, 86351, 198, 35495, 107837, 49508, 101347, 49085, 101136, 102296, 103079, 198, 24140, 36811, 20565, 198, 64189, 86157, 101438, 102888, 105991, 27797, 198, 11192, 524, 6190, 220, 20, 1363, 27, 6190, 220, 21, 397, 11192, 2705, 198, 31460, 60939, 45176, 220, 2366, 16, 198, 33, 1372, 4292, 61094, 4874, 27597, 2818, 720, 127702, 120417, 720, 35, 647, 123736, 12609, 198, 122695, 44215, 108955, 29854, 21028, 198, 11907, 720, 66048, 8351, 198, 6280, 19, 100392, 23955, 126276, 21028, 5251, 120, 230, 67945, 103551, 106327, 101852, 103430, 90759, 55000, 101574, 101954, 55925, 106745, 11, 720, 100981, 115584, 107988, 112521, 102296, 13094, 113531, 90960, 90759, 62398, 105453, 33229, 80732, 103655, 43139, 198, 58189, 100654, 38187, 102296, 34804, 120380, 82273, 103719, 107138, 63375, 112521, 102296, 119398, 18359, 101852, 117984, 39331, 13, 720, 3080, 100392, 13094, 121066, 109296, 11, 101604, 100654, 38187, 102296, 34804, 720, 42529, 101015, 30426, 115096, 101585, 49085, 44005, 58083, 102913, 17835, 101834, 127038, 251, 28867, 108, 39331, 627, 107837, 34804, 102258, 61938, 13, 720, 107837, 34804, 49508, 64254, 109659, 39331, 627, 102296, 105297, 7, 103229, 104443, 8, 1084, 55421, 117035, 54780, 101327, 122628, 18918, 126470, 43139, 720, 107011, 94801, 66406, 101090, 18359, 107123, 24140, 101360, 101787, 56154, 121469, 21028, 101327, 102130, 33931, 54780, 720, 102436, 123645, 44215, 108955, 116688, 108652, 103430, 198, 64189, 100654, 7, 105469, 101257, 8, 5996, 116194, 44966, 54780, 107478, 21028, 82068, 101228, 102233, 43139, 720, 57139, 54542, 18918, 119225, 124295, 198, 66406, 101090, 101482, 108308, 198, 125462, 102335, 104911, 198, 127702, 80732, 101604, 100654, 38187, 102296, 56773, 77437, 127702, 198, 102546, 102365, 33177, 220, 6280, 19, 100392, 220, 22, 100551, 220, 22, 33177, 198, 124270, 13094, 56154, 102027, 42529, 114768, 86503, 62841, 41953, 11, 102155, 101347, 110616, 33229, 41953, 198, 113735, 96318, 27797, 112521, 102296, 14, 103222, 231, 101347, 102296, 103079, 63171, 93917, 101824, 116604, 198, 26799, 101948, 101136, 220, 20, 11, 24110, 108609, 102467, 198, 102757, 101096, 55421, 29833, 220, 17, 11, 21239, 80732, 198, 102133, 101066, 55430, 77437, 107152, 29833, 220, 2721, 11, 16739, 11, 22039, 55430, 198, 26799, 86157, 220, 20, 93917, 220, 17, 11, 21038, 108609, 102467, 198, 101948, 56154, 101228, 58232, 22035, 127929, 72043, 89359, 117615, 22035, 17835, 20, 106103, 220, 777, 720, 7, 24140, 16582, 58189, 11, 106960, 104221, 101109, 103430, 340, 57139, 54542, 66406, 101090, 198, 32428, 58232, 66406, 101090, 198, 25941, 102477, 30446, 66406, 101090, 198, 107011, 94801, 66406, 101090, 114171, 29102, 66406, 101090, 198, 105469, 101257, 198, 103229, 104443, 198, 64189, 198, 100654, 198, 102296, 198, 105297, 198, 11192, 524, 6190, 220, 21, 1363, 27, 6190, 220, 22, 397, 11192, 2148, 198, 31460, 60939, 45176, 220, 2366, 16, 198, 33, 1372, 4292, 61094, 4874, 27597, 2818, 720, 1721, 720, 24140, 26799, 55421, 102888, 105991, 27797, 198, 18722, 58189, 100654, 38187, 102296, 34804, 103738, 65677, 123645, 115489, 111490, 59777, 77437, 101360, 118562, 24140, 102888, 105991, 27797, 110578, 57002, 101824, 75908, 99029, 24140, 29833, 103194, 104019, 18918, 120138, 104019, 101090, 101577, 43139, 101585, 30381, 83290, 93851, 198, 29102, 101360, 103924, 13, 101604, 100654, 38187, 102296, 21028, 99969, 103866, 14260, 32428, 101584, 79225, 124788, 118562, 24140, 101480, 101482, 99029, 74769, 71023, 45618, 102546, 18359, 116253, 103948, 35495, 117097, 41820, 107205, 107032, 125546, 220, 1041, 4, 18918, 102888, 198, 105991, 27797, 101360, 103924, 627, 220, 100994, 41953, 102517, 107032, 24140, 102888, 105991, 27797, 111652, 7, 2366, 15, 100392, 111902, 8, 320, 101353, 82001, 25, 63207, 101497, 97, 340, 89359, 101968, 100994, 102662, 104690, 102888, 105991, 27797, 104690, 102888, 105991, 27797, 111652, 198, 32428, 101584, 79225, 41953, 220, 11128, 220, 11128, 220, 1041, 14062, 101796, 103866, 79225, 41953, 220, 10125, 220, 10125, 220, 1041, 14062, 65895, 86351, 79225, 41953, 220, 1313, 220, 18, 220, 975, 14062, 64189, 86157, 79225, 41953, 220, 14378, 220, 3080, 220, 1682, 14062, 22254, 58260, 237, 231, 79225, 41953, 220, 18, 13, 17, 220, 18, 13, 17, 220, 1041, 14062, 220, 100994, 41953, 102517, 29833, 103194, 58368, 113360, 101438, 103194, 74769, 71023, 119182, 49085, 7, 2366, 15, 100392, 111902, 340, 220, 39623, 45780, 237, 238, 24140, 75908, 99029, 104690, 101824, 29833, 103194, 58368, 113360, 101438, 103194, 74769, 71023, 119182, 49085, 198, 89359, 101968, 220, 679, 23, 220, 679, 24, 220, 2366, 15, 220, 2366, 16, 119623, 198, 36092, 45780, 237, 238, 24140, 75908, 99029, 104690, 198, 7, 73653, 101497, 97, 340, 65895, 86351, 220, 16, 13, 17, 220, 16, 13, 18, 220, 16, 13, 17, 220, 16, 13, 18, 198, 64189, 86157, 220, 15966, 220, 679, 220, 9714, 220, 16, 220, 5313, 198, 103588, 71023, 119182, 49085, 198, 1278, 70, 14, 15284, 241, 340, 65895, 86351, 198, 33, 2114, 482, 220, 17, 13, 20, 220, 16, 13, 24, 220, 16, 13, 17, 198, 34891, 220, 22, 13, 24, 220, 21, 13, 24, 220, 23, 13, 17, 220, 21, 198, 64189, 101314, 101438, 103194, 220, 20, 220, 24, 13, 18, 220, 1114, 13, 21, 220, 22, 13, 19, 198, 11079, 220, 22, 13, 18, 220, 22, 13, 20, 220, 22, 13, 23, 220, 22, 13, 24, 198, 64189, 86157, 198, 33, 2114, 220, 17, 13, 23, 220, 18, 13, 19, 220, 20, 13, 19, 220, 19, 13, 16, 198, 34891, 220, 777, 220, 1691, 220, 1627, 220, 972, 198, 64189, 101314, 101438, 103194, 220, 19, 13, 19, 220, 17, 13, 18, 220, 18, 13, 20, 220, 17, 13, 16, 198, 11079, 220, 22, 13, 19, 220, 21, 13, 24, 220, 22, 13, 16, 220, 22, 13, 19, 198, 71682, 101838, 58368, 113360, 55421, 102678, 103655, 30426, 102546, 198, 65895, 86351, 79225, 41953, 21028, 100994, 101096, 27797, 24140, 101824, 120376, 27797, 125546, 50152, 11, 55000, 24140, 102757, 198, 104508, 102657, 29102, 41953, 43139, 101003, 44966, 102657, 29102, 65219, 61415, 11, 106354, 41381, 24140, 101106, 21028, 50152, 198, 102772, 82818, 13447, 17835, 75908, 99029, 113191, 29833, 22817, 122226, 120078, 13, 103153, 86351, 79225, 124788, 720, 34983, 101927, 77535, 87472, 101015, 64432, 109074, 19954, 105547, 254, 24486, 115809, 101090, 104762, 49085, 104519, 120, 60798, 22035, 51796, 21121, 720, 82001, 83290, 101703, 17835, 102058, 33390, 21028, 74177, 113360, 101438, 103194, 13094, 101834, 101584, 45618, 82818, 13447, 17835, 105164, 198, 101482, 99029, 107205, 107387, 75908, 22035, 101360, 26799, 3451, 71682, 101838, 58368, 113360, 55421, 101464, 103655, 30426, 102546, 123956, 18359, 102681, 54780, 83290, 74769, 71023, 101360, 103924, 13, 95713, 102678, 103655, 30426, 102546, 67236, 720, 58126, 58232, 16969, 102293, 100392, 101999, 50643, 108859, 11, 101834, 101584, 45618, 19954, 45618, 102546, 101838, 109070, 11, 78453, 220, 16, 62841, 720, 24140, 103194, 123297, 120908, 125744, 101360, 103924, 627, 71682, 101838, 101464, 103655, 30426, 102546, 34804, 107152, 220, 20, 60861, 44690, 320, 22035, 16582, 100087, 8, 720, 3356, 26478, 40417, 105, 142, 243, 142, 247, 66977, 245, 1830, 20627, 243, 198, 20627, 243, 198, 20627, 243, 198, 20627, 251, 198, 66977, 245, 1830, 20627, 243, 198, 20627, 243, 198, 20627, 251, 198, 66977, 245, 1830, 20627, 243, 198, 64189, 86157, 79225, 41953, 198, 77535, 101438, 57390, 100508, 82068, 720, 86157, 44690, 36811, 89359, 104690, 5462, 2114, 340, 57390, 100508, 82068, 720, 86157, 44690, 36811, 89359, 104690, 3100, 2114, 340, 64189, 101314, 101438, 103194, 104690, 198, 1490, 13, 15, 198, 19, 13, 17, 198, 1954, 13, 15, 198, 868, 13, 22, 198, 1490, 13, 15, 198, 16, 13, 24, 198, 65895, 86351, 79225, 41953, 198, 77535, 101438, 57390, 100508, 82068, 720, 86157, 44690, 36811, 89359, 104690, 5462, 2114, 340, 57390, 100508, 82068, 720, 86157, 44690, 36811, 89359, 104690, 3100, 2114, 340, 64189, 101314, 101438, 103194, 104690, 198, 1135, 13, 15, 220, 1272, 13, 15, 198, 23, 13, 17, 220, 17, 13, 806, 13, 24, 198, 1490, 13, 15, 198, 9, 103153, 86351, 79225, 124788, 33229, 104065, 55000, 24140, 102657, 29102, 41953, 82273, 102757, 82158, 95415, 75908, 99029, 198, 9, 118089, 79225, 124788, 120307, 107065, 44005, 118562, 24140, 102657, 29102, 41953, 57575, 118909, 111902, 60798, 23955, 16582, 104019, 95415, 75908, 99029, 198, 214, 220, 107849, 82068, 118152, 198, 214, 220, 220, 2366, 15, 100392, 102326, 82068, 198, 2437, 198, 77535, 101438, 13447, 101927, 33931, 64432, 109074, 198, 18722, 64189, 86157, 79225, 124788, 59777, 104152, 61816, 101577, 21028, 29833, 103194, 19954, 101412, 116129, 126652, 82273, 44690, 57390, 67525, 46810, 83290, 65677, 50643, 118562, 24140, 102657, 29102, 30426, 102546, 18359, 107065, 101360, 117097, 11, 118562, 24140, 16969, 220, 16, 101532, 720, 101438, 29102, 14260, 57390, 100508, 82068, 82158, 18918, 101429, 60798, 35495, 11, 101003, 21121, 101438, 13094, 52072, 101314, 53400, 118562, 24140, 16969, 48918, 101438, 100508, 82068, 82158, 18918, 102681, 83290, 220, 17, 101532, 82158, 124005, 13, 220, 16, 11, 220, 17, 101532, 82158, 53400, 118562, 24140, 16969, 720, 104156, 102757, 125986, 24140, 102657, 29102, 30426, 102546, 18359, 101429, 110218, 107849, 82068, 111902, 60798, 23955, 16582, 17835, 75908, 99029, 114409, 13, 103153, 86351, 79225, 41953, 21028, 50152, 102772, 33229, 104065, 55000, 24140, 102757, 104508, 102657, 29102, 41953, 43139, 101003, 44966, 102657, 29102, 198, 116039, 117097, 11, 106603, 115888, 124788, 29833, 103194, 58368, 113360, 101438, 103194, 21028, 74769, 71023, 119182, 118450, 107849, 82068, 108785, 27797, 118152, 21028, 220, 1135, 4, 23955, 16582, 29833, 102611, 43139, 103504, 102260, 18918, 29833, 102365, 83290, 104019, 16582, 198, 35495, 103924, 627, 24140, 26799, 55421, 104019, 198, 11192, 524, 6190, 220, 22, 1363, 27, 6190, 220, 23, 397, 11192, 1644, 198, 31460, 60939, 45176, 220, 2366, 16, 198, 33, 1372, 4292, 61094, 4874, 27597, 2818, 720, 21121, 102252, 104449, 57390, 720, 83146, 10604, 198, 21121, 102252, 104449, 57390, 16969, 91767, 74177, 54542, 66965, 103551, 57519, 110572, 20565, 103153, 33390, 24486, 104219, 38187, 112373, 11, 55216, 102252, 104449, 57390, 62060, 110685, 19954, 103607, 110616, 103684, 102058, 116688, 55216, 102275, 105870, 120903, 50152, 115888, 198, 19954, 67890, 113760, 126652, 101412, 119866, 63207, 118009, 126728, 23955, 108093, 20565, 117455, 20565, 35495, 103924, 13, 10013, 16969, 220, 679, 24, 100392, 220, 717, 100551, 7997, 27359, 126950, 18359, 117870, 111320, 35495, 11, 720, 10866, 15, 100392, 102704, 120878, 44690, 101711, 102365, 37707, 59794, 102326, 102335, 54780, 102519, 106138, 32179, 120878, 44690, 100654, 66406, 42529, 37707, 14319, 15545, 18918, 101703, 44966, 83290, 120878, 44690, 50467, 104690, 74769, 71023, 109916, 198, 18918, 125590, 104706, 101360, 120326, 102080, 109208, 101824, 102888, 77535, 19954, 105078, 22035, 64432, 102662, 103686, 124784, 107472, 59777, 106634, 102199, 102914, 63171, 118450, 74623, 104790, 44005, 78102, 106603, 102757, 111850, 38187, 101193, 18359, 96677, 103304, 101360, 103924, 13, 720, 13094, 61394, 24486, 115878, 82068, 122040, 64254, 19954, 101604, 113825, 83290, 104008, 118951, 49085, 69332, 100392, 3451, 10866, 15, 120878, 44690, 101711, 102365, 529, 18359, 101585, 105198, 111320, 104429, 11, 101604, 100654, 38187, 102296, 18359, 110097, 24486, 120380, 112521, 102296, 101096, 198, 101015, 49085, 3451, 49706, 102423, 107837, 102296, 117526, 529, 102722, 108860, 18359, 102681, 83290, 124695, 43139, 120878, 44690, 101711, 102365, 103504, 102260, 104685, 33931, 55216, 58126, 18918, 46810, 83290, 102058, 29854, 101360, 103924, 13, 101604, 100654, 38187, 102296, 34804, 23955, 198, 81673, 110192, 60861, 17835, 55216, 102252, 104449, 57390, 107651, 19954, 111516, 106304, 104182, 62060, 102657, 67525, 46810, 83290, 106434, 23955, 108093, 18918, 56069, 106356, 24486, 95415, 46810, 102005, 111490, 109862, 101360, 62060, 110685, 57519, 112469, 18359, 29833, 102365, 198, 83290, 86888, 101360, 103924, 13, 106083, 101272, 20565, 25941, 114080, 21028, 50643, 18918, 102681, 83290, 55216, 102252, 104449, 57390, 62060, 110685, 114291, 18359, 101968, 21121, 102517, 17835, 114080, 21028, 101360, 11, 106083, 101272, 20565, 25941, 59777, 28617, 45780, 228, 254, 106064, 720, 89359, 106734, 83290, 102293, 100551, 107036, 115888, 41953, 21028, 106083, 101272, 20565, 25941, 3844, 2474, 220, 16, 11, 36020, 220, 17, 8, 74769, 71023, 104690, 18359, 104019, 101360, 103924, 627, 1721, 720, 21121, 102252, 104449, 57390, 62060, 110685, 106906, 101015, 101824, 66610, 102436, 198, 18722, 58189, 100654, 38187, 102296, 34804, 101604, 101738, 109567, 29854, 101272, 105178, 16582, 21028, 3451, 102837, 101272, 20565, 25941, 114080, 21028, 50643, 529, 18918, 114702, 83290, 57519, 56154, 101532, 123645, 91586, 105078, 22035, 44215, 101090, 101482, 108308, 18359, 29833, 102365, 83290, 86888, 101360, 36439, 36630, 198, 22720, 13, 2437, 720, 21121, 102252, 104449, 57390, 58083, 115777, 101824, 55216, 62841, 36811, 32428, 109862, 198, 18722, 58189, 100654, 38187, 102296, 34804, 55216, 102252, 104449, 117216, 119864, 21028, 120138, 44215, 101090, 23955, 108093, 17835, 106478, 101353, 101360, 11, 107285, 17835, 110452, 55216, 102252, 104449, 57390, 107651, 19954, 103607, 110616, 62060, 102657, 101360, 26799, 109670, 13, 55216, 102252, 104449, 57390, 720, 107752, 82233, 101824, 55216, 62841, 36811, 123486, 111850, 38187, 82068, 118408, 33390, 11, 103738, 29102, 82068, 118408, 33390, 78102, 43139, 119670, 101360, 11, 106603, 23955, 108093, 19954, 102597, 62060, 110685, 101482, 101193, 18359, 29833, 102365, 111320, 39331, 627, 220, 23955, 108093, 56069, 106356, 101824, 58083, 115777, 62060, 110685, 75908, 101193, 198, 107752, 82233, 62060, 110685, 101482, 101193, 55216, 62841, 36811, 32428, 198, 105633, 38187, 82068, 198, 115394, 33390, 198, 102837, 101272, 20565, 25941, 74769, 71023, 103131, 106792, 74769, 71023, 104690, 102678, 103655, 101824, 74769, 71023, 103131, 106792, 38187, 62060, 110685, 50643, 101015, 59877, 106734, 198, 6806, 106083, 101272, 20565, 25941, 74769, 71023, 103131, 103686, 42771, 198, 6806, 118711, 57139, 115896, 112785, 116604, 103686, 67945, 198, 6806, 108280, 127812, 101327, 113735, 102464, 71023, 198, 6806, 91586, 105078, 22035, 111516, 106304, 107034, 106687, 102467, 20565, 104834, 103655, 198, 6806, 108280, 127812, 119502, 101824, 116604, 102657, 103686, 67945, 198, 6806, 108280, 127812, 112521, 102296, 119864, 127501, 63171, 35495, 198, 109208, 44690, 42529, 109916, 102517, 126950, 55170, 84136, 34961, 107004, 101824, 62060, 110685, 50643, 101015, 59877, 106734, 198, 26799, 55421, 106869, 66338, 114213, 101661, 118089, 101438, 65677, 55421, 57390, 103686, 67945, 101824, 112521, 80307, 45780, 223, 105, 39519, 102, 41820, 107034, 67945, 198, 101438, 29102, 82068, 198, 115394, 33390, 198, 21121, 57002, 13094, 104449, 120307, 125461, 115888, 41953, 102517, 124110, 58232, 34983, 96717, 101482, 117022, 59877, 102335, 720, 21121, 57002, 13094, 104449, 105131, 107519, 125461, 100994, 102662, 105115, 125461, 62060, 110685, 111373, 101824, 116604, 102657, 50467, 104449, 57390, 198, 118561, 119864, 101971, 103079, 117210, 126951, 26799, 108742, 121389, 84136, 119175, 93131, 102258, 57390, 198, 79596, 198, 58189, 101738, 109567, 29854, 101272, 41953, 198, 102837, 101272, 20565, 25941, 114080, 21028, 50643, 198, 32428, 101584, 79225, 41953, 198, 101193, 66965, 127812, 107560, 198, 101796, 103866, 79225, 41953, 198, 101193, 66965, 127812, 107560, 198, 65895, 86351, 79225, 41953, 198, 101193, 66965, 127812, 107560, 198, 64189, 86157, 79225, 41953, 198, 101193, 66965, 127812, 107560, 198, 101193, 66965, 66338, 116853, 107656, 107560, 198, 11192, 524, 6190, 220, 23, 1363, 27, 6190, 220, 24, 397, 11192, 1032, 198, 31460, 60939, 45176, 220, 2366, 16, 198, 33, 1372, 4292, 61094, 4874, 27597, 2818, 720, 66406, 101090, 101272, 82068, 198, 23030, 21304, 198, 1721, 720, 2366, 15, 100392, 44215, 101090, 127812, 101824, 103153, 56154, 62060, 110685, 198, 18722, 66965, 110572, 124141, 777, 103686, 86157, 43139, 119567, 125561, 19954, 103213, 103194, 13094, 113610, 111320, 104429, 11, 127063, 107285, 17835, 110452, 112521, 102296, 126918, 109018, 115809, 101090, 104762, 18359, 56773, 101461, 198, 39331, 13, 112780, 18359, 63171, 104065, 24486, 107285, 17835, 110452, 112521, 102296, 29833, 36811, 104690, 34804, 220, 679, 24, 100392, 62060, 71682, 220, 1032, 4, 103185, 44690, 111320, 104429, 11, 112521, 104176, 102080, 112994, 34804, 220, 679, 24, 100392, 62060, 198, 71682, 220, 17, 13, 18, 103588, 117208, 102278, 111320, 39331, 13, 29833, 102662, 102786, 103931, 102193, 43139, 59777, 24486, 107285, 17835, 110452, 112521, 102296, 126918, 21028, 112662, 50643, 21121, 105220, 121048, 101604, 100654, 38187, 102296, 34804, 57519, 122211, 720, 13094, 101838, 18359, 120952, 24486, 29833, 36811, 30426, 41953, 19954, 102597, 101003, 101347, 24486, 100994, 41953, 20565, 58189, 62060, 110685, 54780, 101254, 24140, 108964, 112785, 116604, 103686, 124784, 102681, 83290, 96270, 30381, 103684, 29833, 108964, 198, 18359, 107478, 71023, 111320, 39331, 627, 66965, 122211, 720, 109208, 29854, 82068, 36609, 58189, 198, 16582, 127240, 36609, 66965, 121735, 61394, 720, 103079, 101518, 103686, 67945, 198, 35495, 24140, 108964, 112785, 720, 103079, 101518, 103686, 67945, 198, 107837, 104176, 102080, 112994, 198, 7, 104684, 61394, 14, 122752, 340, 8848, 198, 6330, 198, 5120, 198, 1399, 198, 23424, 198, 679, 21, 198, 24061, 198, 679, 22, 198, 25822, 198, 679, 23, 198, 24061, 198, 679, 24, 198, 23901, 198, 2366, 15, 198, 84391, 17835, 110452, 112521, 102296, 29833, 36811, 198, 7, 106113, 73653, 101497, 97, 340, 11192, 524, 6190, 220, 24, 29, 128009, 128006, 882, 128007, 198, 103194, 52688, 25, 356, 18, 12, 17, 12, 17, 13, 67890, 103588, 89359, 93917, 87097, 44690, 81673, 106434, 83290, 116100, 107744, 88708, 72043, 111530, 102888, 102436, 101360, 65621, 127798, 19954, 95713, 107205, 113914, 109659, 18359, 87138, 34983, 92769, 1462, 16, 2432, 57002, 41953, 119398, 73653, 113914, 109659, 8, 100994, 30381, 79225, 30426, 38187, 118450, 108683, 24140, 101360, 65621, 20565, 1980, 108728, 512, 681, 16, 8, 57519, 113048, 49706, 104977, 22035, 31495, 232, 13447, 518, 364, 17, 8, 106943, 63375, 49706, 104977, 22035, 31495, 232, 13447, 518, 364, 18, 8, 64432, 102233, 101568, 518, 364, 19, 8, 106943, 63375, 49706, 104977, 13447, 518, 364, 20, 8, 121520, 49706, 104977, 13447, 663, 128009, 128006, 78191, 128007, 198, 104152, 93292, 25, 115036, 99901, 107031, 101604, 100654, 38187, 102296, 13094, 100994, 30381, 79225, 30426, 38187, 118450, 108683, 24140, 101360, 65621, 22035, 19954, 102597, 120307, 103684, 61139, 20565, 108273, 119222, 116154, 39331, 13, 101604, 100654, 38187, 102296, 21028, 118909, 101824, 44215, 101090, 102326, 82068, 11, 67890, 102130, 116669, 44215, 101090, 75908, 108308, 78102, 19954, 102597, 61139, 73653, 110097, 106910, 103924, 627, 109659, 104449, 25, 102066, 29833, 127409, 13, 128009]\n"
     ]
    }
   ],
   "source": [
    "print('입력에 대한 정수 인코딩 결과:')\n",
    "print(batch[\"input_ids\"][0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "377f9f21-5caa-417c-b549-cae18348809e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "input_ids 디코딩 결과:\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "당신은 주어진 질문에 대해서 검색 결과, 질문, 보기를 바탕으로 답변해야 합니다.\n",
      "답변할 때는 근거:를 먼저 작성하고 답변:을 작성하십시오.\n",
      "검색 결과를 바탕으로 답변할 수 없는 경우에는 근거:에 검색 결과에 질문에 대한 답을 알 수 있는 내용이 없다고 설명하고 답변: 알 수 없음이라고 적으세요. 반드시 '알 수 없음'이라고 적어야 합니다.\n",
      "\n",
      "### 예시 ###\n",
      "근거: 삼양홀딩스는 직원들의 복리후생과 업무환경 개선에 많은 노력을 기울이고 있습니다. 사내에서 아침, 점심, 저녁을 무료로 제공하는 구내 식당과 피트니스 센터 운영을 통해 임직원의 건강을 지원하고 있으며, 카페테리아 및 다양한 편의시설을 제공하여 여유와 휴식을 취할 수 있는 환경을 마련하고 있습니다 (문서 0). 또한, 삼양홀딩스는 직원들이 일과 생활의 균형을 유지할 수 있는 유연근무제를 도입하여 직원들이 가장 편리한 시간에 근무할 수 있도록 하고 있습니다 (문서 0). 이러한 점들을 고려할 때, 삼양홀딩스는 쾌적한 근무환경을 제공하고 있다고 평가할 수 있습니다.\n",
      "답변: '5) 매우그렇다\n",
      "\n",
      "검색 결과:\n",
      "<document 0>\n",
      "---\n",
      "ABOUT THIS REPORT\n",
      "본 보고서는 고객, 직원, 주주, 투자자 등 이해관계자들에게 동국제강의 \n",
      "환경경영 정보를 제공하기 위하여 발행하였습니다. 동국제강은 철강\n",
      "기업으로서 ‘자원순환 사회’ 및 ‘저탄소 사회’ 실현에 공헌하는 것을 환경\n",
      "과제로 삼고 있으며, 이러한 활동과 성과에 대한 정보를 중심으로 구성\n",
      "하고 있습니다.\n",
      "보고범위\n",
      "동국제강 본사 및 국내 사업장(인천공장, 포항공장, 부산공장, 당진공장, \n",
      "신평공장)의 활동과 성과를 담고 있습니다.\n",
      "보고기간\n",
      "2020년 1월 1일 ~ 2020년 12월 31일 동안의 활동 내용을 주로 담고 \n",
      "있으며, 환경개선 효과를 비교하기 위하여 과거 수 개년 동안의 실적과 \n",
      "향후 목표를 함께 수록하였습니다.\n",
      "본 보고서는 지속가능경영보고서의 국제표준 가이드라인인 GRI(Global \n",
      "Reporting Initiative) Standards, TCFD 등의 환경부문에 대한 기준을 \n",
      "반영하여 작성하였습니다. 보고서 내 재무 성과는 한국채택국제회계기\n",
      "준(K-IFRS)으로 작성하였습니다.\n",
      "서울특별시 중구 을지로5길 19(수하동, 페럼타워)\n",
      "문의 02-317-1114   \n",
      "홈페이지 www.dongkuk.com\n",
      "철을 되살리다\n",
      "생명을 되살리다\n",
      "---\n",
      "</document 0>\n",
      "\n",
      "<document 1>\n",
      "---\n",
      "28\n",
      "ENVIRONMENT REPORT 2021\n",
      "BETTER LIFE WITH STEEL \n",
      "01 \n",
      "SCR 투자\n",
      " -\n",
      "동국제강은 정부의 친환경정책에 적극적으로 동참하여, 철강 생산과정에서 발생하는 질소산화물의 배출을 저감하고\n",
      "자 2020년 부산에 소재한 신평공장의 가열로에 SCR설비를 도입하여 질소산화물 배출을 약 80% 저감시키는 등 SCR \n",
      "설비의 효과를 검증한 바 있습니다. 이에 추가적으로 포항공장 형강생산라인의 가열로에 SCR설비 1기를, 부산공장의 \n",
      "용융아연도금(CGL) 생산라인에 4기의 SCR 설비를 도입하기로 결정하였습니다. 투자금액은 37억  원 수준이며 이를 \n",
      "통하여 질소산화물 저감 목표를 달성토록 할 것입니다. \n",
      "  대기관리권역법 관련 투자액 (단위: 백만 원)\n",
      "구분 부산공장 인천공장 포항공장 당진공장 계\n",
      "SCR 3,300 - 548 - 3,848\n",
      "TMS 1,920 430 355 320 3,025\n",
      "계 5,220 430 903 320 6,873\n",
      "02 \n",
      "굴뚝 TMS 투자\n",
      " -\n",
      "대기오염물질 배출량을 실시간으로 모니터링하는 TMS(Tele-Monitoring System) 시스템 구축하여, 배출농도를 관할\n",
      "기관과 함께 법적 기준치 이하로 관리하고 있습니다. 동국제강은 올해도 18억 원을 투자하여 16개소에 TMS 시스템 구\n",
      "축을 완료할 계획이며, 내년까지 총 25개소로 확대할 예정입니다.\n",
      "  대기오염물질 배출량 (단위: 톤)\n",
      "구분 2018 2019 2020 2021 계획\n",
      "먼지 81 91 72 80\n",
      "황산화물 25 42 311 228\n",
      "질소산화물 1,030 1,080 1,028 972\n",
      "  대기오염 물질 배출 집약도 (단위: kg/t-생산량)\n",
      "구분 2018 2019 2020 2021 계획\n",
      "먼지 0.013 0.015 0.012 0.014\n",
      "황산화물 0.004 0.007 0.053 0.039\n",
      "질소산화물 0.160 0.178 0.176 0.167\n",
      "원격제어\n",
      "유선\n",
      "(전용선)\n",
      "무선\n",
      "(CDMA)인터넷\n",
      "수도권\n",
      "관제센터\n",
      "호남권\n",
      "관제센터\n",
      "영남권\n",
      "관제센터\n",
      "중부권\n",
      "관제센터\n",
      "사업장 측정기기\n",
      "자료 수집장치\n",
      "자료 전송장치\n",
      "자료 관리시스템\n",
      "TMS 시스템 운영 체계\n",
      "* 포항공장 : 신평공장 투자액 포함\n",
      "* SCR(Selective Catalytic Reduction)설비 : 조업 과정에서 발생하는 질소산화물을 선택적 촉매 환원법에 의해 수증기, 질소 등 무해한 가스 성분으로 바꾸어 주는 대기오염 방지 설비 \n",
      "종합환경\n",
      "관제센터 관할시·도환경부\n",
      "한국\n",
      "환경공단\n",
      "최근 국내로 유입되는 중국발 미세먼지 등의 영향으로 시민들이 일상생활에서 체감하는 대기환경의 중요성이 갈수록 \n",
      "커지고 있습니다. 이에 정부는 대기총량규제의 확대 적용 등 국내 대기오염물질 저감을 위하여 관련 규제를 강화하여 \n",
      "나가고 있습니다. \n",
      "동국제강은 철강생산 과정에서 발생하는 질소산화물(NOx), 황산화물(SOx), 먼지 등 대기오염물질의 배출을 줄이고 \n",
      "대기환경을 개선하기 위하여 다양한 노력을 기울이고 있습니다.\n",
      "체계적 대기오염물질 관리를 위하여 핵심 환경경영지표(KPI)로 대기오염물질 배출 원단위를 설정하고 있으며, 이는 \n",
      "조강 1톤 생산 시 굴뚝으로 배출되는 질소산화물, 황산화물 및 먼지의 각각의 배출량으로 산정됩니다. 동국제강은 이렇\n",
      "게 산정된 배출 원단위를 이해관계자에게 투명하게 공개하며 사회적 기업으로서 책임을 다하고자 노력하고 있습니다.\n",
      "대기오염물질 관리\n",
      "---\n",
      "</document 1>\n",
      "\n",
      "<document 2>\n",
      "---\n",
      "23\n",
      "ENVIRONMENT REPORT 2021\n",
      "BETTER LIFE WITH STEEL \n",
      "전기로는 저탄소 사회 실현을 위한 \n",
      "효과적인 제강생산 방법입니다.\n",
      "동국제강이 \n",
      "저탄소 사회를 만들어 갑니다.\n",
      "철강 생산과정에서 배출되는 CO2 가운데, 90% 이상은 고로 공정으로부터 배출되고 있습니다. 조강 \n",
      "1톤 생산 시 배출되는 CO2 양을 비교하면, 전기로 공법에서 CO2 배출량은 고로 공법의 약 ¼ 수준으로 \n",
      "조사되고 있습니다. 고로 공법에서는 철광석에서 철을 추출할 때, 산화철로부터 석탄(코크스)을 이용\n",
      "하여 산소를 빼앗는 ‘환원’이 필요하며, 그때 대량의 CO2를 배출합니다. 한편 전기로 공법에서는 철 스\n",
      "크랩을 전기로 용해함으로써 철을 제조하는데, 이 전기를 발전소에서 발전할 때 발생하는 CO2가 전기\n",
      "로 공법 CO2 배출량의 대부분을 차지합니다. 현 시점의 전력 구성에 있어서도 전기로 공법에서의 CO2\n",
      "배출량은 고로 공법에 비하여 압도적으로 적으며, 차후 신재생 에너지 등 비화석 에너지의 전력 보급에 \n",
      "의하여 전력의 탈탄소화가 진전되면 전기로 공법에 의한 CO2 배출량은 더욱 저감될 것입니다. 게다가 \n",
      "원료의 수송 프로세스에서 발생하는 CO2에 대하여서도, 대부분 국내에서 철 스크랩을 조달하여 재활\n",
      "용하는 전기로 업체가, 주원료의 대부분을 해외로부터 수입하는 고로 업체보다 단연 압도적입니다.\n",
      "국제 사회는 저탄소 사회 구현을 위하여 철강 산업 구조의 변화와 혁신을 추진하고 있습니다. 전략의 \n",
      "핵심은 고탄소 배출 공정인 고로 공정을 전기로 공정으로 전환하는 데 있으며, EU 및 미국 등 선진국을 \n",
      "중심으로 공정의 전환을 적극적으로 추진 중입니다. IEA(국제에너지기구)의 조사 결과에 따르면, 각국\n",
      "의 공정 전환 계획에 의거한 글로벌 철강업계의 전기로의 비중은 2019년 29%에서 2050년엔 57%까\n",
      "지 확대될 것으로 전망하였습니다. 이러한 추세를 보더라도 동국제강의 주요 제강 공법인 전기로 공법\n",
      "은 미래지향적인 공법임을 인식할 수 있습니다. 이에 동국제강은 당사의 전기로 공법을 통한 철강 제품 \n",
      "생산을 확대하는 것이야말로 저탄소 사회 실현에 기여하는 것이라는 사명감을 가지고 지속가능한 기\n",
      "업을 만들기 위하여 노력하겠습니다. \n",
      "글로벌 전기로 공법 \n",
      "확대 전망\n",
      "동국제강 전기로 생산에 따른 \n",
      "CO2 발생 저감 효과(2020년) \n",
      "고로 공법과 전기로 공법의 \n",
      "CO2 배출 흐름 비교\n",
      "고로 공법과 전기로 공법의 \n",
      "조강 1톤당 CO2 배출량 비교\n",
      "2019\n",
      "29%\n",
      "71%\n",
      "전기로 비중 확대\n",
      "+28%\n",
      "전기로고로\n",
      "1.5\n",
      "7.3\n",
      "CO2\n",
      "5.8백만 톤\n",
      "\u001a  고로(BOF)  \n",
      "\u001a  전기로(EAF)\n",
      "* Source : IEA, Iron & Steel Technology Roadmap(2020.10)\n",
      "* 산정 기준 : STEP(현재 각국 시행 중인 정책 및 목표 반영 시나리오) 및\n",
      " SDS(2070년 탄소중립 목표 달성에 필요한 정책 반영 시나리오\n",
      "* Source : 동경제철 환경보고서\n",
      "(전기로 10개 업체 및 고로 4개 업체의 일본 환경성 제출자료 기반)\n",
      "* 계산식 : 동국제강의 전기로 공법에 의한 조강 생산량 x \n",
      "(고로 1톤당 CO2 배출량 – 전기로 1톤당 CO2 배출량)\n",
      "(CO2 백만 톤)\n",
      "구분 CO2 배출량\n",
      "(천 톤 CO2)\n",
      "조강 생산량\n",
      "(만 톤)\n",
      "1톤당 CO2배출량\n",
      "(톤 CO2)\n",
      "전기로 업체 4,747 1,058 0.4\n",
      "고로 업체 165,064 7,738 1.9\n",
      "1.9tCO2\n",
      "0.4tCO2\n",
      "고로 공법\n",
      "전기로 공법\n",
      "고로 전기로\n",
      "철의 순환 과정\n",
      "1.9(C02톤/철 1톤)\n",
      "0.4(C02톤/철 1톤)\n",
      "0.003(C02톤/철 1톤)\n",
      "0.003(C02톤/철 1톤)\n",
      "국내\n",
      "빌딩\n",
      "가전\n",
      "자동차\n",
      "브라질에서 0.37(C02톤/철 1톤)\n",
      "호주에서 0.11(C02톤/철 1톤)\n",
      "해외\n",
      "철광석\n",
      "  고로     전기로\n",
      "2050\n",
      "57%\n",
      "43%\n",
      "---\n",
      "</document 2>\n",
      "\n",
      "<document 3>\n",
      "---\n",
      "29\n",
      "ENVIRONMENT REPORT 2021\n",
      "BETTER LIFE WITH STEEL \n",
      "03\n",
      "비산먼지 관리\n",
      " -\n",
      "동국제강은 원료 입고 및 생산공정에서 발생하는 비산먼지 제거를 위하여 철 스크랩을 1차적으로 옥내 보관을 실시하\n",
      "고 있으며, 옥외 야적장 및 고철 부두에는 전면 살수설비를 설치하여 비산먼지 발생을 최소화하고 있습니다. 또한, 수\n",
      "송과정에서 발생하는 비산먼지 저감을 위하여 도로 청소 차량을 운영하며, 부원료 이송 과정의 비산먼지는 밀폐하여 \n",
      "외부로 배출되지 않도록 관리하고 있습니다. 이 밖에도 방진설비 도입 및 정부가 주도하는 계절관리제 참여 등 다양한 \n",
      "활동을 통하여 비산먼지 관리를 철저히 하고 있습니다.\n",
      "04\n",
      "냄새 관리\n",
      " -\n",
      "주거시설이 인접한 인천 및 부산공장은 지역주민들의 쾌적한 대기환경 조성을 위해 냄새저감 설비 가동 및 실시간 \n",
      "모니터링을 실시하여 조업 시 발생하는 산업용 냄새를 최소화하여 관리하고 있습니다.\n",
      "  탈취 설비 현황\n",
      "구 분 설 비 설치 개소 2021년 투자금액\n",
      "인천공장 액상 탈취 설비 120톤 제강 0.32억 원\n",
      "부산공장 RTO*  全 CCL 8.23억 원\n",
      "* RTO : 축열식연소산화장치(Regenerative Thermal Oxidizer), VOC를 소각하여 악취물질 저감\n",
      "05\n",
      "정부 및 지방자치단체와의 협약\n",
      " -\n",
      "동국제강은 각 사업장이 위치한 지자체 및 정부부처와 오염물질 배출저감 자발적 협약을 맺고 대기오염 및 미세먼지 \n",
      "저감을 위하여 최선의 노력을 기울이고 있습니다.\n",
      "  환경 관련 주요 협약\n",
      "설치 개소 협약기간 협약기관 사업장\n",
      "미세먼지 저감 자발적 협약 2017.07.10. ~ 2021.12.31. 환경부 인천공장\n",
      "대기오염물질 자발적감축협약 2021.04.14. ~ 2022.12.31. 수도권대기환경청 인천공장\n",
      "화물차 미세먼지 저감 자발적 협약 2021.06.25. 부 수도권대기환경청 인천공장\n",
      "생태복원 MOU 협약 2018.12.05. ~ 2023.12.31. 지자체 포항공장\n",
      "대기오염물질 자발적감축협약 2017.07.10. ~ 2021.12.31 . 당진시청 당진공장\n",
      "미세먼지 특별대책위원회 2019. 11. 부 부산시 부산공장\n",
      "---\n",
      "</document 3>\n",
      "\n",
      "<document 4>\n",
      "---\n",
      "27\n",
      "ENVIRONMENT REPORT 2021\n",
      "BETTER LIFE WITH STEEL \n",
      "1  환경을 경영의 필수요소로 인식하고, 모든 단계에서 우선적으로 고려한다.\n",
      "2  국내외 환경 제반 법규와 협약을 준수하고 고객의 니즈를 만족시키는 수준 높은 기준을 설정하고 이행한다.\n",
      "3  경영활동 전반에 걸쳐 자원의 효율적 사용을 추구하며, 지속적인 개선을 통하여 온실가스 발생을 줄이도록 노력한다.\n",
      "4  환경 비상사태의 잠재적 발생 가능성을 파악하고 조직적인 대응책을 마련한다.\n",
      "5  이를 위하여 목표를 수립·실천하며, 이해관계자에게 본 방침을 공표하고 환경경영의 선진화에 노력한다.\n",
      "02\n",
      "환경경영 방침\n",
      " -\n",
      "동국제강은 지속가능한 친환경 저탄소 경제 구현을 위하여 다음 사항들을 실천합니다.\n",
      "04\n",
      "환경투자 실적\n",
      " -\n",
      "동국제강은 매년 환경에 대한 투자를 확대해가고 있습니다. 최근에는 미세먼지 저감에 대한 사회적 책임을 갖고 어려\n",
      "운 경영여건 속에서도 대기 관련 투자를 대폭 확대하였습니다. 2020년 환경투자비용은 전체 투자비의 11%인 82억 \n",
      "원이었으며, 전년 대비 82% 확대하였습니다.\n",
      "  환경투자 실적 및 목표 (단위: 억 원)\n",
      "구 분 2018 2019 2020  2021 계획\n",
      "총 투자비 438 418 759 1,291\n",
      "환경 투자비 14 45 82 115\n",
      "- 대기 1.8 6.4 55.1 84.9\n",
      "- 수질 5.9 38.0 1.5 5.2\n",
      "- 기타 6.0 0.7 25.4 25.0\n",
      "05\n",
      "환경경영 시스템\n",
      " -\n",
      "생산활동 중 발생 가능한 환경오염을 예방하고, 피해를 최소화를 위하여 시스템 기반으로 철저히 관리하고 있습니\n",
      "다. 환경경영시스템 국제규격 ISO14001에 따른 환경관리 항목을 체계적으로 관리하며, 현장 DB와 동국형 프로세스\n",
      "(DKMS)를 접목하여 전사 실시간 공유가 가능한 Web 시스템을 구축하였습니다.\n",
      "03\n",
      "환경경영 추진 조직\n",
      " -\n",
      "각 사업장의 안전환경팀은 전반적인 활동의 실행 주체로서 환경 이슈를 신속하게 대응하고 있으며, 주기적인 전사 \n",
      "회의 체계를 통하여 조직적인 관리를 해나가고 있습니다.\n",
      "  환경 관련 주요 회의\n",
      "구  분 내  용\n",
      "안전환경 실무자 회의 전사 환경안전 관련 이슈 점검 회의(공장 오프라인 회의)\n",
      "온실가스 협의체 분기별 전사 배출량 모니터링, 감축기술 공유 및 주요 이슈 점검 회의\n",
      "안전환경위원회 전사 환경/안전/보건 통합관리, 정부 환경정책 법규 대응 등\n",
      "* JFE 등 국내외 주요 철강사와 선진 환경안전 관리기법 공유를 위한 교류회의 수시 진행 중\n",
      "CEO\n",
      "COO\n",
      "인천공장장 포항공장장 당진공장장 부산공장장\n",
      "인천공장 \n",
      "안전환경팀\n",
      "포항공장\n",
      "안전환경팀\n",
      "당진공장\n",
      "안전환경팀\n",
      "부산공장\n",
      " 안전환경팀\n",
      "동반협력실장\n",
      "안전환경기획팀\n",
      " 자원 관리\n",
      "•에너지경영시스템 도입\n",
      "• 에너지, 온실가스 통합 관리체계 구축\n",
      "에너지 통합 관리\n",
      "• 폐자원, 수자원, 오염물질 관리\n",
      "기후변화 대응\n",
      "• 탄소경영 리스크 관리\n",
      "• 기후변화 리스크 대응\n",
      "구 분 인증 기간 인증기관 사업장\n",
      "ISO 14001\n",
      "2020.09.24. ~ 2023.09.23. BSI 인천공장\n",
      "2018.04.03. ~ 2024.04.02. BSI 포항공장\n",
      "2019.09.14. ~ 2022.09.13. BSI 당진공장\n",
      "2021.03.15. ~ 2024.03.14. KSA 부산공장\n",
      "---\n",
      "</document 4>\n",
      "\n",
      "<document 5>\n",
      "---\n",
      "30\n",
      "ENVIRONMENT REPORT 2021\n",
      "BETTER LIFE WITH STEEL \n",
      "동국제강은 자원순환 사회 실현에 기여하기 위하여 제품 생산과정에서 발생되는 부산물을 자원으로 재활용하고 폐기\n",
      "물 발생을 최소화하기 위한 노력을 이어가고 있습니다. 압연과정에서 발생되는 고철은 전량 전기로 조업 과정에 재투입\n",
      "하여 원재료로 활용하고 있으며, 제강과정에서 발생하는 대표적인 부산물인 제강 슬래그는 친환경 제품으로 인증받아 \n",
      "도로용 포장 골재 등의 새로운 자원으로 재활용하고 있습니다. 그 밖의 부산물인 철가루 형태의 밀 스케일(Mill Scale)과 \n",
      "제강 분진도 재활용 처리하여 자원순환에 이바지하고 있습니다.\n",
      "또한, 일부 재활용되지 않는 폐기물에 대해선 매립, 소각 처리를 최소화하기 위해 ‘부산물 자원화율’을 핵심경영지표\n",
      "(KPI)로 선정하여 관리하고 있습니다. 이러한 노력으로 부산물 자원화율은 2018년 98.4%에서 2020년 98.0%까지 \n",
      "지속적으로 유지하고 있습니다. \n",
      "  부산물 자원화 실적  (단위: 만 톤)\n",
      "구 분 2018 2019 2020\n",
      "발 생 63.5 78.8 57.6\n",
      "재활용/판매 62.5 77.8 56.5\n",
      "자원화율 98.4% 98.7% 98.0%\n",
      "* 발생고철 제외된 양으로 재산정\n",
      "  부산물 발생 비율(2020년 기준)   부산물의 용도별 재활용 현황\n",
      "재활용 용도 비 중\n",
      "성·복토용 골재 70%\n",
      "고로 부원료 12%\n",
      "아연 회수 10%\n",
      "기타 6%\n",
      "부산물 발생량\n",
      "57.6만톤\n",
      "분진    10% \n",
      "폐내화물\n",
      "2%\n",
      "산화철   5% \n",
      "매립·소각\n",
      "2%\n",
      "제강 슬래그\n",
      "68%\n",
      "아연(Zinc : Zn)의 Recycling\n",
      "제강 슬래그 재활용\n",
      "전기로(EAF)는 아연(Zinc)을 재활용하는 데 가장 널리 사용되는 공정입니다. 전기로 공정 중 발생되는 분진의 주성분\n",
      "은 철분과 아연이며, 이 분진의 약 30%를 차지하는 아연은 추출과 제련 과정을 거쳐 다시 아연도금강판을 생산하는 \n",
      "철강도금공장으로 돌아옵니다. 생산된 아연도금강판은 차량, 가전제품 등에 사용되고 수명을 다하여 고철이 되면 다\n",
      "시 전기로 공정을 통하여 재탄생됩니다. \n",
      "제강 슬래그는 도로 포장용 골재로 재활용되고 있습니다. 도로 기층은 통상적으로 모래, 자갈, 암석 같은 천연 자원들\n",
      "을 가공하여 사용하지만 동국제강의 전기로 설비에서 발생되는 부산물인 제강 슬래그가 이를 대체함으로써 천연골재 \n",
      "사용 감소에 따라 환경 훼손 방지에 기여하고 있습니다. \n",
      "     아연 Recycling에서 동국제강의 역할\n",
      "기타  13% \n",
      "환경부 친환경 제품 인증\n",
      "제강 슬래그\n",
      "도로포장 골재에서 \n",
      "제강 슬래그 재활용 범위 :\n",
      "‘기층+보조기층’ 천연골재 대체재 \n",
      "대체\n",
      "க\n",
      "க\n",
      "ӝக\n",
      "ઑӝக\n",
      "૑க\n",
      "전기로\n",
      "인천/포항\n",
      "공장\n",
      "아연도금\n",
      "강판공장\n",
      "부산공장\n",
      "아연추출공장 아연제련공장\n",
      "아연Zn분진\n",
      "고철 아연도금강판\n",
      "수요가\n",
      "부산물 재활용\n",
      "---\n",
      "</document 5>\n",
      "\n",
      "<document 6>\n",
      "---\n",
      "06\n",
      "ENVIRONMENT REPORT 2021\n",
      "BETTER LIFE WITH STEEL \n",
      "회사소개 \n",
      "Dongkuk Profile\n",
      "최고 경쟁력의\n",
      "Global \n",
      "Steel Company\n",
      "1954년 이 땅의 뼈대부터 다시 세워야 하였던 그때, \n",
      "무엇보다 철강이 바로 서야 한다는 사명감으로\n",
      "동국제강은 국내 최초 민간 철강기업을 세웠습니다. \n",
      "67년이 지난 지금, 동국제강은 \n",
      "세계시장을 선도하는 리더로 우뚝 섰습니다.\n",
      "철은 강합니다. \n",
      "철은 아름답습니다.\n",
      "강병(强兵)    \n",
      "원칙과 신뢰를 기반으로 \n",
      "책임경영을 완수하고 의사 결정의 신속성과 \n",
      "직원의 경쟁력을 키워\n",
      "부국(富國)   \n",
      "몰입과 창의적 소통으로 \n",
      "미래를 준비하자\n",
      "경영방침\n",
      "일반현황\n",
      "회사명 동국제강 주식회사\n",
      "설립일 1954년 7월 7일\n",
      "대표이사 장세욱 부회장, 김연극 사장\n",
      "사업내용 철강/냉연강판 제조 및 판매\n",
      "자본금 5,892억 원\n",
      "종업원 수 2,544명\n",
      "발행주식 총 수 95,432,737주\n",
      "자산 5조 2,495억 원\n",
      "본사 소재지 서울특별시 중구 을지로5길 19 \n",
      "(수하동, 페럼타워)\n",
      "미래경영\n",
      "인재경영\n",
      "스피드경영\n",
      "책임경영윤리경영\n",
      "富國\n",
      "强兵\n",
      "부\n",
      "국\n",
      "강\n",
      "병\n",
      "---\n",
      "</document 6>\n",
      "\n",
      "<document 7>\n",
      "---\n",
      "31\n",
      "ENVIRONMENT REPORT 2021\n",
      "BETTER LIFE WITH STEEL \n",
      "01 \n",
      "수자원 재활용\n",
      " -\n",
      "동국제강은 물 자원의 중요성을 인식하고 폐수 재활용 향상 및 방류수 수질 관리를 주요 관리영역으로 선정하여 관\n",
      "리하고 있습니다. 동국제강의 포항·인천공장은 폐수 무방류 배출 시설을 갖추고 있으며 사용되는 용수의 100%를 재\n",
      "활용하고 있습니다.\n",
      "  공장별 용수 재활용률(2020년 기준) (단위: 만 톤)\n",
      "구 분 공급량 재활용량 재활용률\n",
      "인천공장 179 179 100%\n",
      "포항공장 139 139 100%\n",
      "당진공장 22 3 14%\n",
      "부산공장 229 67 29%\n",
      "신평공장 3.2 3.2 100%\n",
      "  공장별 수질오염물질 배출농도(2020년 기준)\n",
      "  오폐수 방류량 및 수질오염물질 배출농도\n",
      "구 분 2018 2019 2020 2021 계획\n",
      "오폐수 방류량\n",
      "(만 톤)\n",
      "당진 1.2 1.3 1.2 1.3\n",
      "부산 258 201 186 1 85\n",
      "배출농도\n",
      "(mg/ℓ)\n",
      "당진\n",
      "BOD - 2.5 1.9 1.2\n",
      "COD 7.9 6.9 8.2 6\n",
      "부유물질 5 9.3 17.6 7.4\n",
      "PH 7.3 7.5 7.8 7.9\n",
      "부산\n",
      "BOD 2.8 3.4 5.4 4.1\n",
      "COD 19 21 26 18\n",
      "부유물질 4.4 2.3 3.5 2.1\n",
      "PH 7.4 6.9 7.1 7.4\n",
      "비점오염원 저감시설\n",
      "당진공장의 공업용수 및 생활용수의 경우, 하수종\n",
      "말처리장으로 유입처리되나, 일반우수관의 경우\n",
      "에는 바다로 방류될 수 밖에 없습니다. 당진공장은 \n",
      "해양생태계 보존에 어떠한 악영향도 끼치지 않기 \n",
      "위하여 도로 노면의 오염물질이 우천 시 바다로 직\n",
      "방류되는 것을 방지하고자 ‘비점오염원저감시설’\n",
      "을 통과하여 배출하고 있습니다. 해당 저감시설 내 \n",
      "여재는 매년 교체하며, 우천 시에 시설점검, 연 1회 \n",
      "수질분석 등을 실시하고 있습니다.\n",
      "비점저감시설은 총 5개소 (지하 위치) \n",
      "*/\n",
      "065ਬҕҙ੗тக\n",
      "க\n",
      "க\n",
      "஝\n",
      "੗тக\n",
      "க\n",
      "஝\n",
      "੗тக\n",
      "부산공장\n",
      "생물화학적 \n",
      "산소요구량(BOD)\n",
      "화학적 \n",
      "산소요구량(COD)\n",
      "부유물질량\n",
      "80.0\n",
      "4.2\n",
      "90.0\n",
      "15.7\n",
      "80.0\n",
      "1.9\n",
      "당진공장\n",
      "생물화학적 \n",
      "산소요구량(BOD)\n",
      "화학적 \n",
      "산소요구량(COD)\n",
      "부유물질량\n",
      "50.0 40.0\n",
      "8.2 2.11.9\n",
      "80.0\n",
      "* 당진공장은 사외 하수처리장 최종 처리 후 방류\n",
      "* 부산공장은 직접 운영하는 폐수처리장에서 환경 기준치 이하 관리 후 방류\n",
      "\u001a  법적기준\n",
      "\u001a  2020년 실적\n",
      "02\n",
      "생물다양성 보존\n",
      " -\n",
      "부산공장은 인근 해역의 수질에 미치는 영향을 최소화하기 위하여 자체 폐수처리시설을 운영하고 있으며, 폐수는 1차 \n",
      "물리·화학적 처리를 거치고, 유기물이 함유된 폐수는 생물학적 처리를 통하여 2차 처리 됩니다. 1, 2차 처리된 폐수는 \n",
      "최종폐수처리시설을 거쳐 법적 기준치 이하로 방류됩니다. 당진공장의 경우에는 사외 하수종말처리장으로 유입처리\n",
      "되고 있으며, 각 사업장은 수질오염물질의 배출농도를 법적 허용기준의 50% 이하 수준으로 목표를 수립하여 관리하\n",
      "고 있습니다.\n",
      "수자원 관리\n",
      "---\n",
      "</document 7>\n",
      "\n",
      "<document 8>\n",
      "---\n",
      "33\n",
      "ENVIRONMENT REPORT 2021\n",
      "BETTER LIFE WITH STEEL \n",
      "기후변화 \n",
      "Climate Change\n",
      "기후변화는 이미 오래전부터 전 세계가 당면한 과제이며, 기후변화 대응에 적극적인 노력을 기울이지 않을 경우 사업\n",
      "에 지대한 영향을 미칠 만큼 중요한 이슈가 되어가고 있습니다. EU는 2019년 12월 Green Deal 정책을 발표하였고, \n",
      "2050년까지 탄소중립Carbon Neutral 실현과 더불어 탄소국경세Carbon Border Tax를 도입하여 탄소 다량 배출 국가\n",
      "를 압박하고 탈석탄 및 재생에너지 보급 확대를 위한 인센티브 제도를 개편하는 등 각종 규제안을 마련하고 있습니다. \n",
      "이러한 국제적 흐름에 동참하여 한국 정부도 작년 ‘2050 탄소중립’을 선언하였으며, 동국제강을 포함한 국내 철강업\n",
      "계도 ‘그린철강위원회’ 출범을 통하여 공동으로 탄소중립 목표 달성 기여를 위하여 노력하고 있습니다. 동국제강은 이\n",
      "와 별개로 기후변화 문제에 효율적으로 대처하기 위하여 관련 이슈를 파악한 후 위험성을 분석하고 대응 전략을 수립\n",
      "하여 실행하고 있습니다. 온실가스 협의체를 통하여 기후변화 대응 활동을 분기별로 협의하고, 온실가스 인벤토리를 \n",
      "구축하여 매월 모든 사업장의 온실가스(Scope 1, Scope 2) 배출량을 관리하고 있습니다.\n",
      "01 \n",
      "기후변화 대응 체계 및 조직\n",
      " -\n",
      "동국제강은 동반협력실 산하의 ‘온실가스 협의체’를 구성하여 전사차원의 에너지 경영방침을 수립하여 실행하고 있습\n",
      "니다.02 \n",
      "기후변화 리스크 및 기회요인 분석\n",
      " -\n",
      "동국제강은 기후변화를 기업의 주요 경영 이슈로 판단하고, 글로벌 기후변화 문제에 적극 대처하고자 합니다. 기후변화 \n",
      "리스크 및 기회요인을 규제적 측면, 물리적 측면 등으로 분류하고, 각 이슈에 대한 대응방안을 수립하였습니다.\n",
      "  이슈 파악 및 리스크 대응 방안\n",
      "리스크 대응방안 기회요인\n",
      "규제적\n",
      "측면\n",
      "온실가스 배출권 거래 배출량 저감 및 배출권 거래제 대응체계 구축\n",
      "• 온실가스 배출권 확보\n",
      "• 프리미엄 제품 판매 확대\n",
      "• 친환경 신사업 진출\n",
      "• 에너지 효율 증대로 원가절감\n",
      "• 친환경 인증 및 판매처 확대\n",
      "• 친환경 철강 기업 이미지 제고\n",
      "탄소세 국가별 정책 모니터링 및 대응체계 구축\n",
      "자원순환 기본법 부산물 자원화 확대 및 철 스크랩 사용 증대\n",
      "물리적\n",
      "측면\n",
      "기상이변 직접 피해 사업장별 자연재해 예방 시스템 구현 \n",
      "기상이변 간접 피해 공급망 피해 대응 구매 및 판매처 다변화\n",
      "기타 기업 평판 이해관계자 커뮤니케이션 강화\n",
      "CEO\n",
      "동반협력실장\n",
      "온실가스 협의체\n",
      "인천공장\n",
      "안전환경팀\n",
      "포항공장\n",
      "안전환경팀\n",
      "당진공장\n",
      "안전환경팀\n",
      "부산공장\n",
      "안전환경팀\n",
      "안전환경기획팀\n",
      "---\n",
      "</document 8>\n",
      "\n",
      "<document 9>\n",
      "---\n",
      "13\n",
      "ENVIRONMENT REPORT 2021\n",
      "BETTER LIFE WITH STEEL \n",
      "경영실적\n",
      "Management Performance\n",
      "01 \n",
      "2020년 경영환경 및 당사 대응\n",
      " -\n",
      "전 세계 코로나19 확산으로 경제활동에 차질이 발생하였으며, 이는 글로벌 철강산업에도 악영향을 주었\n",
      "습니다. 중국을 제외한 글로벌 철강 수요량은 2019년 대비 13% 감소하였으며, 철광석 가격은 2019년 대\n",
      "비 2.3배 급등하였습니다. 수급 불균형으로 인한 글로벌 철강산업의 침체기 속에서도 동국제강은 전기로 \n",
      "이점을 활용한 수요시장에 대한 유연한 공장가동 대응과 고수익 제품 판매 확대를 통하여 안정적인 수익\n",
      "을 창출하였습니다.\n",
      "전기로 \n",
      "탄력적 가동\n",
      "하반기 가전컬러 \n",
      "판매 확대\n",
      "고수익 제품 \n",
      "판매 확대\n",
      "철광석 가격\n",
      "(달러/톤)\n",
      "210\n",
      "160\n",
      "110\n",
      "60\n",
      "835\n",
      "2016\n",
      "859\n",
      "2017\n",
      "874\n",
      "2018\n",
      "859\n",
      "2019\n",
      "745\n",
      "2020\n",
      "글로벌 철강 수요\n",
      "(백만 톤)\n",
      "---\n",
      "</document 9><|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "질문: C3-2-2. 지배구조 요소와 관련하여 아래 항목 중 현재 재직하고 있는 회사에 해당되는 응답을 선택해주세요._1)(상장기업만 응답) 공정공시제도를 준수하고 있는가?\n",
      "\n",
      "보기:\n",
      "['1) 전혀그렇지않다', '2) 약간그렇지않다', '3) 보통이다', '4) 약간그렇다', '5) 매우그렇다']<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "근거: 검색 결과에서는 동국제강이 공정공시제도를 준수하고 있는지에 대한 직접적인 정보가 제공되지 않았습니다. 동국제강의 환경 및 경영 실적, 지속가능 경영 방침 등에 대한 정보만 포함되어 있습니다.\n",
      "답변: 알 수 없음.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "# 디코딩된 input_ids 출력\n",
    "decoded_text = tokenizer.decode(\n",
    "    batch[\"input_ids\"][0].tolist(),\n",
    "    skip_special_tokens=False,\n",
    "    clean_up_tokenization_spaces=False\n",
    ")\n",
    "\n",
    "print(\"\\ninput_ids 디코딩 결과:\")\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7c3cfef-655b-451d-9fa6-599c0397e4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레이블에 대한 정수 인코딩 결과:\n",
      "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 104152, 93292, 25, 115036, 99901, 107031, 101604, 100654, 38187, 102296, 13094, 100994, 30381, 79225, 30426, 38187, 118450, 108683, 24140, 101360, 65621, 22035, 19954, 102597, 120307, 103684, 61139, 20565, 108273, 119222, 116154, 39331, 13, 101604, 100654, 38187, 102296, 21028, 118909, 101824, 44215, 101090, 102326, 82068, 11, 67890, 102130, 116669, 44215, 101090, 75908, 108308, 78102, 19954, 102597, 61139, 73653, 110097, 106910, 103924, 627, 109659, 104449, 25, 102066, 29833, 127409, 13, 128009]\n"
     ]
    }
   ],
   "source": [
    "print('레이블에 대한 정수 인코딩 결과:')\n",
    "print(batch[\"labels\"][0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82f7eaa4-3837-42de-a37b-8800da82462a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "labels 디코딩 결과 (-100 제외):\n",
      "근거: 검색 결과에서는 동국제강이 공정공시제도를 준수하고 있는지에 대한 직접적인 정보가 제공되지 않았습니다. 동국제강의 환경 및 경영 실적, 지속가능 경영 방침 등에 대한 정보만 포함되어 있습니다.\n",
      "답변: 알 수 없음.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "# -100이 아닌 부분만 골라 디코딩\n",
    "label_ids = [token_id for token_id in batch[\"labels\"][0].tolist() if token_id != -100]\n",
    "\n",
    "decoded_labels = tokenizer.decode(\n",
    "    label_ids,\n",
    "    skip_special_tokens=False,\n",
    "    clean_up_tokenization_spaces=False\n",
    ")\n",
    "\n",
    "print(\"\\nlabels 디코딩 결과 (-100 제외):\")\n",
    "print(decoded_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cbdb20-95a2-41e1-a63a-14f9f6765d6a",
   "metadata": {},
   "source": [
    "### input_ids와 labels는 어떻게 생성되는가?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cd6653-5097-4456-8a08-699687804632",
   "metadata": {},
   "source": [
    "\n",
    "LLM 학습에서 `input_ids`와 `labels`는 모델의 학습 목표에 따라 생성됩니다. 이를 예시 문장과 정수 인코딩을 통해 상세히 설명하겠습니다.\r\n",
    "\r\n",
    "예를 들어, 다음과 같은 대화 데이터를 모델이 학습해야 한다고 가정합니다.\r\n",
    "사용자가 `안녕하세요, 오늘 날씨는 어떤가요?`라고 물었고,\r\n",
    "모델은 `안녕하세요! 오늘 날씨는 맑고 화창합니다.`라고 응답해야 한다고 합시다.\r\n",
    "\r\n",
    "LLaMA 3에서는 다음과 같은 템플릿 구조를 사용합니다:\r\n",
    "\r\n",
    "`<|begin_of_text|><|start_header_id|>user<|end_header_id|>\r\n",
    "안녕하세요, 오늘 날씨는 어떤가요?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\r\n",
    "안녕하세요! 오늘 날씨는 맑고 화창합니다.<|eot_id|>`\r\n",
    "\r\n",
    "이 전체 텍스트는 토크나이저에 의해 정수 시퀀스로 변환됩니다. 예시로 단순화된 정수 시퀀스는 다음과 같다고 가정합니다:\r\n",
    "\r\n",
    "`input_ids = [1001, 2001, 3001, 4001, 5001, 6001, 7001, 1002, 1001, 8001, 9001, 1003, 2002]`\r\n",
    "\r\n",
    "여기서 모델이 예측해야 할 영역은 assistant의 응답 부분인\r\n",
    "`안녕하세요! 오늘 날씨는 맑고 화창합니다.`에 해당하는 토큰들입니다.\r\n",
    "따라서 `labels`는 다음과 같이 설정됩니다:\r\n",
    "\r\n",
    "`labels = [-100, -100, -100, -100, -100, -100, -100, -100, -100, 8001, 9001, 1003, 2002]`\r\n",
    "\r\n",
    "이처럼 `labels`는 모델의 출력이 필요한 영역만을 포함하고, 나머지 부분은 `-100`으로 채워져\r\n",
    "모델이 실제로 예측하고 오차를 계산해야 하는 대상(학습 대상)에서 제외됩니다.\r\n",
    "\r\n",
    "이를 통해 모델은 불필요한 입력 부분을 학습하지 않고, assnt 응답 부분에만 집중할 수 있습니다.\r\n",
    "\"\"\"\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d42c907-fb98-405a-9b90-5a3413199092",
   "metadata": {},
   "source": [
    "## 5. 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9ef86a9-8b8a-4aeb-809a-9d7babca9cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:283: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    max_seq_length=max_seq_length,  # 최대 시퀀스 길이 설정\n",
    "    train_dataset=train_dataset,\n",
    "    data_collator=collate_fn,\n",
    "    peft_config=peft_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1af87dc-5b07-4a0f-b922-cabf0ca549fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2412' max='2412' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2412/2412 9:25:13, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.093500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.854100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.857800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.749000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.674200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.741100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.684600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.662200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.707000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.780600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.656000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.694500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.583900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.688700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.666200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.684100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.625500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.681700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.696900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.726200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.718300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.648200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.617900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.649100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.613300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.708400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.597100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.678200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.696400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.697800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.633800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.705000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.687200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.661500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.708800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.632100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.685000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.620700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.633800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.726600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.638100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.680600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.583600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.680800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.619300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.652000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.687200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.648700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.572100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.694000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.578700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.652400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.656900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.668900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.630700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.636500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.664600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.663300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>0.610400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.715600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>0.696500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.696700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.655400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.648800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.659900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.654600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>0.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.659000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.656100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.646400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>0.658000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.628100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>0.588500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.617500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.626300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.643400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>0.658600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.624600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>0.657500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.565800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>0.632800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>0.597900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>0.628700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.617100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.556000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>0.603800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>0.665300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>0.593600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>0.561100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.610900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>0.566800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>0.618200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>0.612300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>0.588600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.627200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.565000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>0.629100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>0.593100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>0.616300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.570500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010</td>\n",
       "      <td>0.659900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.615100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1030</td>\n",
       "      <td>0.628300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.586000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>0.565100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1070</td>\n",
       "      <td>0.550600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.577500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1090</td>\n",
       "      <td>0.674200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.604500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1110</td>\n",
       "      <td>0.603900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>0.592100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1130</td>\n",
       "      <td>0.652600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.631200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.580300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160</td>\n",
       "      <td>0.558000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1170</td>\n",
       "      <td>0.582100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1180</td>\n",
       "      <td>0.613500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1190</td>\n",
       "      <td>0.574500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.626700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1210</td>\n",
       "      <td>0.589900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1220</td>\n",
       "      <td>0.558300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1230</td>\n",
       "      <td>0.601400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240</td>\n",
       "      <td>0.578900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.619500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.538400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1270</td>\n",
       "      <td>0.567300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>0.634500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1290</td>\n",
       "      <td>0.581400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.551100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1310</td>\n",
       "      <td>0.608400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.546300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1330</td>\n",
       "      <td>0.627700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1340</td>\n",
       "      <td>0.597700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.590100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1360</td>\n",
       "      <td>0.578600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1370</td>\n",
       "      <td>0.566600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.605400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1390</td>\n",
       "      <td>0.555000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.578700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1410</td>\n",
       "      <td>0.581800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1420</td>\n",
       "      <td>0.612300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1430</td>\n",
       "      <td>0.614800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.564500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.562600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1460</td>\n",
       "      <td>0.589900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1470</td>\n",
       "      <td>0.627200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1480</td>\n",
       "      <td>0.596100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1490</td>\n",
       "      <td>0.551400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.621200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1510</td>\n",
       "      <td>0.533500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1520</td>\n",
       "      <td>0.555900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1530</td>\n",
       "      <td>0.595200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1540</td>\n",
       "      <td>0.591700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.605900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.625600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1570</td>\n",
       "      <td>0.581000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1580</td>\n",
       "      <td>0.561900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1590</td>\n",
       "      <td>0.576100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.555500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1610</td>\n",
       "      <td>0.589000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.449700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1630</td>\n",
       "      <td>0.588100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1640</td>\n",
       "      <td>0.545700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.491500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1660</td>\n",
       "      <td>0.523300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1670</td>\n",
       "      <td>0.504400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1690</td>\n",
       "      <td>0.556100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.535800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1710</td>\n",
       "      <td>0.593300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1720</td>\n",
       "      <td>0.509200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1730</td>\n",
       "      <td>0.475900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.564500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.507100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1760</td>\n",
       "      <td>0.532600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1770</td>\n",
       "      <td>0.586000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1780</td>\n",
       "      <td>0.594900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1790</td>\n",
       "      <td>0.495600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.524300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1810</td>\n",
       "      <td>0.551900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1820</td>\n",
       "      <td>0.576200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1830</td>\n",
       "      <td>0.501500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1840</td>\n",
       "      <td>0.485500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.487800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.521600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1870</td>\n",
       "      <td>0.552100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1880</td>\n",
       "      <td>0.584700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1890</td>\n",
       "      <td>0.503100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.563400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1910</td>\n",
       "      <td>0.519300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.535100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1930</td>\n",
       "      <td>0.508500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1940</td>\n",
       "      <td>0.577800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.571300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1960</td>\n",
       "      <td>0.505800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1970</td>\n",
       "      <td>0.529100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980</td>\n",
       "      <td>0.535200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1990</td>\n",
       "      <td>0.530300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.597900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2010</td>\n",
       "      <td>0.553800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020</td>\n",
       "      <td>0.534700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2030</td>\n",
       "      <td>0.539800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2040</td>\n",
       "      <td>0.566200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.573300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2060</td>\n",
       "      <td>0.541800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2070</td>\n",
       "      <td>0.545600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2080</td>\n",
       "      <td>0.530600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2090</td>\n",
       "      <td>0.587800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.588300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2110</td>\n",
       "      <td>0.550700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2120</td>\n",
       "      <td>0.535100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2130</td>\n",
       "      <td>0.534800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2140</td>\n",
       "      <td>0.588900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.533600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2160</td>\n",
       "      <td>0.554900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2170</td>\n",
       "      <td>0.564800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2180</td>\n",
       "      <td>0.572600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2190</td>\n",
       "      <td>0.514900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.514800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2210</td>\n",
       "      <td>0.556500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2220</td>\n",
       "      <td>0.566900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2230</td>\n",
       "      <td>0.501600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2240</td>\n",
       "      <td>0.563300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.528700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2260</td>\n",
       "      <td>0.546100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2270</td>\n",
       "      <td>0.541700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2280</td>\n",
       "      <td>0.568500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2290</td>\n",
       "      <td>0.535000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.571600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2310</td>\n",
       "      <td>0.560800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2320</td>\n",
       "      <td>0.571500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2330</td>\n",
       "      <td>0.544900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2340</td>\n",
       "      <td>0.505100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>0.534200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2360</td>\n",
       "      <td>0.565600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2370</td>\n",
       "      <td>0.546100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2380</td>\n",
       "      <td>0.559600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2390</td>\n",
       "      <td>0.567700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.586000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2410</td>\n",
       "      <td>0.506200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "# 학습 시작\n",
    "trainer.train()   # 모델이 자동으로 허브와 output_dir에 저장됨\n",
    "\n",
    "# 모델 저장\n",
    "trainer.save_model()   # 최종 모델을 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6f9d42-574a-4ad8-9327-7315d1a1269b",
   "metadata": {},
   "source": [
    "## 6. 테스트 데이터 준비\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795c2138-e4e5-4afb-a37d-ef8dd70b5f4c",
   "metadata": {},
   "source": [
    "실제 모델에 입력을 넣을 때에는 입력의 뒤에 '<|start_header_id|>assistant<|end_header_id|>\\n'가 부착되어서 넣는 것이 좋습니다. 그래야만 모델이 바로 답변을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abb48dbc-646c-4a2d-ae1f-0ef824cae419",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_lst = []\n",
    "label_lst = []\n",
    "\n",
    "for messages in test_dataset[\"messages\"]:\n",
    "    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=False)\n",
    "    input = text.split('<|start_header_id|>assistant<|end_header_id|>\\n')[0] + '<|start_header_id|>assistant<|end_header_id|>\\n'\n",
    "    label = text.split('<|start_header_id|>assistant<|end_header_id|>\\n')[1].split('<|eot_id|>')[0]\n",
    "    prompt_lst.append(input)\n",
    "    label_lst.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "011e29f0-c6d9-4e90-9ebc-78a4f2ca9d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "당신은 주어진 질문에 대해서 검색 결과, 질문, 보기를 바탕으로 답변해야 합니다.\n",
      "답변할 때는 근거:를 먼저 작성하고 답변:을 작성하십시오.\n",
      "검색 결과를 바탕으로 답변할 수 없는 경우에는 근거:에 검색 결과에 질문에 대한 답을 알 수 있는 내용이 없다고 설명하고 답변: 알 수 없음이라고 적으세요. 반드시 '알 수 없음'이라고 적어야 합니다.\n",
      "\n",
      "### 예시 ###\n",
      "근거: 삼양홀딩스는 직원들의 복리후생과 업무환경 개선에 많은 노력을 기울이고 있습니다. 사내에서 아침, 점심, 저녁을 무료로 제공하는 구내 식당과 피트니스 센터 운영을 통해 임직원의 건강을 지원하고 있으며, 카페테리아 및 다양한 편의시설을 제공하여 여유와 휴식을 취할 수 있는 환경을 마련하고 있습니다 (문서 0). 또한, 삼양홀딩스는 직원들이 일과 생활의 균형을 유지할 수 있는 유연근무제를 도입하여 직원들이 가장 편리한 시간에 근무할 수 있도록 하고 있습니다 (문서 0). 이러한 점들을 고려할 때, 삼양홀딩스는 쾌적한 근무환경을 제공하고 있다고 평가할 수 있습니다.\n",
      "답변: '5) 매우그렇다\n",
      "\n",
      "검색 결과:\n",
      "<document 0>\n",
      "---\n",
      "Environmental Report 2019\n",
      "2019 동국제강 환경보고서\n",
      "※ 본 보고서는 친환경 용지를 사용하여 제작되었습니다.\n",
      "※ 본 보고서와 관련된 사항은 아래로 연락주시기 바랍니다.\n",
      "02 317 1452 | 서울특별시 중구 을지로5길 19(수하동, 페럼타워) 6층\n",
      "보고대상 본 보고서는 동국제강의 환경경영 활동 및 성과 내용을 담고 있습니다.\n",
      "보고기준 및 범위 환경정보공개제도의 등록 정보를 활용하였으며 동국제강의 정보공개 범위로 작성하였습니다.\n",
      "보고기간 본 보고서는 2018년 12월 31일 까지의 환경경영 활동 및 성과 정보를 담고 있으며, 일부 정량 데이터의 경우 최근 3개년 수치를 제공하고 있습니다.\n",
      "---\n",
      "</document 0>\n",
      "\n",
      "<document 1>\n",
      "---\n",
      "13Environmental Report 2019\n",
      "[한국의 온실가스 감축 목표]\n",
      "2030년 BAU* 대비 37% 감축\n",
      "* BAU (Business As Usual)란?\n",
      "온실가스 감축을 위한 인위적인 조치를 취하지 않을 경우 배출이 예상되는 온실가스의 총량\n",
      "33%\n",
      "25%\n",
      "15%\n",
      "8%\n",
      "19%\n",
      "[국내 산업별 CO2 배출 비율]\n",
      "철강\n",
      "정유/석유화학\n",
      "시멘트\n",
      "반도체 디스플레이\n",
      "기타\n",
      "[철강재 1톤당 CO2(온실가스) 배출량 비교]\n",
      "* Life Cycle 관점이란?\n",
      "제품 생산을 위한 원료 채취에서부터 \n",
      "제조, 수송, 사용, 폐기까지 전과정에서 \n",
      "사용되는 연료와 원료에서 배출되는 \n",
      "오염물질의 양을 정량화하여 환경에 \n",
      "미치는 영향을 평가하는 방법\n",
      "구분 고로 업체 전기로 업체\n",
      "CO2(온실가스)배출량 (천tCO2) 90,654 9,412\n",
      "조강생산량 (만톤) 4,768 2,341\n",
      "1톤당 CO2(온실가스) 배출량 (tCO2) 1.90 0.40\n",
      "전기로 사용 시 CO2 \n",
      "1/4배 감소\n",
      "1.9tCO2\n",
      "0.4tCO2\n",
      "고로(高爐) 전기로\n",
      "[2018년 기준]\n",
      "한국은 지구 온난화의 원인인 CO2(온실가스) 배출량이 OECD 회원국 중 4번째로 많은 것으로 조사되었으며, \n",
      "이에 대한 책임과 의무를 다하기 위하여 2030년 국가 온실가스 배출 전망치 대비 37%를 감축하기로 국제 \n",
      "사회와 약속하였습니다. 이러한 환경 시대에 발맞춰 국내의 전체 CO2(온실가스) 배출량의 33%를 차지하는 \n",
      "철강업체가 저탄소 사회의 실현을 위하여 앞장서야 합니다.\n",
      "철강 산업에서 철광석과 코크스를 주원료로 사용하는 고로(高爐) 업체가 CO2(온실가스) 배출량의 90%를 차지 \n",
      "하고 있습니다. 또한, 철강재의 Life Cycle 관점*에서 보더라도 전기로에서 생산된 철강재가 1톤당 CO2 \n",
      "(온실가스) 배출량이 고로에서 생산된 제품보다 4배 이상 적은 것으로 조사되었습니다.\n",
      "철강산업이\n",
      "저탄소 사회 실현에\n",
      "앞장 서야 합니다\n",
      "전기로는 저탄소 사회 \n",
      "실현을 위한 효과적인 \n",
      "생산 방법입니다\n",
      "To realize\n",
      "low carbon society\n",
      "저탄소 사회 실현을 위하여\n",
      "---\n",
      "</document 1>\n",
      "\n",
      "<document 2>\n",
      "---\n",
      "03Environmental Report 2019\n",
      "동국제강이 만들어 갑니다\n",
      "16\n",
      "CEO Message\n",
      "04\n",
      "2018년 환경경영\n",
      "실적 소개\n",
      "14\n",
      "회사소개\n",
      "06\n",
      "2018년 환경경영\n",
      "주요 활동\n",
      "18\n",
      "순환형 사회의\n",
      "실현을 위하여\n",
      "10\n",
      "Green Action Plan 2020\n",
      "22\n",
      "저탄소 사회의\n",
      "실현을 위하여\n",
      "12\n",
      "인증현황\n",
      "24\n",
      "03Environmental Report 2019\n",
      "환경까지 생각하는 국내 전기로 업체의 선두기업 동국제강\n",
      "사람과 환경, 그리고 기업이 함께 공생할 수 있는 사회를 만들기 위한\n",
      "사회적 책임을 65년간 실천해 오고 있습니다.\n",
      "진심이 65년이 되었습니다\n",
      "Contents\n",
      "본 보고서는 고객, 직원, 주주, 투자자 등 이해관계자들에게 동국제강의 환경경영 정보제공을 목적으로 발행하였습니다. 동국제강은 \n",
      "철강기업으로서 “자원 순환 사회” 및 “저탄소 사회” 실현에의 공헌을 환경과제로 삼고 있으며, 이 보고서 또한 당 과제에 대한 정보를  \n",
      "중심으로 구성하고 있습니다.\n",
      "About Report\n",
      "---\n",
      "</document 2>\n",
      "\n",
      "<document 3>\n",
      "---\n",
      "05Environmental Report 2019\n",
      "CEO Message\n",
      "필(必) 환경 시대,\n",
      "동국제강이 친환경 철강 비즈니스 \n",
      "모델의 새로운 기준이 되겠습니다.\n",
      "오늘날 세계는 기후 변화, 유한한 자원, 식량 및 물 부족 등  \n",
      "수많은 환경과제에 직면해있으며, 인류는 지속 가능성을 위해 \n",
      "친환경을 넘어선 必 환경 시대에 돌입했습니다.\n",
      "이에 유엔 지속가능발전 목표(SDGs) 및 파리 기후변화 협약 등 \n",
      "저탄소 자원 순환 사회를 건설하기 위한 국제사회의 노력은 \n",
      "지속되고 있으며, 동국제강은 이런 국제사회의 움직임을  \n",
      "지지하며 적극적으로 동참하고 있습니다.\n",
      "‘철’은 품질 손상 없이 몇 번이고 재활용할 수 있는 무한루프의 \n",
      "성질을 가진 순환 재생 원료입니다. 동국제강은 지난 65년간 \n",
      "철스크랩을 원료로 하는 전기로 사업을 통해 자원 순환 사회 \n",
      "구축에 공헌하고 있습니다.\n",
      "또한, 동국제강의 제조공법인 전기로는 일반 고로공법 대비 \n",
      "이산화탄소 발생량이 25% 수준이기에, 전기로 산업의 성장은 \n",
      "자원 순환 사회 및 저탄소사회 구축에 필수 불가결한 과정  \n",
      "입니다. \n",
      "이에 동국제강은 국내 전기로 업체의 선두주자로서 산업의  \n",
      "발전을 통해 지속가능성 문제를 해결하는데 중요한 역할을  \n",
      "해야만 한다는 책임감을 가지고 노력해왔습니다.\n",
      "2010년 국내 최초로 고효율 · 친환경 전기로인 ‘에코아크  \n",
      "(Eco-Arc) 전기로를 도입하며 동국제강은 선제적으로  \n",
      "친환경 철강기업의 모습을 갖추기 위해 정진하였고, 아울러 \n",
      "ISO14001에 기반한 환경경영시스템 구축, 에너지 · 온실가스 \n",
      "통합 관리체계 구축, 친환경 설비 도입 등 전 사업장에 걸쳐 \n",
      "녹색경영 방침을 준수하고 있습니다.\n",
      "앞으로도 동국제강은 국내 철강 수요의 수십 년 분에 이르는 \n",
      "국내에 축적된 철 스크랩을 고도의 기술을 통하여 효율적인 \n",
      "재활용을 꾀하고, 2030년 이산화탄소 배출 예상량의 37% \n",
      "감축하겠다는 국가 목표를 달성하는데 일조할 수 있도록  \n",
      "끊임없이 노력하고 매진할 것입니다.\n",
      "감사합니다.\n",
      "영속 가능한 \n",
      "글로벌 철강사의\n",
      "꿈과 열정을 이어나가겠습니다.\n",
      "동국제강 회장 장세주\n",
      "철강종가의 저력을 \n",
      "다시 한번 \n",
      "보여드리겠습니다.\n",
      "동국제강 부회장 장세욱\n",
      "---\n",
      "</document 3>\n",
      "\n",
      "<document 4>\n",
      "---\n",
      "23Environmental Report 2019\n",
      "동국제강이 지향하는 순환형, 저탄소 사회 실현을 위하여, 2020년까지 \n",
      "전 임직원은 현재 보다 부산물 및 수자원의 재활용률 개선과 탄소배출량을 \n",
      "추가 감축하는 목표를 설정하고 이를 달성하기 위하여 지속적으로 노력해 \n",
      "나가고 있습니다.\n",
      "Green Action \n",
      "Plan 2020\n",
      "순환형 사회\n",
      "실현 방안 계획\n",
      "   원재료 관리 \n",
      "· 원재료 입고부터 통합 관리 시스템을 통한 제품 총 회수율 증대\n",
      "   부산물 관리 \n",
      "· 탈질설비(SCR) 투자를 통한 오염물질 배출 감축(105ppm 이하 관리) \n",
      "· 부산물 재활용·재사용을 위한 수요 개발 지속(2% 개선)\n",
      "   수자원 관리 \n",
      "· 수처리 설비 투자 및 용수 재사용 기준 개선으로 재활용률 증대 (재활용률 2% 개선)\n",
      "저탄소 사회\n",
      "실현 활동 계획\n",
      "   전력 관리 (기대효과 : CO2 1.8만톤↓) \n",
      "· 에너지관리시스템(↓6,600tCO2), Smart Furnace(↓1,900tCO2) 도입으로 전력 사용량 절감 \n",
      "· 전력 Peak 관리 등 조업 활동 개선으로 전력 원단위 절감(↓8,500tCO2)\n",
      "   연료 관리 부문 (CO2 0.4만톤 ↓) \n",
      "· 가열로 공기비 연소제어 시스템 도입(↓900tCO2) \n",
      "· 가열로 연료 패턴 조정 등 조업 활동 개선으로 연료 원단위 절감(↓2,500tCO2)\n",
      "   기타 관리 부문 (CO2 0.8만톤 ↓) \n",
      "· 제강 탈취제 분사 설비 도입으로 LNG 사용량 절감(↓2,300tCO2) \n",
      "· 바이오매스 보일러 가동률 20% 증대(↓2,900tCO2) \n",
      "· 집진기 설비 개조(↓2,300tCO2) \n",
      "· 원자재 차량 입고 예약 시스템 구축으로 차량 대기시간 축소\n",
      "*  지속가능 발전 목표\n",
      "(Sustainable Development \n",
      "Goals, SDGs) : \n",
      "유엔과 국제사회가 해결하고자 하는 최대 \n",
      "공동 목표로 1)인류의 보편적 문제, 2)지구 \n",
      "환경문제, 3)경제·사회문제를 배경으로 \n",
      "하는 총 17가지 목표 (2016~2030년)\n",
      "6 : 깨끗한 물과 위생\n",
      "8 : 양질의 일자리와 경제성장\n",
      "12 : 지속가능한 생산과 소비\n",
      "13 : 기후 변화 대응\n",
      "14 : 해양 생태계 보존\n",
      "15 : 육상 생태계보호\n",
      "7 : 모두를 위한 깨끗한 에너지\n",
      "11 : 지속가능한 도시와 공동체\n",
      "15 : 육상 생태계보호\n",
      "---\n",
      "</document 4>\n",
      "\n",
      "<document 5>\n",
      "---\n",
      "21Environmental Report 2019\n",
      "동국제강이\n",
      "저탄소 사회를\n",
      "만들어 갑니다\n",
      " 에너지 관리\n",
      "동국제강은 친환경적인 설비에 아낌없는 투자와 지속적인 온실가스 감축 노력을 이어가고 있습니다. 또한,\n",
      "에너지 효율 향상과 친환경 제품개발을 통한 저탄소 사회를 만들어 가기 위해 끊임없이 노력하고 있습니다.\n",
      "     가 열 로의 탄력적 가동으로 에너지 \n",
      "사용량 감축 활동\n",
      "가열로의 LNG 연료 사용량 저감을 위한 인천공장 2호\n",
      "압연 HDR(Hot Direct Rolling), 당진공장 축열식 가열로 \n",
      "도입 및 공장별 Hot Charge 개선노력은 CO2(온실가스) \n",
      "배출량을 연간 9.3만CO2 감축하는 효과를 얻었습니다.\n",
      "   친환경 연료 사용의 온실가스 배출 저감 활동\n",
      "설비 /공장 개선부문 CO2 감축효과\n",
      "Eco Arc 전기로 인천 전력 7.5\n",
      "HDR 보열로 연료(LNG) 3.8\n",
      "축열식 보일러 당진 연료(폐열) 0.9\n",
      "RTO 시설\n",
      "부산\n",
      "0.7\n",
      "바이오 보일러 연료(폐목재) 1.4\n",
      "태양광 발전설비 전력 0.2\n",
      "합 계 14.5\n",
      "[친환경 설비 도입 전후 CO2 감축 효과 비교   ] 2018년 기준(단위:만tCO2/y)\n",
      "부산공장\n",
      "(좌) 바이오 보일러\n",
      "(우) 태양광 발전설비\n",
      "   친환경 에코아크 전기로의 온실가스 \n",
      "배출 저감 활동\n",
      "국내 최초로 도입된 에코아크(Eco Arc) 전기로는 폐가\n",
      "스를 활용한 철스크랩 예열방식으로 일반 전기로 대비 \n",
      "에너지 사용량이 30% 가량 적으며, 환경오염물질 배\n",
      "출도 낮은 친환경적 설비로써 2018년 한해 동안 7.5\n",
      "만TCO2 감축 효과를 얻었습니다.\n",
      "30%\n",
      "120톤제강 에코아크 전기로\n",
      "(기존 전기로 대비)\n",
      " 친환경 UV 강판\n",
      " 2018년 신제품\n",
      "[생산성 및 에너지 효율 향상]\n",
      "일반 강판\n",
      "친환경 UV 강판(高鮮影)\n",
      "비교항목 친환경 UV 강판 일반 강판\n",
      "휘발성유기화합물(VOCs) ZERO 40~50%\n",
      "에너지 절감 효율 5.6배 1\n",
      "공장면적 1/10 1\n",
      "공해방지 설비 불필요 (무공해) 필요\n",
      " 럭스틸 바이오 항균 강판\n",
      "녹색 환경 보호기능을\n",
      "가진 다기능 항균성 강판\n",
      "반영구적 살균효과 0-157 대장균, 녹동균, \n",
      "포도상구균 번식 방지\n",
      "항곰팡이\n",
      " 친환경 제품 개발 및 보급\n",
      "동국제강은 고성능, 고기능,친환경 철근제품을 개발·생산하고 있으며, 열차폐 강판 개발 및 보급을통해 사회의 \n",
      "냉난방 전력을 감소시켜 저탄소 사회에 기여하고 있습니다.\n",
      "   열차폐(Cool Roofing) 강판\n",
      "일반 코팅강판\n",
      "반사율 4%\n",
      "Cool Roofing 강판\n",
      "총 태양복사에너지\n",
      "반사율 25%\n",
      "[친환경 제품의 최근 3년 판매 추이]\n",
      "7%\n",
      "90.8\n",
      "115.9\n",
      "(단위: 천톤)\n",
      "2016 2018\n",
      "1.3\n",
      "2.3\n",
      " 기타 정부 지원사업 참여\n",
      "정부의 에너지 신사업 등에 적극 참여함으로써, 환경 친화적 기업 실현과 저탄소 사회 실현에 앞장서고 있습니다.\n",
      " ESS 시설 설치 운영 \n",
      "인천/포항/부산공장 ESS 시설 설치(‘18년)\n",
      " 전 사업장 LED 조명 교체 \n",
      "공장내 국부조명, 천정등, 가로등을 고효율 조명기기로 전면 교체\n",
      " 온실가스 감축\n",
      "동국제강은 지구온난화 문제에 대해 선제적인 노력을 기울여 추가적인 탄소배출권 구입 없이 정부 할당량을  \n",
      "준수하며 감축해 왔고, 이는 ’15년 정부 온실가스 할당제도 도입 이래 4년 연속 이어온 성과입니다.\n",
      "[동국제강 온실가스 배출량]\n",
      "구분 2016년 2017년 2018년\n",
      "Scope 1 0.140 0.131 0.123\n",
      "Scope 2 0.281 0.271 0.272\n",
      "총 배출 원단위 0.421 0.402 0.394\n",
      "단위: tCO2/톤[‘15년~’18년\n",
      "탄소 배출량(tCO2)]\n",
      "*   상기 수치는 전기로 설비가 포함된 포항, 인천공장만을 산정 범위로 하여 이를 포함한 모든 \n",
      "사업장을 대상으로 하는 정부 제출 명세서 값과는 정확하게 일치하지 않을 수 있음.초과 감축량\n",
      "804.6만\n",
      "773.6만\n",
      "31만\n",
      "할당량\n",
      "실적\n",
      "[분야별 CO2(온실가스) 감축 효과]\n",
      "CO2 감축2016 6.71 16.11\n",
      "18.88\n",
      "19.05\n",
      "8.56 0.84\n",
      "1.05\n",
      "2.25\n",
      "9.06\n",
      "9.29\n",
      "8.77\n",
      "7.51\n",
      "2017\n",
      "2018\n",
      "(만tCO2/y)전기로 가열로 친환경 연료\n",
      "---\n",
      "</document 5>\n",
      "\n",
      "<document 6>\n",
      "---\n",
      "25Environmental Report 2019\n",
      "동국제강은 국제적인 경영시스템에 기반한 관리가 가능하도록 국제 규격 인증을 받아 적용하고 있습니다.\n",
      "더불어 동국제강은 아낌없는 설비투자와 환경경영으로 친환경 지속성장이 가능한 미래형 철강기업 모델을\n",
      "세워가고 있습니다.\n",
      "동국제강\n",
      "주요 환경인증 현황\n",
      "구분 인증기간 인증기관 사업장\n",
      "ISO 14001\n",
      "2017.09.23~2019.09.13\n",
      "BSI\n",
      "당진공장\n",
      "2018.04.03~2021.04.02 포항공장\n",
      "2018.03.15~2021.03.14 한국표준협회 부산공장\n",
      "ISO 50001 2016.09.12~2019.09.11 BSI 당진공장\n",
      "구분 협약기간 협약기관 사업장\n",
      "오염물질\n",
      "배출저감\n",
      "자발적협약\n",
      "2017.07.10~2021.12.31 당진시 당진공장\n",
      "2018.04.09~2020.12.31 포항시 포항공장\n",
      "2018.04.12 환경부 인천공장\n",
      "통합환경허가* 2019.04.26 환경부 당진공장\n",
      "동국제강은 환경부 및 지자체와 자발적 협약을 통해 대기오염 및 미세먼지 저감을 위해 최선의 노력을\n",
      "기울이고 있습니다.\n",
      "동국제강\n",
      "환경 관련 주요 협약\n",
      "* 환경부가 환경오염시설과 관련한 7개 법률 및 10개 인허가를 통합 관리하는 제도, 동국제강이 철강업계 최초로 취득함\n",
      "동국제강은 공정성·투명성·신뢰성 확보를 목적으로 CO2배출량에 관한 제3자 기관의 보증을 받고 있습니다.온실가스 배출량\n",
      "검증의견서\n",
      "[의견서 내용 요약]\n",
      "·   동국제강 주식회사의 2018년 온실가스 배출량 명세서는 온실가스·에너지 목표관리 운영 등에 관한  \n",
      "지침에 따라 작성되었습니다.\n",
      "·   동국제강 주식회사의 2018년 온실가스 배출량 및 에너지 사용량에 대한 중요성 평가 결과 50만톤 \n",
      "CO2-eq.이상 업체로서, 양적 기준치로 중요도는 총 배출량의 2.5% 기준 미만을 만족하고 있습니다 .\n",
      "·   따라서 2018년 동국제강 주식회사의 온실가스 배출량 및 에너지 사용량에 대한 \"적정\" 의견을 제시  \n",
      "합니다.\n",
      "검증기관 : (재) 한국품질재단\n",
      "대표 : 윤석운\n",
      "   대기오염물질 배출량\n",
      "구분 2016년 2017년 2018년\n",
      "먼지 83 66 81\n",
      "황산화물 59 77 26\n",
      "질소산화물 688 694 654\n",
      "(단위: 톤)\n",
      "   온실가스 배출량\n",
      "구분 2016년 2017년 2018년\n",
      "합계 1,867 1,969 1,931\n",
      "Scope 1 706 723 673\n",
      "Scope 2 1,161 1,247 1,259\n",
      "(단위: 천tCO2)\n",
      "   용수 사용량\n",
      "구분 2016년 2017년 2018년\n",
      "용수 사용량 515 616 615\n",
      "재활용량 352 407 418\n",
      "재활용율 68% 66% 68%\n",
      "   대기오염물질 배출농도\n",
      "구분 2016년 2017년 2018년\n",
      "먼지 0.043 0.033 0.038\n",
      "황산화물 0.028 0.033 0.011\n",
      "질소산화물 0.232 0.277 0.246\n",
      "(단위: kg/톤)\n",
      "(단위: 만톤)\n",
      "   에너지 사용량    수질오염물질 배출농도\n",
      "구분 2016년 2017년 2018년\n",
      "합계 32,044 33,609 33,337\n",
      "전기 8,136 7,907 7,163\n",
      "연료 23,908 25,665 25,911\n",
      "스팀 - 38 262\n",
      "구분 법적기준 1번구 2번구\n",
      "생물학적 산소 요구량 80이하 9.0 7.5\n",
      "화학적 산소 요구량 90이하 21.0 29.0\n",
      "부유물질 80이하 3.2 2.8\n",
      "PH 5.8~8.6 7.2 7.1\n",
      "(단위: TJ) (부산공장, 단위: mg/L)\n",
      "   온실가스 및 에너지 집약도    부산물 발생량 및 재활용 현황\n",
      "구분 2016년 2017년 2018년\n",
      "온실가스집약도 0.192 0.193 0.192\n",
      "에너지 집약도 0.003 0.003 0.003\n",
      "구분 2016년 2017년 2018년\n",
      "발생량 95 88 87\n",
      "재활용량 93 83 83\n",
      "재활용률 97.9% 94.9% 95.6%\n",
      "(단위: ttCO2eq/톤, TJ/톤) (단위: 만톤)\n",
      "* 자료 : 수질오염물질 배출농도를 제외하고 나머지 수치는 동국제강의 공장 전체에 대한 평균값을 나타냄\n",
      "별첨 : 환경경영 성과 상세 내용\n",
      "---\n",
      "</document 6>\n",
      "\n",
      "<document 7>\n",
      "---\n",
      "17Environmental Report 2019\n",
      "Dongkuk Steel\n",
      "is going to make\n",
      "· 2018년 환경경영 주요 활동\n",
      "동국제강은 ‘철을 통해 문화 발전에 기여한다’는 경영이념을 바탕으로 고객 만족과  \n",
      "인간중심의 경영을 실천하고 있습니다. 또한 순환형. 저탄소 사회 실현을 위한  \n",
      "진정성 있는 친환경 기업으로 거듭나고자 환경경영방침과 이를 지키기 위한 환경\n",
      "경영 조직을 구성하여 관리에 최선을 다하고 있습니다.\n",
      "동국제강의\n",
      "환경경영 지향점\n",
      "순환형 사회 실현\n",
      "모든 자원이 낭비되지 않고 100% 활용될 수 있는 방안을 강구\n",
      "하여 순환형 사회 실현에 기여하는 기업이 되도록 노력한다.\n",
      "저탄소 사회 실현\n",
      "온실가스 감축과 기후변화 대응을 위한 경영체계를 강화하며, \n",
      "생산공정의 환경 유해성 개선 및 폐제품 관리를 통해 사업운영의 \n",
      "전 영역에 걸쳐 탄소 중립을 추구하는 기업이 되도록 노력한다.\n",
      "필(必)환경\n",
      "Green\n",
      "Action Plan \n",
      "2020\n",
      "* Green Action Plan 2020\n",
      "必환경 시대 최고의 경쟁력을 갖춘  \n",
      "철강업체가 되기 위 해 환경경영에  \n",
      "대한 2020년까지의 목표를 설정하여 \n",
      "전체 임직원이 함께 만들어 갑니다.\n",
      "친환경\n",
      "녹색경영 방침\n",
      "   환경을 경영의 필수 요소로 인식하고, 모든 단계에서 우선적으로 고려한다.\n",
      "   국내외 환경 제반 법규와 협약을 준수하고 고객의 요구사항을 만족시키는 수준 높은 기준을 설정하고 \n",
      "이행한다.\n",
      "   경영활동 전반에 걸쳐 자원의 효율적 사용을 추구하며, 지속적인 개선을 통해 환경오염을 최소화한다.\n",
      "   환경 비상사태의 잠재적 발생 가능성을 파악하고 조직적인 대응책을 마련한다.\n",
      "   환경방침을 달성하기 위한 목표를 수립 실천하며, 이해관계자에게 본 방침을 공표하고 환경경영의 \n",
      "선진화에 노력한다.\n",
      "환경경영 조직도 및 \n",
      "주요 회의\n",
      "각 사업장의 환경안전팀은 전반적인 활동의 실행주체로 환경 이슈를 신속하게 대응하고 있으며,\n",
      "주기적인 전사 회의를 통해 조직적인 관리를 해나가고 있습니다.\n",
      "구분 구성 / 개최시기\n",
      "전사 환경안전 회의 매월 전사 환경안전 관련 경영 이슈 점검 회의 [분기 공장 순회 오프라인 회의]\n",
      "온실가스 배출권 관리 회의 매 분기별 전사 배출량 모니터링, 감축기술 공유 및 주요 이슈 점검 회의\n",
      "* JFE등 국내외 주요 철강사와 선진 환경안전 관리기법 공유를 위한 교류회의 수시 진행\n",
      "CEO\n",
      "COO\n",
      "인천공장장\n",
      "환경안전팀\n",
      "포항공장장\n",
      "환경안전팀\n",
      "당진공장장\n",
      "환경안전팀\n",
      "부산공장장\n",
      "환경안전팀\n",
      "신평형강생산팀\n",
      "Green \n",
      "Management\n",
      "환경경영 시스템\n",
      "구축\n",
      "에너지 통합관리\n",
      "시스템 구축\n",
      "온실가스 인벤토리\n",
      "구축\n",
      "정부와의 환경협약\n",
      "체결\n",
      "---\n",
      "</document 7>\n",
      "\n",
      "<document 8>\n",
      "---\n",
      "15Environmental Report 2019\n",
      "CO2(온실가스) 배출량\n",
      "193.1 만tCO2\n",
      "철스크랩\n",
      "소비량 415 만톤\n",
      "부산물\n",
      "자원화률 96%\n",
      "수자원 \n",
      "재활용률 68%\n",
      "동국제강은 철스크랩을 순환 재생 원료로  \n",
      "활용하는 전기로 제조방식을 기반으로 모든  \n",
      "생산과정에서 환경에 미치는 영향을 고려하여, \n",
      "오염물질 배출과 에너지소비량을 최소화  \n",
      "하려는 원칙을 모든 사업장에서 철저히 지켜\n",
      "나가고 있습니다.\n",
      "Dongkuk Steel is\n",
      "“Steel Recycler”\n",
      "[IN-PUT]\n",
      "*참고) 공공용수역 방류수 : \n",
      "환경법규에 준한 용수 처리 후,\n",
      "공용 수로로 방유된 수자원\n",
      "[OUT-PUT]\n",
      "방류수\n",
      "공공용수역 96%하수도 4%\n",
      "197.1 만톤\n",
      "부산물\n",
      "재자원화 96% 폐기물 4%\n",
      "86.5 만톤\n",
      "제품 (판매량)\n",
      "644.2 만톤\n",
      "동국제강\n",
      "Dongkuk Steel\n",
      "소비자 / 공급자\n",
      "Consumer / Supplier\n",
      "수입\n",
      "(H/C, Slab)\n",
      "판매\n",
      "철스크랩\n",
      "철강 완제품\n",
      "연주\n",
      "에너지 (전력+LNG+기타)\n",
      "33.3 천TJ\n",
      "원재료\n",
      "730.7 만톤\n",
      "금속 99% 기타 1%\n",
      "압연\n",
      "제강\n",
      "Introduction of environmental\n",
      "management performance in 2018\n",
      "2018년 환경경영 실적 소개\n",
      "상수도 2%공업용수 98%\n",
      "수자원\n",
      "615.4 만톤\n",
      "---\n",
      "</document 8>\n",
      "\n",
      "<document 9>\n",
      "---\n",
      "11Environmental Report 2019\n",
      "소재의 친환경성은 일반적으로 얼마나 재활용성이 좋은가를 나타내는 리사이클링 강도로 표시합니다.\n",
      "철강은 0.84로 타 금속 소재에 비해 월등히 높으며, 전체 생산량 가운데 겨우 3~5%만이 재활용되는\n",
      "플라스틱과 비교해도 철은 불순물 제거 후 90% 이상 재활용되고 있습니다.\n",
      "[소재별 리사이클링 강도 비교]\n",
      "0.39\n",
      "0.08\n",
      "0.02\n",
      "0.84\n",
      "알루미늄\n",
      "구리\n",
      "티타늄\n",
      "철강\n",
      "[국내 철강 축적량 추이]\n",
      "541 562 580 598 625 650 677 702 727\n",
      "2010 2012 2014 2016 2018\n",
      "20\n",
      "25\n",
      "단위 : 백만톤\n",
      "누계 축적량\n",
      "축적량\n",
      "[철의 라이프 사이클]\n",
      "Reuse and\n",
      "remanufacturingRaw meterial \n",
      "extraction\n",
      "Steel\n",
      "production\n",
      "Manufacturing\n",
      "Use\n",
      "Steel recycling\n",
      "전기로 90% /\n",
      "고로 10%\n",
      "Pre-consumer steel scrap\n",
      "100% RECYCLABLE\n",
      "Post-consumer steel scrap\n",
      "100% RECYCLABLE\n",
      "철은 최고의 친환경적 \n",
      "금속 소재 입니다\n",
      "국내의 철강누계 축척량은 약 7억톤으로 추정되며, 이는 국내 철강 수요의 30~60년 분에 해당합니다. 축척되어\n",
      "지는 철강을 철스크랩으로 재활용 해 나가는 것은 새로운 천연자원의 소비를 억제하므로 지속적인 환경개선이 \n",
      "가능한 매우 중요한 역할이라 할 수 있습니다.\n",
      "철강재는 미래의\n",
      "새로운 자원입니다\n",
      "전기로는 철을\n",
      "재활용하는 가장\n",
      "효과적인 방법입니다\n",
      "철강재를 생산하는 방법 중, 철스크랩을 주원료로 사용하는 전기로 방식은 철의 재활용률 측면에서 고로 \n",
      "(高爐)보다 약 9배 많은 양을 재사용하고 있으며, 이러한 전기로 생산방식이야말로 가장 효과적으로 자원을 \n",
      "재활용하는 방법이라고 자신합니다.\n",
      "To realize \n",
      "a recycling society\n",
      "순환형 사회 실현을 위하여\n",
      "---\n",
      "</document 9><|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "질문: A4-1-1. 환경적 요소와 관련하여 아래 항목 중 현재 재직하고 있는 회사에 해당되는 응답을 선택해주세요._3)정기적으로 환경 경영에 대한 감사(책임 감사, 활동 감사, 경영감사)를 실시하고 있는가?\n",
      "\n",
      "보기:\n",
      "['1) 전혀그렇지않다', '2) 약간그렇지않다', '3) 보통이다', '4) 약간그렇다', '5) 매우그렇다']<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt_lst[500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "500cdfe5-8e8a-4ad9-a007-7181852c0997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "근거: 동국제강은 환경경영 시스템을 구축하고 있으며, 온실가스 배출량에 대한 제3자 기관의 보증을 받고 있고, 전사 환경안전 회의를 매월 개최하여 환경 이슈를 점검하고 있습니다. 이들은 전반적인 환경경영 활동을 체계적으로 관리하기 위한 노력의 일환입니다. 따라서 정기적으로 환경 경영에 대한 감사를 실시하고 있다고 평가할 수 있습니다 (문서 6, 문서 7).\n",
      "답변: '5) 매우그렇다'\n"
     ]
    }
   ],
   "source": [
    "print(label_lst[500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20845912-3ac4-4eaa-aaa5-edebd8cc5998",
   "metadata": {},
   "source": [
    "## 7. 파인튜닝 모델 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "414b57ea-e413-4421-9235-77c324c7fa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "from transformers import  AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04c57144-194c-4c97-883a-b8c601557f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3fe28633ed44f4f95297b24a05e5c72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FalconMambaForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'GraniteForCausalLM', 'GraniteMoeForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'LlamaForCausalLM', 'MambaForCausalLM', 'Mamba2ForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MllamaForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'NemotronForCausalLM', 'OlmoForCausalLM', 'OlmoeForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
     ]
    }
   ],
   "source": [
    "peft_model_id = \"llama3-8b-esg-survey-model/checkpoint-2412\"\n",
    "fine_tuned_model = AutoPeftModelForCausalLM.from_pretrained(peft_model_id, device_map=\"auto\", low_cpu_mem_usage=True, torch_dtype=torch.float16)\n",
    "pipe = pipeline(\"text-generation\", model=fine_tuned_model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01c8cc1a-db7a-465e-8745-e8b0b340dfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "eos_token = tokenizer(\"<|eot_id|>\", add_special_tokens=False)[\"input_ids\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e7517c0-f227-43f8-bf2e-55dfe965866b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_inference(pipe, prompt):\n",
    "    outputs = pipe(prompt, max_new_tokens=1024, eos_token_id=eos_token, do_sample=False)\n",
    "    return outputs[0]['generated_text'][len(prompt):].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ca694c28-77a9-48be-8192-e50faba386c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (15699 > 8192). Running this sequence through the model will result in indexing errors\n",
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n",
      "This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (8192). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    response:\n",
      "근거: 두산밥캣은 임직원의 안전과 건강을 매우 중요하게 여기며, 이를 위해 효과적인 환경보건안전(EHS) 관리체계를 운영하고 있습니다. 사업장에서 근무하는 모든 임직원의 안전 및 부상 리스크를 최소화하기 위해 노력하고 있으며, 북미의 관리 모델은 OHSAS 모델을 반영하고 있습니다. 또한, 안전과 보건 문제 관리는 예방 및 보호적 접근을 취하며 모든 구성원과 협력 업체가 이러한 노력에 동참하길 요구하고 있습니다 (문서 5). 이러한 노력들은 기업의 경영성과를 향상시키는데 중요한 역할을 할 수 있습니다.\n",
      "답변: '5) 매우 중요하다'\n",
      "    label:\n",
      "\n",
      "근거: 두산밥캣은 임직원 안전, 지역사회와 환경에 대한 깊은 관심을 가지고 사업 운영의 필수적인 사항으로 임직원의 안전과 관련한 효과적인 환경보건안전(EHS) 관리체계와 책임있는 임직원 참여를 통해 이를 관리하고 있습니다 (문서 2). 또한, 모든 임직원의 안전 및 부상 리스크를 최소화하기 위해 노력하며, 사고 발생 후에는 철저한 원인 조사를 실시하여 안전을 강화하고 있습니다 (문서 5). 이러한 점들을 고려할 때, 두산밥캣은 근로자 보건 및 안전을 매우 중요한 요소로 간주하여, 경영성과 향상에 기여한다고 평가하고 있습니다.\n",
      "답변: '5) 매우 중요하다'\n",
      "--------------------------------------------------\n",
      "    response:\n",
      "근거: 대웅제약은 제품의 자원순환성을 강화하기 위해 다양한 노력을 기울이고 있습니다. 대웅제약은 친환경 자재 구매와 친환경 패키징 전략을 통해 환경에 미치는 영향을 최소화하고 있으며, 자원/에너지 사용 절감을 위한 다양한 활동을 추진하고 있습니다 (문서 0, 문서 2). 또한, 폐기물 관리 및 재활용을 통해 자원 순환성을 높이기 위한 노력을 지속하고 있습니다 (문서 2). 이러한 점들을 고려할 때, 대웅제약은 제품의 자원순환성을 강화하기 위해 적극적으로 노력하고 있다고 평가할 수 있습니다.\n",
      "답변: '5) 매우그렇다'\n",
      "    label:\n",
      "\n",
      "근거: 대웅제약은 지속가능경영보고서에서 자원순환성을 강화하기 위한 여러 노력을 하고 있는 것으로 보입니다. 대웅제약은 폐기물을 감축하고 재활용률을 높이기 위해 체계적이고 지속적인 노력을 기울이고 있으며 (문서 2), 친환경 자재를 도입하여 친환경 사업 모델을 구축하고자 협력사와 공동 개발 및 도입을 추진하고 있습니다 (문서 0). 또한, 환경경영의 일환으로 환경영향 최소화와 대기오염물질 및 수질오염물질의 체계적인 관리 등을 통해 자원순환을 위한 다양한 노력을 하고 있다는 점을 알 수 있습니다 (문서 7). 이러한 노력들은 대웅제약이 제품생애주기 전반에 걸쳐 자원순환성을 강화하려고 노력하고 있는 것임을 나타냅니다.\n",
      "답변: '5) 매우그렇다'\n",
      "--------------------------------------------------\n",
      "    response:\n",
      "근거: 검색 결과에서는 삼양사가 주주가치를 제고하기 위한 구체적인 노력에 대한 정보가 제공되지 않았습니다. 따라서 주주가치를 제고하기 위한 활동에 대한 정보를 확인할 수 없습니다.\n",
      "답변: 알 수 없음\n",
      "    label:\n",
      "\n",
      "근거: 제공된 문서에서는 삼양사의 지배구조 요소와 관련하여 주주가치를 제고하기 위해 어떤 구체적인 노력을 하고 있는지에 대한 정보는 직접적으로 언급되어 있지 않습니다. 대신, 삼양사가 임직원을 위한 복리후생, 환경적 지속 가능성, 성과 평가 및 보상 체계 등 다양한 경영 및 운영 전략을 통해 기업의 가치를 높이고 있다는 점은 확인할 수 있습니다. 하지만 이는 직접적인 주주가치 제고 노력과는 구별되므로, 주주 가치 제고와 관련된 명확한 평가는 불가능합니다.\n",
      "답변: 알 수 없음\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for prompt, label in zip(prompt_lst[700:703], label_lst[700:703]):\n",
    "    # print(f\"    prompt:\\n{prompt}\")\n",
    "    print(f\"    response:\\n{test_inference(pipe, prompt)}\")\n",
    "    print(f\"    label:\\n{label.replace('Answer: ', '')}\") # 데이터에서 일부 'Answer: '가 잘리지 않은 경우를 대비\n",
    "    print(\"-\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
