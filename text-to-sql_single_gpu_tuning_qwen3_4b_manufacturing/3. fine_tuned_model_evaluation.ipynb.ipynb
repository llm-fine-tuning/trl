{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c5ef664-1b79-40dc-97e3-a47d7d49540e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-2.8.1-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting vllm==0.8.4\n",
      "  Downloading vllm-0.8.4-cp38-abi3-manylinux1_x86_64.whl.metadata (27 kB)\n",
      "Collecting cachetools (from vllm==0.8.4)\n",
      "  Downloading cachetools-6.2.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from vllm==0.8.4) (7.1.0)\n",
      "Collecting sentencepiece (from vllm==0.8.4)\n",
      "  Downloading sentencepiece-0.2.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from vllm==0.8.4) (2.1.2)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.8.4) (2.32.5)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from vllm==0.8.4) (4.67.1)\n",
      "Collecting blake3 (from vllm==0.8.4)\n",
      "  Downloading blake3-1.0.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
      "Collecting py-cpuinfo (from vllm==0.8.4)\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Requirement already satisfied: transformers>=4.51.1 in /usr/local/lib/python3.12/dist-packages (from vllm==0.8.4) (4.55.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.30.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub[hf_xet]>=0.30.0->vllm==0.8.4) (0.34.4)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.12/dist-packages (from vllm==0.8.4) (0.21.4)\n",
      "Collecting protobuf (from vllm==0.8.4)\n",
      "  Downloading protobuf-6.33.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Collecting fastapi>=0.115.0 (from fastapi[standard]>=0.115.0->vllm==0.8.4)\n",
      "  Downloading fastapi-0.122.0-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from vllm==0.8.4) (3.13.2)\n",
      "Collecting pydantic>=2.9 (from vllm==0.8.4)\n",
      "  Downloading pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
      "Requirement already satisfied: prometheus_client>=0.18.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.8.4) (0.23.1)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from vllm==0.8.4) (11.0.0)\n",
      "Collecting prometheus-fastapi-instrumentator>=7.0.0 (from vllm==0.8.4)\n",
      "  Downloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting tiktoken>=0.6.0 (from vllm==0.8.4)\n",
      "  Downloading tiktoken-0.12.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting lm-format-enforcer<0.11,>=0.10.11 (from vllm==0.8.4)\n",
      "  Downloading lm_format_enforcer-0.10.12-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting llguidance<0.8.0,>=0.7.9 (from vllm==0.8.4)\n",
      "  Downloading llguidance-0.7.30-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting outlines==0.1.11 (from vllm==0.8.4)\n",
      "  Downloading outlines-0.1.11-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting lark==1.2.2 (from vllm==0.8.4)\n",
      "  Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting xgrammar==0.1.18 (from vllm==0.8.4)\n",
      "  Downloading xgrammar-0.1.18-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.12/dist-packages (from vllm==0.8.4) (4.15.0)\n",
      "Requirement already satisfied: filelock>=3.16.1 in /usr/local/lib/python3.12/dist-packages (from vllm==0.8.4) (3.20.0)\n",
      "Collecting partial-json-parser (from vllm==0.8.4)\n",
      "  Downloading partial_json_parser-0.2.1.1.post7-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: pyzmq in /usr/local/lib/python3.12/dist-packages (from vllm==0.8.4) (27.1.0)\n",
      "Collecting msgspec (from vllm==0.8.4)\n",
      "  Downloading msgspec-0.20.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting gguf>=0.13.0 (from vllm==0.8.4)\n",
      "  Downloading gguf-0.17.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting importlib_metadata (from vllm==0.8.4)\n",
      "  Downloading importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting mistral_common>=1.5.4 (from mistral_common[opencv]>=1.5.4->vllm==0.8.4)\n",
      "  Downloading mistral_common-1.8.5-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting opencv-python-headless>=4.11.0 (from vllm==0.8.4)\n",
      "  Downloading opencv_python_headless-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from vllm==0.8.4) (6.0.3)\n",
      "Requirement already satisfied: six>=1.16.0 in /usr/lib/python3/dist-packages (from vllm==0.8.4) (1.16.0)\n",
      "Requirement already satisfied: setuptools>=74.1.1 in /usr/local/lib/python3.12/dist-packages (from vllm==0.8.4) (80.9.0)\n",
      "Collecting einops (from vllm==0.8.4)\n",
      "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting compressed-tensors==0.9.3 (from vllm==0.8.4)\n",
      "  Downloading compressed_tensors-0.9.3-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting depyf==0.18.0 (from vllm==0.8.4)\n",
      "  Downloading depyf-0.18.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting cloudpickle (from vllm==0.8.4)\n",
      "  Downloading cloudpickle-3.1.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting watchfiles (from vllm==0.8.4)\n",
      "  Downloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: python-json-logger in /usr/local/lib/python3.12/dist-packages (from vllm==0.8.4) (4.0.0)\n",
      "Collecting scipy (from vllm==0.8.4)\n",
      "  Downloading scipy-1.16.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (62 kB)\n",
      "Collecting ninja (from vllm==0.8.4)\n",
      "  Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
      "Collecting opentelemetry-sdk<1.27.0,>=1.26.0 (from vllm==0.8.4)\n",
      "  Downloading opentelemetry_sdk-1.26.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-api<1.27.0,>=1.26.0 (from vllm==0.8.4)\n",
      "  Downloading opentelemetry_api-1.26.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp<1.27.0,>=1.26.0 (from vllm==0.8.4)\n",
      "  Downloading opentelemetry_exporter_otlp-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-semantic-conventions-ai<0.5.0,>=0.4.1 (from vllm==0.8.4)\n",
      "  Downloading opentelemetry_semantic_conventions_ai-0.4.13-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting numba==0.61.2 (from vllm==0.8.4)\n",
      "  Downloading numba-0.61.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
      "Collecting ray!=2.44.*,>=2.43.0 (from ray[cgraph]!=2.44.*,>=2.43.0->vllm==0.8.4)\n",
      "  Downloading ray-2.52.1-cp312-cp312-manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Collecting torch==2.6.0 (from vllm==0.8.4)\n",
      "  Downloading torch-2.6.0-cp312-cp312-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Collecting torchaudio==2.6.0 (from vllm==0.8.4)\n",
      "  Downloading torchaudio-2.6.0-cp312-cp312-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting torchvision==0.21.0 (from vllm==0.8.4)\n",
      "  Downloading torchvision-0.21.0-cp312-cp312-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting xformers==0.0.29.post2 (from vllm==0.8.4)\n",
      "  Downloading xformers-0.0.29.post2-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (1.2 kB)\n",
      "Collecting astor (from depyf==0.18.0->vllm==0.8.4)\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from depyf==0.18.0->vllm==0.8.4) (0.3.8)\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba==0.61.2->vllm==0.8.4)\n",
      "  Downloading llvmlite-0.44.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting interegular (from outlines==0.1.11->vllm==0.8.4)\n",
      "  Downloading interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from outlines==0.1.11->vllm==0.8.4) (3.1.6)\n",
      "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.12/dist-packages (from outlines==0.1.11->vllm==0.8.4) (1.6.0)\n",
      "Collecting diskcache (from outlines==0.1.11->vllm==0.8.4)\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: referencing in /usr/local/lib/python3.12/dist-packages (from outlines==0.1.11->vllm==0.8.4) (0.36.2)\n",
      "Requirement already satisfied: jsonschema in /usr/local/lib/python3.12/dist-packages (from outlines==0.1.11->vllm==0.8.4) (4.25.1)\n",
      "Collecting pycountry (from outlines==0.1.11->vllm==0.8.4)\n",
      "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting airportsdata (from outlines==0.1.11->vllm==0.8.4)\n",
      "  Downloading airportsdata-20250909-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting outlines_core==0.1.26 (from outlines==0.1.11->vllm==0.8.4)\n",
      "  Downloading outlines_core-0.1.26-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.6.0->vllm==0.8.4) (3.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.6.0->vllm==0.8.4) (2024.6.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0->vllm==0.8.4)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0->vllm==0.8.4)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0->vllm==0.8.4)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0->vllm==0.8.4)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0->vllm==0.8.4)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0->vllm==0.8.4)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0->vllm==0.8.4)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0->vllm==0.8.4)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0->vllm==0.8.4)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch==2.6.0->vllm==0.8.4)\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch==2.6.0->vllm==0.8.4)\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch==2.6.0->vllm==0.8.4)\n",
      "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0->vllm==0.8.4)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.2.0 (from torch==2.6.0->vllm==0.8.4)\n",
      "  Downloading triton-3.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting sympy==1.13.1 (from torch==2.6.0->vllm==0.8.4)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch==2.6.0->vllm==0.8.4) (1.3.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from lm-format-enforcer<0.11,>=0.10.11->vllm==0.8.4) (25.0)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api<1.27.0,>=1.26.0->vllm==0.8.4)\n",
      "  Downloading deprecated-1.3.1-py2.py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting importlib_metadata (from vllm==0.8.4)\n",
      "  Downloading importlib_metadata-8.0.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting zipp>=0.5 (from importlib_metadata->vllm==0.8.4)\n",
      "  Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc==1.26.0 (from opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm==0.8.4)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-http==1.26.0 (from opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm==0.8.4)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_http-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm==0.8.4)\n",
      "  Downloading googleapis_common_protos-1.72.0-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting grpcio<2.0.0,>=1.0.0 (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm==0.8.4)\n",
      "  Downloading grpcio-1.76.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.7 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.26.0 (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm==0.8.4)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.26.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.26.0 (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm==0.8.4)\n",
      "  Downloading opentelemetry_proto-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting protobuf (from vllm==0.8.4)\n",
      "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Collecting opentelemetry-semantic-conventions==0.47b0 (from opentelemetry-sdk<1.27.0,>=1.26.0->vllm==0.8.4)\n",
      "  Downloading opentelemetry_semantic_conventions-0.47b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm==0.8.4) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm==0.8.4) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm==0.8.4) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm==0.8.4) (2025.10.5)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
      "Collecting jiter<1,>=0.10.0 (from openai)\n",
      "  Downloading jiter-0.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.9->vllm==0.8.4)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic>=2.9->vllm==0.8.4)\n",
      "  Downloading pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic>=2.9->vllm==0.8.4)\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting wrapt<3,>=1.10 (from deprecated>=1.2.6->opentelemetry-api<1.27.0,>=1.26.0->vllm==0.8.4)\n",
      "  Downloading wrapt-2.0.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting starlette<0.51.0,>=0.40.0 (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm==0.8.4)\n",
      "  Downloading starlette-0.50.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting annotated-doc>=0.0.2 (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm==0.8.4)\n",
      "  Downloading annotated_doc-0.0.4-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting fastapi-cli>=0.0.8 (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.8.4)\n",
      "  Downloading fastapi_cli-0.0.16-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting python-multipart>=0.0.18 (from fastapi[standard]>=0.115.0->vllm==0.8.4)\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting email-validator>=2.0.0 (from fastapi[standard]>=0.115.0->vllm==0.8.4)\n",
      "  Downloading email_validator-2.3.0-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting uvicorn>=0.12.0 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.8.4)\n",
      "  Downloading uvicorn-0.38.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->vllm==0.8.4)\n",
      "  Downloading dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting typer>=0.15.1 (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.8.4)\n",
      "  Downloading typer-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting rich-toolkit>=0.14.8 (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.8.4)\n",
      "  Downloading rich_toolkit-0.17.0-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting fastapi-cloud-cli>=0.1.1 (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.8.4)\n",
      "  Downloading fastapi_cloud_cli-0.5.2-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting rignore>=0.5.1 (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.8.4)\n",
      "  Downloading rignore-0.7.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting sentry-sdk>=2.20.0 (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.8.4)\n",
      "  Downloading sentry_sdk-2.46.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting fastar>=0.5.0 (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.8.4)\n",
      "  Downloading fastar-0.8.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.30.0->huggingface-hub[hf_xet]>=0.30.0->vllm==0.8.4) (1.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->outlines==0.1.11->vllm==0.8.4) (3.0.3)\n",
      "Collecting pydantic-extra-types>=2.10.5 (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.5.4->mistral_common[opencv]>=1.5.4->vllm==0.8.4)\n",
      "  Downloading pydantic_extra_types-2.10.6-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema->outlines==0.1.11->vllm==0.8.4) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema->outlines==0.1.11->vllm==0.8.4) (2025.9.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema->outlines==0.1.11->vllm==0.8.4) (0.27.1)\n",
      "Collecting click!=8.3.*,>=7.0 (from ray!=2.44.*,>=2.43.0->ray[cgraph]!=2.44.*,>=2.43.0->vllm==0.8.4)\n",
      "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting msgpack<2.0.0,>=1.0.0 (from ray!=2.44.*,>=2.43.0->ray[cgraph]!=2.44.*,>=2.43.0->vllm==0.8.4)\n",
      "  Downloading msgpack-1.1.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
      "Collecting cupy-cuda12x (from ray[cgraph]!=2.44.*,>=2.43.0->vllm==0.8.4)\n",
      "  Downloading cupy_cuda12x-13.6.0-cp312-cp312-manylinux2014_x86_64.whl.metadata (2.4 kB)\n",
      "Collecting rich>=13.7.1 (from rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.8.4)\n",
      "  Downloading rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.8.4)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.8.4) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.8.4)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken>=0.6.0->vllm==0.8.4) (2025.11.3)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51.1->vllm==0.8.4) (0.6.2)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.15.1->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.8.4)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.8.4)\n",
      "  Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (3.5 kB)\n",
      "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.8.4)\n",
      "  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.8.4)\n",
      "  Downloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.8.4)\n",
      "  Downloading websockets-15.0.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm==0.8.4) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm==0.8.4) (1.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm==0.8.4) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm==0.8.4) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm==0.8.4) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm==0.8.4) (1.22.0)\n",
      "Collecting fastrlock>=0.5 (from cupy-cuda12x->ray[cgraph]!=2.44.*,>=2.43.0->vllm==0.8.4)\n",
      "  Downloading fastrlock-0.8.3-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl.metadata (7.7 kB)\n",
      "Downloading vllm-0.8.4-cp38-abi3-manylinux1_x86_64.whl (294.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.1/294.1 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading compressed_tensors-0.9.3-py3-none-any.whl (98 kB)\n",
      "Downloading depyf-0.18.0-py3-none-any.whl (38 kB)\n",
      "Downloading lark-1.2.2-py3-none-any.whl (111 kB)\n",
      "Downloading numba-0.61.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading outlines-0.1.11-py3-none-any.whl (87 kB)\n",
      "Downloading outlines_core-0.1.26-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (343 kB)\n",
      "Downloading torch-2.6.0-cp312-cp312-manylinux1_x86_64.whl (766.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.6/766.6 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m  \u001b[33m0:00:07\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m  \u001b[33m0:00:06\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m92.5 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m98.2 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m82.9 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchaudio-2.6.0-cp312-cp312-manylinux1_x86_64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.21.0-cp312-cp312-manylinux1_x86_64.whl (7.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading xformers-0.0.29.post2-cp312-cp312-manylinux_2_28_x86_64.whl (44.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading xgrammar-0.1.18-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llguidance-0.7.30-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.0/15.0 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.44.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading lm_format_enforcer-0.10.12-py3-none-any.whl (44 kB)\n",
      "Downloading opentelemetry_api-1.26.0-py3-none-any.whl (61 kB)\n",
      "Downloading importlib_metadata-8.0.0-py3-none-any.whl (24 kB)\n",
      "Downloading opentelemetry_exporter_otlp-1.26.0-py3-none-any.whl (7.0 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.26.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.26.0-py3-none-any.whl (17 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_http-1.26.0-py3-none-any.whl (16 kB)\n",
      "Downloading opentelemetry_proto-1.26.0-py3-none-any.whl (52 kB)\n",
      "Downloading googleapis_common_protos-1.72.0-py3-none-any.whl (297 kB)\n",
      "Downloading grpcio-1.76.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_sdk-1.26.0-py3-none-any.whl (109 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.47b0-py3-none-any.whl (138 kB)\n",
      "Downloading opentelemetry_semantic_conventions_ai-0.4.13-py3-none-any.whl (6.1 kB)\n",
      "Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "Downloading openai-2.8.1-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jiter-0.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (361 kB)\n",
      "Downloading pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "Downloading pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading deprecated-1.3.1-py2.py3-none-any.whl (11 kB)\n",
      "Downloading wrapt-2.0.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (121 kB)\n",
      "Downloading fastapi-0.122.0-py3-none-any.whl (110 kB)\n",
      "Downloading starlette-0.50.0-py3-none-any.whl (74 kB)\n",
      "Downloading annotated_doc-0.0.4-py3-none-any.whl (5.3 kB)\n",
      "Downloading email_validator-2.3.0-py3-none-any.whl (35 kB)\n",
      "Downloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n",
      "Downloading fastapi_cli-0.0.16-py3-none-any.whl (12 kB)\n",
      "Downloading fastapi_cloud_cli-0.5.2-py3-none-any.whl (23 kB)\n",
      "Downloading fastar-0.8.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (821 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.6/821.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gguf-0.17.1-py3-none-any.whl (96 kB)\n",
      "Downloading interegular-0.3.3-py37-none-any.whl (23 kB)\n",
      "Downloading mistral_common-1.8.5-py3-none-any.whl (6.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opencv_python_headless-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (54.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl (19 kB)\n",
      "Downloading pydantic_extra_types-2.10.6-py3-none-any.whl (40 kB)\n",
      "Downloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading ray-2.52.1-cp312-cp312-manylinux2014_x86_64.whl (72.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.3/72.3 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m6m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading msgpack-1.1.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (427 kB)\n",
      "Downloading click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Downloading rich_toolkit-0.17.0-py3-none-any.whl (31 kB)\n",
      "Downloading rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading rignore-0.7.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (959 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m959.8/959.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sentry_sdk-2.46.0-py2.py3-none-any.whl (406 kB)\n",
      "Downloading tiktoken-0.12.0-cp312-cp312-manylinux_2_28_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typer-0.20.0-py3-none-any.whl (47 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading uvicorn-0.38.0-py3-none-any.whl (68 kB)\n",
      "Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (517 kB)\n",
      "Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Downloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (4.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (456 kB)\n",
      "Downloading websockets-15.0.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (182 kB)\n",
      "Downloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "Downloading airportsdata-20250909-py3-none-any.whl (914 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m914.4/914.4 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Downloading blake3-1.0.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (388 kB)\n",
      "Downloading cachetools-6.2.2-py3-none-any.whl (11 kB)\n",
      "Downloading cloudpickle-3.1.2-py3-none-any.whl (22 kB)\n",
      "Downloading cupy_cuda12x-13.6.0-cp312-cp312-manylinux2014_x86_64.whl (112.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.9/112.9 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading fastrlock-0.8.3-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl (53 kB)\n",
      "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "Downloading msgspec-0.20.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (224 kB)\n",
      "Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)\n",
      "Downloading partial_json_parser-0.2.1.1.post7-py3-none-any.whl (10 kB)\n",
      "Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Downloading scipy-1.16.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sentencepiece-0.2.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: triton, py-cpuinfo, nvidia-cusparselt-cu12, fastrlock, zipp, wrapt, websockets, uvloop, typing-inspection, sympy, shellingham, sentry-sdk, sentencepiece, scipy, rignore, python-multipart, python-dotenv, pydantic-core, pycountry, protobuf, partial-json-parser, opentelemetry-semantic-conventions-ai, opencv-python-headless, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ninja, msgspec, msgpack, mdurl, llvmlite, llguidance, lark, jiter, interegular, httptools, grpcio, gguf, fastar, einops, dnspython, diskcache, cupy-cuda12x, cloudpickle, click, cachetools, blake3, astor, annotated-types, annotated-doc, airportsdata, watchfiles, uvicorn, tiktoken, starlette, pydantic, opentelemetry-proto, nvidia-cusparse-cu12, nvidia-cudnn-cu12, numba, markdown-it-py, importlib_metadata, googleapis-common-protos, email-validator, depyf, deprecated, rich, pydantic-extra-types, prometheus-fastapi-instrumentator, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, openai, nvidia-cusolver-cu12, lm-format-enforcer, fastapi, typer, torch, rich-toolkit, ray, outlines_core, opentelemetry-semantic-conventions, xgrammar, xformers, torchvision, torchaudio, outlines, opentelemetry-sdk, mistral_common, fastapi-cloud-cli, fastapi-cli, compressed-tensors, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-exporter-otlp, vllm\n",
      "\u001b[2K  Attempting uninstall: triton\n",
      "\u001b[2K    Found existing installation: triton 3.4.0\n",
      "\u001b[2K    Uninstalling triton-3.4.0:\n",
      "\u001b[2K      Successfully uninstalled triton-3.4.0━━━━━\u001b[0m \u001b[32m  0/101\u001b[0m [triton]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusparselt-cu12━━\u001b[0m \u001b[32m  0/101\u001b[0m [triton]\n",
      "\u001b[2K    Found existing installation: nvidia-cusparselt-cu12 0.7.1\u001b[0m [triton]\n",
      "\u001b[2K    Uninstalling nvidia-cusparselt-cu12-0.7.1:0m \u001b[32m  0/101\u001b[0m [triton]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusparselt-cu12-0.7.10m \u001b[32m  2/101\u001b[0m [nvidia-cusparselt-cu12]\n",
      "\u001b[2K  Attempting uninstall: sympy━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m  7/101\u001b[0m [uvloop]ck]u12]\n",
      "\u001b[2K    Found existing installation: sympy 1.13.3━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m  7/101\u001b[0m [uvloop]\n",
      "\u001b[2K    Uninstalling sympy-1.13.3:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m  9/101\u001b[0m [sympy]\n",
      "\u001b[2K      Successfully uninstalled sympy-1.13.3━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m  9/101\u001b[0m [sympy]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nvtx-cu12━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 22/101\u001b[0m [opencv-python-headless]\n",
      "\u001b[2K    Found existing installation: nvidia-nvtx-cu12 12.8.90━━━━━\u001b[0m \u001b[32m 22/101\u001b[0m [opencv-python-headless]\n",
      "\u001b[2K    Uninstalling nvidia-nvtx-cu12-12.8.90:━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 23/101\u001b[0m [nvidia-nvtx-cu12]s]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nvtx-cu12-12.8.90━━━━━━━\u001b[0m \u001b[32m 23/101\u001b[0m [nvidia-nvtx-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nvjitlink-cu12━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 23/101\u001b[0m [nvidia-nvtx-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\u001b[0m \u001b[32m 23/101\u001b[0m [nvidia-nvtx-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-nvjitlink-cu12-12.8.93:━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 23/101\u001b[0m [nvidia-nvtx-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93━━\u001b[0m \u001b[32m 23/101\u001b[0m [nvidia-nvtx-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nccl-cu12━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 24/101\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-nccl-cu12 2.27.3━━━━━━\u001b[0m \u001b[32m 24/101\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-nccl-cu12-2.27.3:━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 24/101\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nccl-cu12-2.27.3━━━━━━━━━━━━\u001b[0m \u001b[32m 25/101\u001b[0m [nvidia-nccl-cu12]]\n",
      "\u001b[2K  Attempting uninstall: nvidia-curand-cu12━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 25/101\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-curand-cu12 10.3.9.90━\u001b[0m \u001b[32m 25/101\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-curand-cu12-10.3.9.90:━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 25/101\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-curand-cu12-10.3.9.90━━━━━━━\u001b[0m \u001b[32m 26/101\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cufft-cu12━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 26/101\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cufft-cu12 11.3.3.83━━\u001b[0m \u001b[32m 26/101\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cufft-cu12-11.3.3.83:━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 26/101\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83━━━━━━━━\u001b[0m \u001b[32m 27/101\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-runtime-cu12━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 27/101\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-runtime-cu12 12.8.90m \u001b[32m 27/101\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-runtime-cu12-12.8.90:━━━━━━━━━━━━\u001b[0m \u001b[32m 27/101\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-runtime-cu12-12.8.90[0m \u001b[32m 27/101\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-nvrtc-cu12━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 27/101\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-nvrtc-cu12 12.8.93[0m \u001b[32m 27/101\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-nvrtc-cu12-12.8.93:━━━━━━━━━━━━━━\u001b[0m \u001b[32m 27/101\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.8.93━━━━━\u001b[0m \u001b[32m 29/101\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-cupti-cu12━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 29/101\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-cupti-cu12 12.8.90[0m \u001b[32m 29/101\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-cupti-cu12-12.8.90:━━━━━━━━━━━━━━\u001b[0m \u001b[32m 29/101\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-cupti-cu12-12.8.90━━━━━\u001b[0m \u001b[32m 30/101\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cublas-cu12━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 30/101\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cublas-cu12 12.8.4.1━━\u001b[0m \u001b[32m 30/101\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cublas-cu12-12.8.4.1:━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 30/101\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1━━━━━━━━\u001b[0m \u001b[32m 31/101\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K  Attempting uninstall: lark91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 37/101\u001b[0m [llguidance]as-cu12]\n",
      "\u001b[2K    Found existing installation: lark 1.3.0━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 37/101\u001b[0m [llguidance]\n",
      "\u001b[2K    Uninstalling lark-1.3.0:\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 37/101\u001b[0m [llguidance]\n",
      "\u001b[2K      Successfully uninstalled lark-1.3.0━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 37/101\u001b[0m [llguidance]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusparse-cu120m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 62/101\u001b[0m [opentelemetry-proto]\n",
      "\u001b[2K    Found existing installation: nvidia-cusparse-cu12 12.5.8.93[0m \u001b[32m 62/101\u001b[0m [opentelemetry-proto]\n",
      "\u001b[2K    Uninstalling nvidia-cusparse-cu12-12.5.8.93:━━━━━━━━━━━━━━\u001b[0m \u001b[32m 62/101\u001b[0m [opentelemetry-proto]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93━━━━━\u001b[0m \u001b[32m 63/101\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cudnn-cu12╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 63/101\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cudnn-cu12 9.10.2.21━━\u001b[0m \u001b[32m 63/101\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cudnn-cu12-9.10.2.21:0m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 63/101\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21━━━━━━━━\u001b[0m \u001b[32m 64/101\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusolver-cu1290m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m 77/101\u001b[0m [openai]ted]-py]12]\n",
      "\u001b[2K    Found existing installation: nvidia-cusolver-cu12 11.7.3.90[0m \u001b[32m 77/101\u001b[0m [openai]\n",
      "\u001b[2K    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m 77/101\u001b[0m [openai]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90━━━━━\u001b[0m \u001b[32m 78/101\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K  Attempting uninstall: torch━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m 79/101\u001b[0m [lm-format-enforcer]2]\n",
      "\u001b[2K    Found existing installation: torch 2.8.0+cu128[90m━━━━━━━━\u001b[0m \u001b[32m 79/101\u001b[0m [lm-format-enforcer]\n",
      "\u001b[2K    Uninstalling torch-2.8.0+cu128:━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m 82/101\u001b[0m [torch]enforcer]\n",
      "\u001b[2K      Successfully uninstalled torch-2.8.0+cu128m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m 82/101\u001b[0m [torch]\n",
      "\u001b[2K  Attempting uninstall: torchvision━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m 88/101\u001b[0m [xformers]antic-conventions]\n",
      "\u001b[2K    Found existing installation: torchvision 0.23.0+cu128━━━━━\u001b[0m \u001b[32m 88/101\u001b[0m [xformers]\n",
      "\u001b[2K    Uninstalling torchvision-0.23.0+cu128:\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m 88/101\u001b[0m [xformers]\n",
      "\u001b[2K      Successfully uninstalled torchvision-0.23.0+cu1280m\u001b[90m━━━━\u001b[0m \u001b[32m 89/101\u001b[0m [torchvision]\n",
      "\u001b[2K  Attempting uninstall: torchaudio━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m 89/101\u001b[0m [torchvision]\n",
      "\u001b[2K    Found existing installation: torchaudio 2.8.0+cu12890m━━━━\u001b[0m \u001b[32m 89/101\u001b[0m [torchvision]\n",
      "\u001b[2K    Uninstalling torchaudio-2.8.0+cu128:[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m 89/101\u001b[0m [torchvision]\n",
      "\u001b[2K      Successfully uninstalled torchaudio-2.8.0+cu128\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m 90/101\u001b[0m [torchaudio]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101/101\u001b[0m [vllm]0m [vllm]metry-exporter-otlp-proto-http]\n",
      "\u001b[1A\u001b[2KSuccessfully installed airportsdata-20250909 annotated-doc-0.0.4 annotated-types-0.7.0 astor-0.8.1 blake3-1.0.8 cachetools-6.2.2 click-8.2.1 cloudpickle-3.1.2 compressed-tensors-0.9.3 cupy-cuda12x-13.6.0 deprecated-1.3.1 depyf-0.18.0 diskcache-5.6.3 dnspython-2.8.0 einops-0.8.1 email-validator-2.3.0 fastapi-0.122.0 fastapi-cli-0.0.16 fastapi-cloud-cli-0.5.2 fastar-0.8.0 fastrlock-0.8.3 gguf-0.17.1 googleapis-common-protos-1.72.0 grpcio-1.76.0 httptools-0.7.1 importlib_metadata-8.0.0 interegular-0.3.3 jiter-0.12.0 lark-1.2.2 llguidance-0.7.30 llvmlite-0.44.0 lm-format-enforcer-0.10.12 markdown-it-py-4.0.0 mdurl-0.1.2 mistral_common-1.8.5 msgpack-1.1.2 msgspec-0.20.0 ninja-1.13.0 numba-0.61.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 openai-2.8.1 opencv-python-headless-4.12.0.88 opentelemetry-api-1.26.0 opentelemetry-exporter-otlp-1.26.0 opentelemetry-exporter-otlp-proto-common-1.26.0 opentelemetry-exporter-otlp-proto-grpc-1.26.0 opentelemetry-exporter-otlp-proto-http-1.26.0 opentelemetry-proto-1.26.0 opentelemetry-sdk-1.26.0 opentelemetry-semantic-conventions-0.47b0 opentelemetry-semantic-conventions-ai-0.4.13 outlines-0.1.11 outlines_core-0.1.26 partial-json-parser-0.2.1.1.post7 prometheus-fastapi-instrumentator-7.1.0 protobuf-4.25.8 py-cpuinfo-9.0.0 pycountry-24.6.1 pydantic-2.12.5 pydantic-core-2.41.5 pydantic-extra-types-2.10.6 python-dotenv-1.2.1 python-multipart-0.0.20 ray-2.52.1 rich-14.2.0 rich-toolkit-0.17.0 rignore-0.7.6 scipy-1.16.3 sentencepiece-0.2.1 sentry-sdk-2.46.0 shellingham-1.5.4 starlette-0.50.0 sympy-1.13.1 tiktoken-0.12.0 torch-2.6.0 torchaudio-2.6.0 torchvision-0.21.0 triton-3.2.0 typer-0.20.0 typing-inspection-0.4.2 uvicorn-0.38.0 uvloop-0.22.1 vllm-0.8.4 watchfiles-1.1.1 websockets-15.0.1 wrapt-2.0.1 xformers-0.0.29.post2 xgrammar-0.1.18 zipp-3.23.0\n"
     ]
    }
   ],
   "source": [
    "!pip install openai vllm==0.8.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76d455e7-3c11-4a33-a3ca-e5a72639bbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-28 06:58:28 [__init__.py:239] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from typing import List\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_from_disk\n",
    "from vllm import LLM, SamplingParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90713ee6-2d2e-4d57-8225-dd4a6d0f257d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e68834cc61b44b0b1dab02d38e0e373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 11-28 06:58:31 [config.py:2836] Casting torch.float16 to torch.bfloat16.\n",
      "INFO 11-28 06:58:42 [config.py:689] This model supports multiple tasks: {'generate', 'embed', 'reward', 'classify', 'score'}. Defaulting to 'generate'.\n",
      "INFO 11-28 06:58:42 [config.py:1901] Chunked prefill is enabled with max_num_batched_tokens=8192.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd857424d0ee40d28cd490344c71b609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "054ce7730fb1474ead4a37961573919f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef380794c100479887ad060474ba6070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8d28ea261c9424d8d11365296c7e24d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d6bb2ec67244310b00ce90556e422bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/707 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8084bf6e391b4e5a8ec1021bcfebcfd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/613 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87e028e7fe06404787014374352e6c32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.jinja: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc72e0d60c5f47c99bff8226ace66497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/213 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-28 06:58:48 [core.py:61] Initializing a V1 LLM engine (v0.8.4) with config: model='iamjoon/qwen3-4b-text-to-sql-ko-checkpoint-750', speculative_config=None, tokenizer='iamjoon/qwen3-4b-text-to-sql-ko-checkpoint-750', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=262144, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=iamjoon/qwen3-4b-text-to-sql-ko-checkpoint-750, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":3,\"custom_ops\":[\"none\"],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\"],\"use_inductor\":true,\"compile_sizes\":[],\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":512}\n",
      "WARNING 11-28 06:58:49 [utils.py:2444] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f714859be00>\n",
      "INFO 11-28 06:58:50 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0\n",
      "INFO 11-28 06:58:50 [cuda.py:221] Using Flash Attention backend on V1 engine.\n",
      "INFO 11-28 06:58:50 [gpu_model_runner.py:1276] Starting to load model iamjoon/qwen3-4b-text-to-sql-ko-checkpoint-750...\n",
      "WARNING 11-28 06:58:50 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "INFO 11-28 06:58:51 [weight_utils.py:265] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce0724ec3adc46bf909a41494091e150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e399fba460fb45599dbd55c87db990bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.08G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-28 07:01:27 [weight_utils.py:281] Time spent downloading weights for iamjoon/qwen3-4b-text-to-sql-ko-checkpoint-750: 156.628537 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf1b36ca2506474b8d2d19edc0fc40db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb25e36e165d4bf9b7a89bc7f8ef9e8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-28 07:01:37 [loader.py:458] Loading weights took 9.31 seconds\n",
      "INFO 11-28 07:01:37 [gpu_model_runner.py:1291] Model loading took 7.6064 GiB and 166.935592 seconds\n",
      "INFO 11-28 07:01:48 [backends.py:416] Using cache directory: /root/.cache/vllm/torch_compile_cache/8b69c4817e/rank_0_0 for vLLM's torch.compile\n",
      "INFO 11-28 07:01:48 [backends.py:426] Dynamo bytecode transform time: 10.48 s\n",
      "INFO 11-28 07:01:54 [backends.py:132] Cache the graph of shape None for later use\n",
      "INFO 11-28 07:02:29 [backends.py:144] Compiling a graph for general shape takes 40.17 s\n",
      "INFO 11-28 07:03:10 [monitor.py:33] torch.compile takes 50.65 s in total\n",
      "INFO 11-28 07:03:11 [kv_cache_utils.py:634] GPU KV cache size: 449,616 tokens\n",
      "INFO 11-28 07:03:11 [kv_cache_utils.py:637] Maximum concurrency for 262,144 tokens per request: 1.72x\n",
      "INFO 11-28 07:03:40 [gpu_model_runner.py:1626] Graph capturing finished in 29 secs, took 0.59 GiB\n",
      "INFO 11-28 07:03:40 [core.py:163] init engine (profile, create kv cache, warmup model) took 122.32 seconds\n",
      "INFO 11-28 07:03:40 [core_client.py:435] Core engine process 0 ready.\n"
     ]
    }
   ],
   "source": [
    "vllm_model = LLM(\n",
    "    model=\"iamjoon/qwen3-4b-text-to-sql-ko-checkpoint-750\",\n",
    "    dtype=\"bfloat16\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb92b74a-e1c3-40c8-8663-1051194d5b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 데이터 개수: 776\n",
      "Train: 621개\n",
      "Test:  155개\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import random\n",
    "\n",
    "# 시드 고정\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "\n",
    "# 1. 허깅페이스 허브에서 데이터셋 로드\n",
    "dataset = load_dataset(\"iamjoon/manufacturing-text-to-sql\", split=\"train\")\n",
    "print(f\"원본 데이터 개수: {len(dataset)}\")\n",
    "\n",
    "# 2. train/test split\n",
    "test_ratio = 0.2\n",
    "indices = list(range(len(dataset)))\n",
    "random.shuffle(indices)\n",
    "test_size = int(len(indices) * test_ratio)\n",
    "test_indices = indices[:test_size]\n",
    "train_indices = indices[test_size:]\n",
    "\n",
    "# 3. OpenAI format 변환 함수\n",
    "def format_data(sample):\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": sample[\"system_prompt\"]},\n",
    "            {\"role\": \"user\", \"content\": sample[\"user_prompt\"]},\n",
    "            {\"role\": \"assistant\", \"content\": sample[\"assistant\"]},\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# 4. 변환\n",
    "train_dataset = [format_data(dataset[i]) for i in train_indices]\n",
    "test_dataset = [format_data(dataset[i]) for i in test_indices]\n",
    "\n",
    "# 5. 결과 출력\n",
    "print(f\"Train: {len(train_dataset)}개\")\n",
    "print(f\"Test:  {len(test_dataset)}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b31243f1-dc3d-460c-a47c-a88b511918f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'datasets.arrow_dataset.Dataset'>\n",
      "<class 'datasets.arrow_dataset.Dataset'>\n"
     ]
    }
   ],
   "source": [
    "# 리스트 형태에서 다시 Dataset 객체로 변경\n",
    "print(type(train_dataset))\n",
    "print(type(test_dataset))\n",
    "train_dataset = Dataset.from_list(train_dataset)\n",
    "test_dataset = Dataset.from_list(test_dataset)\n",
    "print(type(train_dataset))\n",
    "print(type(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "872b0c31-76af-4bbb-9190-8c177df4453d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"iamjoon/qwen3-4b-text-to-sql-ko-checkpoint-150\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a63e1802-9b18-4700-8350-2083cd1698a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_lst = []\n",
    "label_lst = []\n",
    "questions = []\n",
    "contexts = []\n",
    "\n",
    "for prompt in test_dataset[\"messages\"]:\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        prompt, tokenize=False, add_generation_prompt=False\n",
    "    )\n",
    "    input = text.split('<|im_start|>assistant')[0] + '<|im_start|>assistant'\n",
    "    label = text.split('<|im_start|>assistant')[1].split('<|im_end|>')[0]\n",
    "    question = text.split('<|im_start|>user')[1].split('<|im_end|>')[0].strip()\n",
    "    prompt_lst.append(input)\n",
    "    label_lst.append(label)\n",
    "    questions.append(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb0ebc98-6cfb-493e-823e-15b1588fb50e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'포르쉐라인에서 2025년 3월 오전(08~19시)과 야간(그 외) 수율을 비교해줘.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72237b06-cf5e-486c-a86f-7667341d62b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nWITH FD AS (SELECT LOTNO, CASE WHEN HOUR(ACTUALTIME) BETWEEN 8 AND 19 THEN 'DAY_SHIFT' ELSE 'NIGHT_SHIFT' END AS SHIFT_GRP, SUM(TRANSQTY) AS FINISHSUM FROM LOG_LOTTRANSLOG WHERE LINENO='ML0000' AND TRANSACTIONNAME='FINISH' AND DATE_FORMAT(ACTUALTIME,'%Y%m')='202503' GROUP BY LOTNO, CASE WHEN HOUR(ACTUALTIME) BETWEEN 8 AND 19 THEN 'DAY_SHIFT' ELSE 'NIGHT_SHIFT' END), SD AS (SELECT LOTNO, CASE WHEN HOUR(ACTUALTIME) BETWEEN 8 AND 19 THEN 'DAY_SHIFT' ELSE 'NIGHT_SHIFT' END AS SHIFT_GRP, SUM(TRANSQTY) AS STARTSUM FROM LOG_LOTTRANSLOG WHERE LINENO='ML0000' AND TRANSACTIONNAME='START' AND DATE_FORMAT(ACTUALTIME,'%Y%m')='202503' GROUP BY LOTNO, CASE WHEN HOUR(ACTUALTIME) BETWEEN 8 AND 19 THEN 'DAY_SHIFT' ELSE 'NIGHT_SHIFT' END) SELECT FD.SHIFT_GRP, ROUND((SUM(FD.FINISHSUM)/NULLIF(SUM(SD.STARTSUM),0))*100,2) AS YIELD_PCT FROM FD INNER JOIN SD ON FD.LOTNO=SD.LOTNO AND FD.SHIFT_GRP=SD.SHIFT_GRP GROUP BY FD.SHIFT_GRP;\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_lst[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1858d8e1-1073-4c83-939e-8a84bc2b046f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성 파라미터 설정\n",
    "sampling_params = SamplingParams(\n",
    "    temperature=0,\n",
    "    max_tokens=2048,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fb19a33-e6e7-4be1-9602-804c47872d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3af97ed76d41451aa251267804e59cd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/155 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = vllm_model.generate(prompt_lst, sampling_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c689597d-d9ef-42b2-9770-a4a814ef21b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [pred.outputs[0].text for pred in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d77e59d4-ea01-4447-92dc-7d3c0cd4fcf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nWITH DAILY AS ( SELECT DATE(ACTUALTIME) AS WORKDATE, SUM(TRANSQTY) AS TOTAL_PROD FROM LOG_LOTTRANSLOG WHERE LINENO = 'ML0000' AND TRANSACTIONNAME = 'FINISH' AND DATE_FORMAT(ACTUALTIME, '%Y') = '2025' GROUP BY DATE(ACTUALTIME) ) SELECT WORKDATE, TOTAL_PROD, ROUND((SUM(TOTAL_PROD) OVER (ORDER BY WORKDATE ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)) / NULLIF(SUM(TRANSQTY) OVER (ORDER BY WORKDATE ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), 0) * 100, 2) AS CUMULATIVE_YIELD_PCT FROM DAILY ORDER BY WORKDATE;\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc8afa3f-99a7-4290-9d42-71c836409727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI API 초기화\n",
    "client = OpenAI(api_key=\"여러분의 키 값\")  # 본인의 API 키로 교체하세요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffde7ff-c2ce-44a1-9094-9e7d0599ddf7",
   "metadata": {},
   "source": [
    "## LLM 기반의 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69bf5c92-fc01-4b17-8fb1-a6d802db7f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "def evaluate_sql_equivalence(\n",
    "    gold_sql: str,\n",
    "    predicted_sql: str,\n",
    "    schema: Optional[str] = None,\n",
    "    question: Optional[str] = None\n",
    ") -> dict:\n",
    "    \n",
    "    system_prompt = \"\"\"당신은 SQL 쿼리의 의미적 동등성을 평가하는 전문가입니다.\n",
    "\n",
    "두 SQL 쿼리가 의미적으로 동등한지 판단해야 합니다.\n",
    "의미적 동등성이란, 어떤 유효한 데이터베이스 상태에서든 동일한 결과를 반환하는 것을 의미합니다.\n",
    "\n",
    "평가 시 고려사항:\n",
    "1. SELECT 컬럼 순서는 동등성에 영향을 주지 않음\n",
    "2. WHERE 절의 AND/OR 조건 순서가 달라도 논리적으로 동등하면 동등함\n",
    "3. 명시적 JOIN과 콤마로 구분된 FROM + WHERE 조건은 동등할 수 있음\n",
    "4. 별칭(alias)은 동등성에 영향을 주지 않음\n",
    "5. DISTINCT 필요 여부는 스키마에 따라 다름\n",
    "6. 서브쿼리와 JOIN은 동등할 수 있음\n",
    "7. 다른 집계 방식도 같은 결과를 낼 수 있음\n",
    "\n",
    "엄격하되 공정하게 평가하세요. 어떤 유효한 시나리오에서든 다른 결과를 낼 수 있는 쿼리는 동등하지 않습니다.\n",
    "\n",
    "반드시 아래 JSON 형식으로만 응답하세요:\n",
    "{\n",
    "    \"is_equivalent\": true 또는 false\n",
    "}\"\"\"\n",
    "\n",
    "    user_content = f\"\"\"다음 두 SQL 쿼리가 의미적으로 동등한지 평가해주세요.\n",
    "\n",
    "[정답 SQL]\n",
    "{gold_sql}\n",
    "\n",
    "[예측 SQL]\n",
    "{predicted_sql}\"\"\"\n",
    "\n",
    "    if schema:\n",
    "        user_content += f\"\"\"\n",
    "\n",
    "[데이터베이스 스키마]\n",
    "{schema}\"\"\"\n",
    "\n",
    "    if question:\n",
    "        user_content += f\"\"\"\n",
    "\n",
    "[원본 질문]\n",
    "{question}\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4.1\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_content}\n",
    "        ],\n",
    "        temperature=0,\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    \n",
    "    result = json.loads(response.choices[0].message.content)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4096629-1b5e-485e-8789-31077d1340cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 155/155 [01:14<00:00,  2.09it/s]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for pred, label in tqdm(zip(preds, label_lst), total=len(preds)):\n",
    "    result = evaluate_sql_equivalence(gold_sql=label, predicted_sql=pred)\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "676d6b55-1c30-44e6-a60d-deb0455893d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is_equivalent': True}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[130]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f231219b-2bf3-4728-87ed-354536bedab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint-150\n",
      "True  개수: 30\n",
      "False 개수: 125\n",
      "Accuracy: 0.1935483870967742\n"
     ]
    }
   ],
   "source": [
    "true_count = 0\n",
    "false_count = 0\n",
    "\n",
    "for r in results:\n",
    "    val = str(r[\"is_equivalent\"]).strip().lower()\n",
    "    \n",
    "    if val == \"true\":\n",
    "        true_count += 1\n",
    "    elif val == \"false\":\n",
    "        false_count += 1\n",
    "    else:\n",
    "        print(\"예외 값 발견:\", r[\"is_equivalent\"])\n",
    "\n",
    "accuracy = true_count / len(results)\n",
    "\n",
    "print('checkpoint-150')\n",
    "print(\"True  개수:\", true_count)\n",
    "print(\"False 개수:\", false_count)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bcf4fedb-78db-4f69-ab5f-83a49cba8311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint-300\n",
      "True  개수: 49\n",
      "False 개수: 106\n",
      "Accuracy: 0.3161290322580645\n"
     ]
    }
   ],
   "source": [
    "true_count = 0\n",
    "false_count = 0\n",
    "\n",
    "for r in results:\n",
    "    val = str(r[\"is_equivalent\"]).strip().lower()\n",
    "    \n",
    "    if val == \"true\":\n",
    "        true_count += 1\n",
    "    elif val == \"false\":\n",
    "        false_count += 1\n",
    "    else:\n",
    "        print(\"예외 값 발견:\", r[\"is_equivalent\"])\n",
    "\n",
    "accuracy = true_count / len(results)\n",
    "\n",
    "print('checkpoint-300')\n",
    "print(\"True  개수:\", true_count)\n",
    "print(\"False 개수:\", false_count)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c45a1e5d-0fe6-4ed7-981b-f3a2a40bb94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint-450\n",
      "True  개수: 60\n",
      "False 개수: 95\n",
      "Accuracy: 0.3870967741935484\n"
     ]
    }
   ],
   "source": [
    "true_count = 0\n",
    "false_count = 0\n",
    "\n",
    "for r in results:\n",
    "    val = str(r[\"is_equivalent\"]).strip().lower()\n",
    "    \n",
    "    if val == \"true\":\n",
    "        true_count += 1\n",
    "    elif val == \"false\":\n",
    "        false_count += 1\n",
    "    else:\n",
    "        print(\"예외 값 발견:\", r[\"is_equivalent\"])\n",
    "\n",
    "accuracy = true_count / len(results)\n",
    "\n",
    "print('checkpoint-450')\n",
    "print(\"True  개수:\", true_count)\n",
    "print(\"False 개수:\", false_count)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba650706-8209-4a97-810d-36ecb15f7a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint-600\n",
      "True  개수: 66\n",
      "False 개수: 89\n",
      "Accuracy: 0.4258064516129032\n"
     ]
    }
   ],
   "source": [
    "true_count = 0\n",
    "false_count = 0\n",
    "\n",
    "for r in results:\n",
    "    val = str(r[\"is_equivalent\"]).strip().lower()\n",
    "    \n",
    "    if val == \"true\":\n",
    "        true_count += 1\n",
    "    elif val == \"false\":\n",
    "        false_count += 1\n",
    "    else:\n",
    "        print(\"예외 값 발견:\", r[\"is_equivalent\"])\n",
    "\n",
    "accuracy = true_count / len(results)\n",
    "\n",
    "print('checkpoint-600')\n",
    "print(\"True  개수:\", true_count)\n",
    "print(\"False 개수:\", false_count)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eaf8d023-82fc-46a7-b88e-9d84937c4017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint-750\n",
      "True  개수: 69\n",
      "False 개수: 86\n",
      "Accuracy: 0.44516129032258067\n"
     ]
    }
   ],
   "source": [
    "true_count = 0\n",
    "false_count = 0\n",
    "\n",
    "for r in results:\n",
    "    val = str(r[\"is_equivalent\"]).strip().lower()\n",
    "    \n",
    "    if val == \"true\":\n",
    "        true_count += 1\n",
    "    elif val == \"false\":\n",
    "        false_count += 1\n",
    "    else:\n",
    "        print(\"예외 값 발견:\", r[\"is_equivalent\"])\n",
    "\n",
    "accuracy = true_count / len(results)\n",
    "\n",
    "print('checkpoint-750')\n",
    "print(\"True  개수:\", true_count)\n",
    "print(\"False 개수:\", false_count)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
