[2025-03-15 15:37:46,117] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-03-15 15:37:48,409] [WARNING] [runner.py:215:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2025-03-15 15:37:48,410] [INFO] [runner.py:607:main] cmd = /usr/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None rag_train.py
[2025-03-15 15:37:50,059] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-03-15 15:37:52,409] [INFO] [launch.py:139:main] 0 NV_LIBNCCL_DEV_PACKAGE=libnccl-dev=2.15.5-1+cuda11.8
[2025-03-15 15:37:52,409] [INFO] [launch.py:139:main] 0 NV_LIBNCCL_DEV_PACKAGE_VERSION=2.15.5-1
[2025-03-15 15:37:52,409] [INFO] [launch.py:139:main] 0 NCCL_VERSION=2.15.5-1
[2025-03-15 15:37:52,409] [INFO] [launch.py:139:main] 0 NV_LIBNCCL_DEV_PACKAGE_NAME=libnccl-dev
[2025-03-15 15:37:52,409] [INFO] [launch.py:139:main] 0 NV_LIBNCCL_PACKAGE=libnccl2=2.15.5-1+cuda11.8
[2025-03-15 15:37:52,409] [INFO] [launch.py:139:main] 0 NV_LIBNCCL_PACKAGE_NAME=libnccl2
[2025-03-15 15:37:52,409] [INFO] [launch.py:139:main] 0 NV_LIBNCCL_PACKAGE_VERSION=2.15.5-1
[2025-03-15 15:37:52,409] [INFO] [launch.py:146:main] WORLD INFO DICT: {'localhost': [0, 1]}
[2025-03-15 15:37:52,409] [INFO] [launch.py:152:main] nnodes=1, num_local_procs=2, node_rank=0
[2025-03-15 15:37:52,409] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1]})
[2025-03-15 15:37:52,409] [INFO] [launch.py:164:main] dist_world_size=2
[2025-03-15 15:37:52,409] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1
[2025-03-15 15:37:52,411] [INFO] [launch.py:256:main] process 8329 spawned with command: ['/usr/bin/python', '-u', 'rag_train.py', '--local_rank=0']
[2025-03-15 15:37:52,412] [INFO] [launch.py:256:main] process 8330 spawned with command: ['/usr/bin/python', '-u', 'rag_train.py', '--local_rank=1']
원본 데이터의 type 분포:
mrc_question_with_1_to_4_negative: 296
no_answer: 404
mrc_question: 491
paraphrased_question: 196
synthetic_question: 497
원본 데이터의 type 분포:
mrc_question: 491
synthetic_question: 497
paraphrased_question: 196
no_answer: 404
mrc_question_with_1_to_4_negative: 296

전체 데이터 분할 결과: Train 943개, Test 941개

학습 데이터의 type 분포:
mrc_question_with_1_to_4_negative: 148

전체 데이터 분할 결과: Train 943개, Test 941개

학습 데이터의 type 분포:
no_answer: 202
mrc_question: 246
mrc_question: 246
synthetic_question: 249
paraphrased_question: 98
paraphrased_question: 98
synthetic_question: 249

테스트 데이터의 type 분포:
no_answer: 202
mrc_question_with_1_to_4_negative: 148
mrc_question_with_1_to_4_negative: 148

테스트 데이터의 type 분포:
no_answer: 202
mrc_question: 245
mrc_question: 245
synthetic_question: 248
paraphrased_question: 98
paraphrased_question: 98
synthetic_question: 248
로컬 train_dataset 로드 완료.
로컬 test_dataset 로드 완료.
no_answer: 202
mrc_question_with_1_to_4_negative: 148
로컬 train_dataset 로드 완료.
로컬 test_dataset 로드 완료.

Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  8.55it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  8.50it/s]
Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  8.26it/s]
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  8.56it/s]
Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  7.20it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.71it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.64it/s]

Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  5.86it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  5.66it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  6.00it/s]
템플릿 적용 결과: <|im_start|>system
당신은 검색 결과를 바탕으로 질문에 답변해야 합니다.

다음의 지시사항을 따르십시오.
1. 질문과 검색 결과를 바탕으로 답변하십시오.
2. 검색 결과에 없는 내용을 답변하려고 하지 마십시오.
3. 질문에 대한 답이 검색 결과에 없다면 검색 결과에는 "해당 질문~에 대한 내용이 없습니다." 라고 답변하십시오.
4. 답변할 때 특정 문서를 참고하여 문장 또는 문단을 작성했다면 뒤에 출처는 이중 리스트로 해당 문서 번호를 남기십시오. 예를 들어서 특정 문장이나 문단을 1번 문서에서 인용했다면 뒤에 [[ref1]]이라고 기재하십시오.
5. 예를 들어서 특정 문장이나 문단을 1번 문서와 5번 문서에서 동시에 인용했다면 뒤에 [[ref1]], [[ref5]]이라고 기재하십시오.
6. 최대한 다수의 문서를 인용하여 답변하십시오.

검색 결과:
-----
문서1: 어플라이드 머티어리얼즈는 BE 세미컨덕터 인더스트리(Besi)와 협력해 업계 최초로 다이(Die) 기반 하이브리드 본딩(bonding)에 대한 완전하고 검증된 장비 솔루션을 개발한다고 밝혔다. 다이 기반 하이브리드 본딩은 고성능 컴퓨팅, 인공지능(AI), 5G 등 첨단 기술 관련 제품에서 이기종 칩과 하위시스템 설계를 가능하게 하는 새로운 칩 간 연결 기술이다. 전통적인 2D 스케일링이 둔화되면서 반도체 업계는 ‘PPACt(전력∙성능∙공간비용∙출시소요기간)’ 개선을 위한 새로운 방안으로 이기종 설계 및 칩 통합을 모색하고 있다. 이를 위해 어플라이드와 Besi는 공동 개발 프로그램을 만들고, 차세대 칩 간 본딩 기술에 초점을 맞춘 COE(Center of Excellence)를 설립한다. 이 프로그램은 양사가 보유한 프론트엔드(전공정), 백엔드(후공정) 전문성을 바탕으로 고객에게 최적화된 통합 하이브리드 본딩 구성과 장비 솔루션을 제공한다. 하이브리드 본딩은 직접적인 구리 인터커넥트를 이용해 다이 형태의 다수 ‘칩렛(Chiplet)’을 연결한다. 이 기술을 통해 디자이너는 다양한 프로세스 노드와 기술의 칩렛을 물리∙전기적으로 더욱 가깝게 위치시켜 단일의 거대한 다이로 만들었을 때와 동일한 또는 그보다 더 향상된 성능을 제공한다. 하이브리드 본딩은 칩 밀도를 높이고 칩렛 간 인터커넥트 배선 길이를 줄여 전체적인 성능, 전력, 효율, 비용을 개선한다. 완전한 다이 기반 하이브리드 본딩 장비 솔루션은 고속의 초정밀 칩렛 배치 기술 외에도 광범위한 반도체 제조 기술이 요구된다. 이를 위해 양사 공동 개발 프로그램은 어플라이드가 지닌 식각(etch), 평탄화(planarization), 증착(deposition), 웨이퍼 세정, 계측(metrology), 검사, 입자 결함 제어 공정의 전문성과 Besi의 업계 선두 다이 배치, 인터커넥트 및 조립 솔루션을 결합한다. COE는 업계 최첨단 웨이퍼 레벨 패키징 연구소 가운데 하나인 어플라이드의 싱가포르 소재 첨단 패키징 개발 센터(Advanced Packaging Development Center)에 위치한다. COE는 1만7300평방피트 규모의 클래스 10 클린룸에서 웨이퍼 레벨 패키징 장비 풀 라인을 갖추고 이기종 통합을 위한 기초적인 구성요소를 형성한다. 또한 고객에게 설계, 모델링, 시뮬레이션, 제작, 테스트 등을 포함해 맞춤형 하이브리드 본딩 시험체의 개발을 가속화하는 플랫폼을 제공한다.
-----
문서2: 대도시 주변 그린벨트(개발제한구역) 해제지역에 들어서는 대규모 주택단지 ‘보금자리’. 이 주택 브랜드가 도입된 건 2009년이다. 이명박 정부가 2018년까지 주택 150만가구를 공급하는 것을 목표로 시작한 장기 주택정책 사업이다. 지역별로는 수도권 100만가구, 지방 50만가구이며 유형별로는 분양 70만가구, 임대 80만가구 등이다.수도권에서는 서울 강남, 서울 서초, 고양 원흥, 하남 미사가 보금자리 시범지구(1차지구)로 선정된 데 이어 서울 세곡2, 서울 내곡, 남양주 진건, 시흥 인계, 구리 갈매, 부천 옥길 등이 2차 지구로 뽑혔다. 3차에서는 광명·시흥을 비롯해 서울 항동, 인천 구월 등이 지정되는 등 총 6차에 걸쳐 30여만가구가 들어서는 보금자리지구가 선정됐다. 2018년까지 150만가구를 공급하는 게 목표인 가운데 2009~2012년 4년 동안 사업 승인을 받은 물량은 36만가구로 당초 계획의 59.16%에 그쳤다. 수도권은 54.71%, 지방은 68.06%였다. 착공 및 준공 실적은 더 떨어진다. 같은 기간 착공 실적은 전국 8만1492가구로 당초 계획의 13.58%에 불과했다. 준공 실적도 1만가구(1.68%)에 머물렀다. 국회 국토교통위원회 소속 오병윤 통합진보당 의원(광주 서구을)이 지난해 국정감사 때 보금자리주택사업을 총괄 분석한 결과다. 보금자리주택은 이번 정부가 들어서면서 추진력을 더 잃었다는 평가가 나온다. 서승환 국토교통부 장관은 지난해 3월 취임 기자간담회에서 “앞으로 대규모 개발을 통한 주택 공급은 바람직하지 않다”고 말해 보금자리주택 사업의 일반 분양을 축소하거나 중단하겠다는 뜻을 밝혔다. 현 정부는 도심의 확장을 막는 그린벨트를 해제한 데다 2008년 글로벌 금융위기 이후 침체된 민간 주택시장을 교란시킨다는 지적을 받아온 보금자리의 이름을 ‘공공주택’으로 고치는 등 보금자리의 흔적 지우기에 나섰다.
-----
문서3: 미국에는 총 7곳이 있는데, 녹스빌의 테네시 대학교, 웨스턴 캐롤라이나 대학교, 텍사스 주립대학교, 샘 휴스턴 주립대학교, 서던일리노이 대학교, 콜로라도 메사 대학교 등에서 설립한 대학연구시설이다. 이들 연구시설에서는 부패 관련 연구를 진행할 수 있는 환경을 갖춰놓았기 때문에 '시체농장'의 범주에 해당되며, 그 목적은 여러가지가 있으나 주된 이유는 인간의 몸에서 일어나는 부패 현상에 대해 연구하고 이해하기 위함이다. 그 결과로 얻는 연구 결과는 의학, 법학, 교육적 목적으로 널리 활용된다. 

인류학센터 법의학소장을 맡은 리처드 얀츠 (Richard Jantz) 박사는 일상 속에서 사람이 어떻게 여러가지 움직임을 취하는지 관찰하면서, 사람이 보고 숨쉬고 맡는 곳이 어딘지를 보라고 조언하였다. 얀츠 박사는 인체의 기본 구조를 인식하는 것이 중요하다는 것을 깨닫고, 죽을 때에 영향을 주는 환경적 사건의 중요성과 시체 처리꾼들이 어떻게 부패와 상호작용하는지에 대한 이해에 초점을 맞춘 시체농장 연구시설의 필요성을 느꼈다. 노스캐롤라이나 애쉬빌의 FBI 소장을 맡고 있는 릭 슈위언 (Rick Schewien) 역시 시체농장의 용도를 두고 시체농장에서 얻는 정보를 다단계로 활용할 수 있고 과학에 보탬이 되어준다는 점에 있다고 밝혔다.
-----
문서4: 서울 강서구 마곡지구에 여의도공원 2배 규모의 아시아 최대 생태공원(조감도)이 조성된다. 서울시는 마곡지구에 5000여종의 식물을 갖춘 도시형 식물원인 ‘서울 화목원(花木園)’(가칭)을 2016년 12월까지 준공할 예정이라고 21일 발표했다. 서울 서남권의 첫 대형 공원이자 서울의 ‘녹색 허브’ 역할을 할 것으로 기대된다. 산업단지(190만㎡)에 입주하는 기업 연구시설에 이어 주거단지(106만㎡) 내 아파트 일반분양이 본격화되는 마곡지구에 호재로 작용할 전망이다.서울시에 따르면 기존의 대규모 택지개발지구에 조성되는 공원이 거주자들의 여가·휴양 기능에 초점을 맞췄다면 서울화목원은 인근 마곡첨단산업지구(산업)와 경계를 허물고 옛 마곡의 풍광을 재현하는 데 치중한다. 겸재 정선의 ‘종해청조(宗海廳潮)’에 나타난 옛 양천 지역의 모습을 재현하기 위해 인공 시설물을 최소화하고 물재생센터의 재생수와 빗물을 공원 호수로 활용하는 것이 특징이다. 전체 면적은 50만3431㎡로 여의도 공원(23만㎡)의 2배가 넘고 어린이대공원(56만㎡)보다 약간 작다. 화목원에는 6만㎡ 규모 식물원과 식물문화센터가 들어선다. 식물문화센터는 3개 건물(연면적 1만㎡)에 전시온실, 식물도서관, 가드닝센터 등이 갖춰진다. 시는 다음달 중 관계기관 협의를 거쳐 기본계획안을 확정하고 설계에 들어갈 예정이다.
-----
문서5: 한국의 과학기술인력 양성과 연구개발(R&D) 사업을 지배하는 논리는 ‘산학협력’도 ‘클러스터’도 아닌 ‘지역균형’이다. 지난 5년 사이에 DGIST(대구경북과학기술원), UNIST(울산과학기술원) 등 과학기술원 두 곳이 새로 들어섰다. KAIST(한국과학기술원)와 GIST(광주과학기술원)를 합해 네 개로 늘어났다. 다른 지역도 과기원 유치 경쟁에 나서는 등 연간 수백억원씩의 국가 예산이 투입되는 과기원을 놓고 지역 간 ‘나눠먹기식’ 경쟁 양상까지 보이고 있다. 한국경제신문의 설문조사 결과 주요 대학 공대 학장 10명 중 6명은 “지역균형발전 등 정치논리에 따라 과기원이 난립하는 것은 바람직하지 않다”고 지적했다.과기원은 1995년 광주광역시에 GIST가 들어서면서 본격화했다. 2000년대 들어 지방자치단체장 후보와 정치인들이 너도나도 과기원 유치를 공약으로 내걸었다. 치열한 경쟁 끝에 2011년 DGIST, 올해는 UNIST(울산과학기술대가 과기원으로 전환)가 각각 대구와 울산에서 개원했다.그러자 과기원이 없는 다른 지역들도 지역구 정치인을 통해 지속적으로 과기원 유치를 타진하고 있다. 국회 미래창조과학방송통신위원회에는 부산경남과기원, 전북과기원, 창원과기원, 부산과기원 등 4곳의 과기원 설립 법률안이 계류 중이다. 부산경남과기원 관련 법안만 두 개다. 의원들은 저마다 “지역 경제 규모에 걸맞은 과학인재 양성 기관이 있어야 한다”며 과기원 설립을 주장하고 있다. 한 지방 국립대 총장은 “대전에 KAIST가 있으니 광주·대구·울산에도 하나씩 만들어 달라고 해서 이 지경이 됐다”며 “이렇게 가다간 광역지자체마다 과기원이 하나씩 들어설 것”이라고 전망했다. 국가 차원의 체계적인 과학기술인력 양성이라는 취지보다는 지역균형발전이라는 ‘정치적 고려’가 과기원 설립에 크게 작용했음을 보여주는 대목이다.학계에서도 과기원 난립을 우려하는 목소리가 커지고 있다. 박진우 고려대 공대 학장은 “지역 발전을 염두에 둔다면 기존 지방 국립대를 집중 육성하면 되지 구태여 지역마다 과기원을 따로 둘 필요는 없다”고 말했다. 경북대의 한 교수는 “과기원들이 1997년 설립됐다가 중복 투자 등 문제로 2009년 KAIST에 통합된 한국정보통신대학교(ICU)와 같은 길을 걷지 않을까 우려스럽다”고 했다.<|im_end|>
<|im_start|>user
이기종 설계를 위해 설립한 프로그램이 위치한 장소<|im_end|>
<|im_start|>assistant
이기종 설계를 위해 설립한 프로그램은 어플라이드 머티어리얼즈와 BE 세미컨덕터 인더스트리(Besi)가 공동으로 개발한 프로그램으로, 이 프로그램은 싱가포르에 위치한 어플라이드의 첨단 패키징 개발 센터(Advanced Packaging Development Center)에 위치한 COE(Center of Excellence)에서 운영됩니다. 이 센터는 1만7300평방피트 규모의 클래스 10 클린룸을 갖추고 있으며, 웨이퍼 레벨 패키징 장비 풀 라인을 통해 이기종 통합을 위한 기초적인 구성요소를 형성합니다. [[ref1]]<|im_end|>

템플릿 적용 결과: <|im_start|>system
당신은 검색 결과를 바탕으로 질문에 답변해야 합니다.

다음의 지시사항을 따르십시오.
1. 질문과 검색 결과를 바탕으로 답변하십시오.
2. 검색 결과에 없는 내용을 답변하려고 하지 마십시오.
3. 질문에 대한 답이 검색 결과에 없다면 검색 결과에는 "해당 질문~에 대한 내용이 없습니다." 라고 답변하십시오.
4. 답변할 때 특정 문서를 참고하여 문장 또는 문단을 작성했다면 뒤에 출처는 이중 리스트로 해당 문서 번호를 남기십시오. 예를 들어서 특정 문장이나 문단을 1번 문서에서 인용했다면 뒤에 [[ref1]]이라고 기재하십시오.
5. 예를 들어서 특정 문장이나 문단을 1번 문서와 5번 문서에서 동시에 인용했다면 뒤에 [[ref1]], [[ref5]]이라고 기재하십시오.
6. 최대한 다수의 문서를 인용하여 답변하십시오.

검색 결과:
-----
문서1: 어플라이드 머티어리얼즈는 BE 세미컨덕터 인더스트리(Besi)와 협력해 업계 최초로 다이(Die) 기반 하이브리드 본딩(bonding)에 대한 완전하고 검증된 장비 솔루션을 개발한다고 밝혔다. 다이 기반 하이브리드 본딩은 고성능 컴퓨팅, 인공지능(AI), 5G 등 첨단 기술 관련 제품에서 이기종 칩과 하위시스템 설계를 가능하게 하는 새로운 칩 간 연결 기술이다. 전통적인 2D 스케일링이 둔화되면서 반도체 업계는 ‘PPACt(전력∙성능∙공간비용∙출시소요기간)’ 개선을 위한 새로운 방안으로 이기종 설계 및 칩 통합을 모색하고 있다. 이를 위해 어플라이드와 Besi는 공동 개발 프로그램을 만들고, 차세대 칩 간 본딩 기술에 초점을 맞춘 COE(Center of Excellence)를 설립한다. 이 프로그램은 양사가 보유한 프론트엔드(전공정), 백엔드(후공정) 전문성을 바탕으로 고객에게 최적화된 통합 하이브리드 본딩 구성과 장비 솔루션을 제공한다. 하이브리드 본딩은 직접적인 구리 인터커넥트를 이용해 다이 형태의 다수 ‘칩렛(Chiplet)’을 연결한다. 이 기술을 통해 디자이너는 다양한 프로세스 노드와 기술의 칩렛을 물리∙전기적으로 더욱 가깝게 위치시켜 단일의 거대한 다이로 만들었을 때와 동일한 또는 그보다 더 향상된 성능을 제공한다. 하이브리드 본딩은 칩 밀도를 높이고 칩렛 간 인터커넥트 배선 길이를 줄여 전체적인 성능, 전력, 효율, 비용을 개선한다. 완전한 다이 기반 하이브리드 본딩 장비 솔루션은 고속의 초정밀 칩렛 배치 기술 외에도 광범위한 반도체 제조 기술이 요구된다. 이를 위해 양사 공동 개발 프로그램은 어플라이드가 지닌 식각(etch), 평탄화(planarization), 증착(deposition), 웨이퍼 세정, 계측(metrology), 검사, 입자 결함 제어 공정의 전문성과 Besi의 업계 선두 다이 배치, 인터커넥트 및 조립 솔루션을 결합한다. COE는 업계 최첨단 웨이퍼 레벨 패키징 연구소 가운데 하나인 어플라이드의 싱가포르 소재 첨단 패키징 개발 센터(Advanced Packaging Development Center)에 위치한다. COE는 1만7300평방피트 규모의 클래스 10 클린룸에서 웨이퍼 레벨 패키징 장비 풀 라인을 갖추고 이기종 통합을 위한 기초적인 구성요소를 형성한다. 또한 고객에게 설계, 모델링, 시뮬레이션, 제작, 테스트 등을 포함해 맞춤형 하이브리드 본딩 시험체의 개발을 가속화하는 플랫폼을 제공한다.
-----
문서2: 대도시 주변 그린벨트(개발제한구역) 해제지역에 들어서는 대규모 주택단지 ‘보금자리’. 이 주택 브랜드가 도입된 건 2009년이다. 이명박 정부가 2018년까지 주택 150만가구를 공급하는 것을 목표로 시작한 장기 주택정책 사업이다. 지역별로는 수도권 100만가구, 지방 50만가구이며 유형별로는 분양 70만가구, 임대 80만가구 등이다.수도권에서는 서울 강남, 서울 서초, 고양 원흥, 하남 미사가 보금자리 시범지구(1차지구)로 선정된 데 이어 서울 세곡2, 서울 내곡, 남양주 진건, 시흥 인계, 구리 갈매, 부천 옥길 등이 2차 지구로 뽑혔다. 3차에서는 광명·시흥을 비롯해 서울 항동, 인천 구월 등이 지정되는 등 총 6차에 걸쳐 30여만가구가 들어서는 보금자리지구가 선정됐다. 2018년까지 150만가구를 공급하는 게 목표인 가운데 2009~2012년 4년 동안 사업 승인을 받은 물량은 36만가구로 당초 계획의 59.16%에 그쳤다. 수도권은 54.71%, 지방은 68.06%였다. 착공 및 준공 실적은 더 떨어진다. 같은 기간 착공 실적은 전국 8만1492가구로 당초 계획의 13.58%에 불과했다. 준공 실적도 1만가구(1.68%)에 머물렀다. 국회 국토교통위원회 소속 오병윤 통합진보당 의원(광주 서구을)이 지난해 국정감사 때 보금자리주택사업을 총괄 분석한 결과다. 보금자리주택은 이번 정부가 들어서면서 추진력을 더 잃었다는 평가가 나온다. 서승환 국토교통부 장관은 지난해 3월 취임 기자간담회에서 “앞으로 대규모 개발을 통한 주택 공급은 바람직하지 않다”고 말해 보금자리주택 사업의 일반 분양을 축소하거나 중단하겠다는 뜻을 밝혔다. 현 정부는 도심의 확장을 막는 그린벨트를 해제한 데다 2008년 글로벌 금융위기 이후 침체된 민간 주택시장을 교란시킨다는 지적을 받아온 보금자리의 이름을 ‘공공주택’으로 고치는 등 보금자리의 흔적 지우기에 나섰다.
-----
문서3: 미국에는 총 7곳이 있는데, 녹스빌의 테네시 대학교, 웨스턴 캐롤라이나 대학교, 텍사스 주립대학교, 샘 휴스턴 주립대학교, 서던일리노이 대학교, 콜로라도 메사 대학교 등에서 설립한 대학연구시설이다. 이들 연구시설에서는 부패 관련 연구를 진행할 수 있는 환경을 갖춰놓았기 때문에 '시체농장'의 범주에 해당되며, 그 목적은 여러가지가 있으나 주된 이유는 인간의 몸에서 일어나는 부패 현상에 대해 연구하고 이해하기 위함이다. 그 결과로 얻는 연구 결과는 의학, 법학, 교육적 목적으로 널리 활용된다. 

인류학센터 법의학소장을 맡은 리처드 얀츠 (Richard Jantz) 박사는 일상 속에서 사람이 어떻게 여러가지 움직임을 취하는지 관찰하면서, 사람이 보고 숨쉬고 맡는 곳이 어딘지를 보라고 조언하였다. 얀츠 박사는 인체의 기본 구조를 인식하는 것이 중요하다는 것을 깨닫고, 죽을 때에 영향을 주는 환경적 사건의 중요성과 시체 처리꾼들이 어떻게 부패와 상호작용하는지에 대한 이해에 초점을 맞춘 시체농장 연구시설의 필요성을 느꼈다. 노스캐롤라이나 애쉬빌의 FBI 소장을 맡고 있는 릭 슈위언 (Rick Schewien) 역시 시체농장의 용도를 두고 시체농장에서 얻는 정보를 다단계로 활용할 수 있고 과학에 보탬이 되어준다는 점에 있다고 밝혔다.
-----
문서4: 서울 강서구 마곡지구에 여의도공원 2배 규모의 아시아 최대 생태공원(조감도)이 조성된다. 서울시는 마곡지구에 5000여종의 식물을 갖춘 도시형 식물원인 ‘서울 화목원(花木園)’(가칭)을 2016년 12월까지 준공할 예정이라고 21일 발표했다. 서울 서남권의 첫 대형 공원이자 서울의 ‘녹색 허브’ 역할을 할 것으로 기대된다. 산업단지(190만㎡)에 입주하는 기업 연구시설에 이어 주거단지(106만㎡) 내 아파트 일반분양이 본격화되는 마곡지구에 호재로 작용할 전망이다.서울시에 따르면 기존의 대규모 택지개발지구에 조성되는 공원이 거주자들의 여가·휴양 기능에 초점을 맞췄다면 서울화목원은 인근 마곡첨단산업지구(산업)와 경계를 허물고 옛 마곡의 풍광을 재현하는 데 치중한다. 겸재 정선의 ‘종해청조(宗海廳潮)’에 나타난 옛 양천 지역의 모습을 재현하기 위해 인공 시설물을 최소화하고 물재생센터의 재생수와 빗물을 공원 호수로 활용하는 것이 특징이다. 전체 면적은 50만3431㎡로 여의도 공원(23만㎡)의 2배가 넘고 어린이대공원(56만㎡)보다 약간 작다. 화목원에는 6만㎡ 규모 식물원과 식물문화센터가 들어선다. 식물문화센터는 3개 건물(연면적 1만㎡)에 전시온실, 식물도서관, 가드닝센터 등이 갖춰진다. 시는 다음달 중 관계기관 협의를 거쳐 기본계획안을 확정하고 설계에 들어갈 예정이다.
-----
문서5: 한국의 과학기술인력 양성과 연구개발(R&D) 사업을 지배하는 논리는 ‘산학협력’도 ‘클러스터’도 아닌 ‘지역균형’이다. 지난 5년 사이에 DGIST(대구경북과학기술원), UNIST(울산과학기술원) 등 과학기술원 두 곳이 새로 들어섰다. KAIST(한국과학기술원)와 GIST(광주과학기술원)를 합해 네 개로 늘어났다. 다른 지역도 과기원 유치 경쟁에 나서는 등 연간 수백억원씩의 국가 예산이 투입되는 과기원을 놓고 지역 간 ‘나눠먹기식’ 경쟁 양상까지 보이고 있다. 한국경제신문의 설문조사 결과 주요 대학 공대 학장 10명 중 6명은 “지역균형발전 등 정치논리에 따라 과기원이 난립하는 것은 바람직하지 않다”고 지적했다.과기원은 1995년 광주광역시에 GIST가 들어서면서 본격화했다. 2000년대 들어 지방자치단체장 후보와 정치인들이 너도나도 과기원 유치를 공약으로 내걸었다. 치열한 경쟁 끝에 2011년 DGIST, 올해는 UNIST(울산과학기술대가 과기원으로 전환)가 각각 대구와 울산에서 개원했다.그러자 과기원이 없는 다른 지역들도 지역구 정치인을 통해 지속적으로 과기원 유치를 타진하고 있다. 국회 미래창조과학방송통신위원회에는 부산경남과기원, 전북과기원, 창원과기원, 부산과기원 등 4곳의 과기원 설립 법률안이 계류 중이다. 부산경남과기원 관련 법안만 두 개다. 의원들은 저마다 “지역 경제 규모에 걸맞은 과학인재 양성 기관이 있어야 한다”며 과기원 설립을 주장하고 있다. 한 지방 국립대 총장은 “대전에 KAIST가 있으니 광주·대구·울산에도 하나씩 만들어 달라고 해서 이 지경이 됐다”며 “이렇게 가다간 광역지자체마다 과기원이 하나씩 들어설 것”이라고 전망했다. 국가 차원의 체계적인 과학기술인력 양성이라는 취지보다는 지역균형발전이라는 ‘정치적 고려’가 과기원 설립에 크게 작용했음을 보여주는 대목이다.학계에서도 과기원 난립을 우려하는 목소리가 커지고 있다. 박진우 고려대 공대 학장은 “지역 발전을 염두에 둔다면 기존 지방 국립대를 집중 육성하면 되지 구태여 지역마다 과기원을 따로 둘 필요는 없다”고 말했다. 경북대의 한 교수는 “과기원들이 1997년 설립됐다가 중복 투자 등 문제로 2009년 KAIST에 통합된 한국정보통신대학교(ICU)와 같은 길을 걷지 않을까 우려스럽다”고 했다.<|im_end|>
<|im_start|>user
이기종 설계를 위해 설립한 프로그램이 위치한 장소<|im_end|>
<|im_start|>assistant
이기종 설계를 위해 설립한 프로그램은 어플라이드 머티어리얼즈와 BE 세미컨덕터 인더스트리(Besi)가 공동으로 개발한 프로그램으로, 이 프로그램은 싱가포르에 위치한 어플라이드의 첨단 패키징 개발 센터(Advanced Packaging Development Center)에 위치한 COE(Center of Excellence)에서 운영됩니다. 이 센터는 1만7300평방피트 규모의 클래스 10 클린룸을 갖추고 있으며, 웨이퍼 레벨 패키징 장비 풀 라인을 통해 이기종 통합을 위한 기초적인 구성요소를 형성합니다. [[ref1]]<|im_end|>

[2025-03-15 15:38:00,084] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-03-15 15:38:00,165] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-03-15 15:38:01,542] [INFO] [comm.py:652:init_distributed] cdb=None
[2025-03-15 15:38:01,543] [INFO] [comm.py:683:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2025-03-15 15:38:01,613] [INFO] [comm.py:652:init_distributed] cdb=None
/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length. Will not be supported from version '1.0.0'.

Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.
  warnings.warn(message, FutureWarning)
/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length. Will not be supported from version '1.0.0'.

Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.
  warnings.warn(message, FutureWarning)
/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:283: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:283: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.
  warnings.warn(
Parameter Offload: Total persistent parameters: 5379584 in 365 params
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...

  0%|          | 0/177 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]

  1%|          | 1/177 [00:06<17:55,  6.11s/it]
  1%|          | 2/177 [00:09<12:41,  4.35s/it]
  2%|▏         | 3/177 [00:12<10:54,  3.76s/it]
  2%|▏         | 4/177 [00:15<10:00,  3.47s/it]
  3%|▎         | 5/177 [00:18<09:31,  3.32s/it]
  3%|▎         | 6/177 [00:21<09:13,  3.24s/it]
  4%|▍         | 7/177 [00:24<09:01,  3.18s/it]
  5%|▍         | 8/177 [00:27<08:50,  3.14s/it]
  5%|▌         | 9/177 [00:30<08:41,  3.10s/it]
  6%|▌         | 10/177 [00:33<08:35,  3.08s/it]
                                                
{'loss': 0.8121, 'grad_norm': 0.6868474684085057, 'learning_rate': 0.0001, 'epoch': 0.17}

  6%|▌         | 10/177 [00:33<08:35,  3.08s/it]
  6%|▌         | 11/177 [00:36<08:28,  3.06s/it]
  7%|▋         | 12/177 [00:39<08:23,  3.05s/it]
  7%|▋         | 13/177 [00:42<08:19,  3.05s/it]
  8%|▊         | 14/177 [00:45<08:15,  3.04s/it]
  8%|▊         | 15/177 [00:48<08:12,  3.04s/it]
  9%|▉         | 16/177 [00:51<08:09,  3.04s/it]
 10%|▉         | 17/177 [00:54<08:06,  3.04s/it]
 10%|█         | 18/177 [00:57<08:02,  3.03s/it]
 11%|█         | 19/177 [01:00<07:58,  3.03s/it]
 11%|█▏        | 20/177 [01:03<07:54,  3.02s/it]
                                                
{'loss': 8.1067, 'grad_norm': 0.0, 'learning_rate': 0.0001, 'epoch': 0.34}

 11%|█▏        | 20/177 [01:03<07:54,  3.02s/it]
 12%|█▏        | 21/177 [01:06<07:54,  3.04s/it]
 12%|█▏        | 22/177 [01:09<07:50,  3.04s/it]
 13%|█▎        | 23/177 [01:13<07:46,  3.03s/it]
 14%|█▎        | 24/177 [01:16<07:44,  3.04s/it]
 14%|█▍        | 25/177 [01:19<07:40,  3.03s/it]
 15%|█▍        | 26/177 [01:22<07:38,  3.04s/it]
 15%|█▌        | 27/177 [01:25<07:35,  3.03s/it]
 16%|█▌        | 28/177 [01:28<07:31,  3.03s/it]
 16%|█▋        | 29/177 [01:31<07:28,  3.03s/it]
 17%|█▋        | 30/177 [01:34<07:25,  3.03s/it]
                                                
{'loss': 0.1271, 'grad_norm': 0.0, 'learning_rate': 0.0001, 'epoch': 0.51}

 17%|█▋        | 30/177 [01:34<07:25,  3.03s/it]
 18%|█▊        | 31/177 [01:37<07:21,  3.03s/it]
 18%|█▊        | 32/177 [01:40<07:18,  3.02s/it]
 19%|█▊        | 33/177 [01:43<07:14,  3.02s/it]
 19%|█▉        | 34/177 [01:46<07:11,  3.02s/it]
 20%|█▉        | 35/177 [01:49<07:09,  3.02s/it]
 20%|██        | 36/177 [01:52<07:06,  3.03s/it]
 21%|██        | 37/177 [01:55<07:03,  3.02s/it]
 21%|██▏       | 38/177 [01:58<06:59,  3.02s/it]
 22%|██▏       | 39/177 [02:01<06:57,  3.02s/it]
 23%|██▎       | 40/177 [02:04<06:54,  3.02s/it]
                                                
{'loss': 0.0587, 'grad_norm': 0.0, 'learning_rate': 0.0001, 'epoch': 0.68}

 23%|██▎       | 40/177 [02:04<06:54,  3.02s/it]
 23%|██▎       | 41/177 [02:07<06:50,  3.02s/it]
 24%|██▎       | 42/177 [02:10<06:47,  3.02s/it]
 24%|██▍       | 43/177 [02:13<06:44,  3.02s/it]
 25%|██▍       | 44/177 [02:16<06:41,  3.02s/it]
 25%|██▌       | 45/177 [02:19<06:37,  3.01s/it]
 26%|██▌       | 46/177 [02:22<06:34,  3.02s/it]
 27%|██▋       | 47/177 [02:25<06:31,  3.02s/it]
 27%|██▋       | 48/177 [02:28<06:29,  3.02s/it]
 28%|██▊       | 49/177 [02:31<06:26,  3.02s/it]
 28%|██▊       | 50/177 [02:34<06:23,  3.02s/it]
                                                
{'loss': 3.0649, 'grad_norm': 0.0, 'learning_rate': 0.0001, 'epoch': 0.85}

 28%|██▊       | 50/177 [02:34<06:23,  3.02s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]

 29%|██▉       | 51/177 [02:49<13:49,  6.59s/it]
 29%|██▉       | 52/177 [02:52<11:30,  5.52s/it]
 30%|██▉       | 53/177 [02:55<09:51,  4.77s/it]
 31%|███       | 54/177 [02:58<08:41,  4.24s/it]
 31%|███       | 55/177 [03:01<07:52,  3.88s/it]
 32%|███▏      | 56/177 [03:04<07:17,  3.62s/it]
 32%|███▏      | 57/177 [03:07<06:53,  3.44s/it]
 33%|███▎      | 58/177 [03:10<06:34,  3.31s/it]
 33%|███▎      | 59/177 [03:13<06:19,  3.21s/it]
 34%|███▍      | 60/177 [03:16<06:09,  3.15s/it]
                                                
{'loss': 5.6354, 'grad_norm': 0.31411162170581186, 'learning_rate': 0.0001, 'epoch': 1.02}

 34%|███▍      | 60/177 [03:16<06:09,  3.15s/it]
 34%|███▍      | 61/177 [03:19<06:00,  3.11s/it]
 35%|███▌      | 62/177 [03:22<05:53,  3.08s/it]
 36%|███▌      | 63/177 [03:25<05:48,  3.06s/it]
 36%|███▌      | 64/177 [03:28<05:44,  3.04s/it]
 37%|███▋      | 65/177 [03:31<05:39,  3.03s/it]
 37%|███▋      | 66/177 [03:34<05:36,  3.03s/it]
 38%|███▊      | 67/177 [03:37<05:31,  3.02s/it]
 38%|███▊      | 68/177 [03:40<05:28,  3.01s/it]
 39%|███▉      | 69/177 [03:43<05:24,  3.01s/it]
 40%|███▉      | 70/177 [03:46<05:21,  3.00s/it]
                                                
{'loss': 0.8183, 'grad_norm': 0.0, 'learning_rate': 0.0001, 'epoch': 1.19}

 40%|███▉      | 70/177 [03:46<05:21,  3.00s/it]
 40%|████      | 71/177 [03:49<05:19,  3.02s/it]
 41%|████      | 72/177 [03:52<05:17,  3.02s/it]
 41%|████      | 73/177 [03:55<05:13,  3.01s/it]
 42%|████▏     | 74/177 [03:58<05:10,  3.01s/it]
 42%|████▏     | 75/177 [04:01<05:07,  3.01s/it]
 43%|████▎     | 76/177 [04:04<05:04,  3.02s/it]
 44%|████▎     | 77/177 [04:07<05:02,  3.02s/it]
 44%|████▍     | 78/177 [04:10<04:59,  3.02s/it]
 45%|████▍     | 79/177 [04:13<04:55,  3.02s/it]
 45%|████▌     | 80/177 [04:16<04:52,  3.02s/it]
                                                
{'loss': 29.5737, 'grad_norm': 0.28208849531546415, 'learning_rate': 0.0001, 'epoch': 1.36}

 45%|████▌     | 80/177 [04:16<04:52,  3.02s/it]
 46%|████▌     | 81/177 [04:19<04:49,  3.01s/it]
 46%|████▋     | 82/177 [04:22<04:45,  3.01s/it]
 47%|████▋     | 83/177 [04:25<04:42,  3.01s/it]
 47%|████▋     | 84/177 [04:28<04:40,  3.01s/it]
 48%|████▊     | 85/177 [04:31<04:37,  3.01s/it]
 49%|████▊     | 86/177 [04:34<04:33,  3.01s/it]
 49%|████▉     | 87/177 [04:37<04:30,  3.01s/it]
 50%|████▉     | 88/177 [04:41<04:27,  3.01s/it]
 50%|█████     | 89/177 [04:44<04:24,  3.01s/it]
 51%|█████     | 90/177 [04:47<04:21,  3.00s/it]
                                                
{'loss': 0.2373, 'grad_norm': 0.2961300400993476, 'learning_rate': 0.0001, 'epoch': 1.53}

 51%|█████     | 90/177 [04:47<04:21,  3.00s/it]
 51%|█████▏    | 91/177 [04:50<04:19,  3.02s/it]
 52%|█████▏    | 92/177 [04:53<04:16,  3.02s/it]
 53%|█████▎    | 93/177 [04:56<04:13,  3.02s/it]
 53%|█████▎    | 94/177 [04:59<04:10,  3.02s/it]
 54%|█████▎    | 95/177 [05:02<04:07,  3.02s/it]
 54%|█████▍    | 96/177 [05:05<04:04,  3.02s/it]
 55%|█████▍    | 97/177 [05:08<04:01,  3.02s/it]
 55%|█████▌    | 98/177 [05:11<03:59,  3.03s/it]
 56%|█████▌    | 99/177 [05:14<03:56,  3.03s/it]
 56%|█████▋    | 100/177 [05:17<03:52,  3.02s/it]
                                                 
{'loss': 0.2491, 'grad_norm': 0.0, 'learning_rate': 0.0001, 'epoch': 1.69}

 56%|█████▋    | 100/177 [05:17<03:52,  3.02s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]

 57%|█████▋    | 101/177 [05:31<08:06,  6.40s/it]
 58%|█████▊    | 102/177 [05:34<06:48,  5.44s/it]
 58%|█████▊    | 103/177 [05:37<05:49,  4.72s/it]
 59%|█████▉    | 104/177 [05:40<05:07,  4.21s/it]
 59%|█████▉    | 105/177 [05:43<04:37,  3.85s/it]
 60%|█████▉    | 106/177 [05:46<04:15,  3.60s/it]
 60%|██████    | 107/177 [05:49<04:00,  3.44s/it]
 61%|██████    | 108/177 [05:52<03:48,  3.32s/it]
 62%|██████▏   | 109/177 [05:55<03:39,  3.23s/it]
 62%|██████▏   | 110/177 [05:58<03:32,  3.16s/it]
                                                 
{'loss': 0.0082, 'grad_norm': 0.0, 'learning_rate': 0.0001, 'epoch': 1.86}

 62%|██████▏   | 110/177 [05:58<03:32,  3.16s/it]
 63%|██████▎   | 111/177 [06:01<03:26,  3.13s/it]
 63%|██████▎   | 112/177 [06:05<03:21,  3.09s/it]
 64%|██████▍   | 113/177 [06:08<03:16,  3.07s/it]
 64%|██████▍   | 114/177 [06:11<03:12,  3.06s/it]
 65%|██████▍   | 115/177 [06:14<03:08,  3.05s/it]
 66%|██████▌   | 116/177 [06:17<03:05,  3.04s/it]
 66%|██████▌   | 117/177 [06:20<03:02,  3.04s/it]
 67%|██████▋   | 118/177 [06:23<02:58,  3.03s/it]
 67%|██████▋   | 119/177 [06:26<03:00,  3.11s/it]
 68%|██████▊   | 120/177 [06:29<02:55,  3.09s/it]
                                                 
{'loss': 1.4397, 'grad_norm': 0.0, 'learning_rate': 0.0001, 'epoch': 2.03}

 68%|██████▊   | 120/177 [06:29<02:55,  3.09s/it]
 68%|██████▊   | 121/177 [06:32<02:51,  3.07s/it]
 69%|██████▉   | 122/177 [06:35<02:48,  3.06s/it]
 69%|██████▉   | 123/177 [06:38<02:45,  3.06s/it]
 70%|███████   | 124/177 [06:41<02:44,  3.11s/it]
 71%|███████   | 125/177 [06:44<02:40,  3.08s/it]
 71%|███████   | 126/177 [06:47<02:36,  3.07s/it]
 72%|███████▏  | 127/177 [06:50<02:33,  3.07s/it]
 72%|███████▏  | 128/177 [06:53<02:29,  3.06s/it]
 73%|███████▎  | 129/177 [06:57<02:26,  3.05s/it]
 73%|███████▎  | 130/177 [07:00<02:23,  3.05s/it]
                                                 
{'loss': 9.3738, 'grad_norm': 0.3643305100711969, 'learning_rate': 0.0001, 'epoch': 2.2}

 73%|███████▎  | 130/177 [07:00<02:23,  3.05s/it]
 74%|███████▍  | 131/177 [07:03<02:19,  3.04s/it]
 75%|███████▍  | 132/177 [07:06<02:16,  3.04s/it]
 75%|███████▌  | 133/177 [07:09<02:13,  3.04s/it]
 76%|███████▌  | 134/177 [07:12<02:10,  3.03s/it]
 76%|███████▋  | 135/177 [07:15<02:07,  3.03s/it]
 77%|███████▋  | 136/177 [07:18<02:04,  3.03s/it]
 77%|███████▋  | 137/177 [07:21<02:01,  3.03s/it]
 78%|███████▊  | 138/177 [07:24<01:57,  3.03s/it]
 79%|███████▊  | 139/177 [07:27<01:55,  3.03s/it]
 79%|███████▉  | 140/177 [07:30<01:52,  3.03s/it]
                                                 
{'loss': 0.1838, 'grad_norm': 0.0, 'learning_rate': 0.0001, 'epoch': 2.37}

 79%|███████▉  | 140/177 [07:30<01:52,  3.03s/it]
 80%|███████▉  | 141/177 [07:33<01:48,  3.03s/it]
 80%|████████  | 142/177 [07:36<01:45,  3.03s/it]
 81%|████████  | 143/177 [07:39<01:42,  3.03s/it]
 81%|████████▏ | 144/177 [07:42<01:39,  3.02s/it]
 82%|████████▏ | 145/177 [07:45<01:36,  3.02s/it]
 82%|████████▏ | 146/177 [07:48<01:33,  3.02s/it]
 83%|████████▎ | 147/177 [07:51<01:30,  3.03s/it]
 84%|████████▎ | 148/177 [07:54<01:27,  3.03s/it]
 84%|████████▍ | 149/177 [07:57<01:24,  3.03s/it]
 85%|████████▍ | 150/177 [08:00<01:21,  3.03s/it]
                                                 
{'loss': 0.0409, 'grad_norm': 0.019688991444651242, 'learning_rate': 0.0001, 'epoch': 2.54}

 85%|████████▍ | 150/177 [08:00<01:21,  3.03s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]

 85%|████████▌ | 151/177 [08:14<02:46,  6.41s/it]
 86%|████████▌ | 152/177 [08:17<02:14,  5.39s/it]
 86%|████████▋ | 153/177 [08:20<01:52,  4.69s/it]
 87%|████████▋ | 154/177 [08:23<01:36,  4.18s/it]
 88%|████████▊ | 155/177 [08:26<01:24,  3.83s/it]
 88%|████████▊ | 156/177 [08:30<01:15,  3.59s/it]
 89%|████████▊ | 157/177 [08:33<01:08,  3.42s/it]
 89%|████████▉ | 158/177 [08:36<01:02,  3.30s/it]
 90%|████████▉ | 159/177 [08:39<00:57,  3.21s/it]
 90%|█████████ | 160/177 [08:42<00:53,  3.16s/it]
                                                 
{'loss': 0.0377, 'grad_norm': 0.0, 'learning_rate': 0.0001, 'epoch': 2.71}

 90%|█████████ | 160/177 [08:42<00:53,  3.16s/it]
 91%|█████████ | 161/177 [08:45<00:49,  3.11s/it]
 92%|█████████▏| 162/177 [08:48<00:46,  3.08s/it]
 92%|█████████▏| 163/177 [08:51<00:43,  3.07s/it]
 93%|█████████▎| 164/177 [08:54<00:39,  3.06s/it]
 93%|█████████▎| 165/177 [08:57<00:36,  3.05s/it]
 94%|█████████▍| 166/177 [09:00<00:33,  3.05s/it]
 94%|█████████▍| 167/177 [09:03<00:30,  3.04s/it]
 95%|█████████▍| 168/177 [09:06<00:27,  3.04s/it]
 95%|█████████▌| 169/177 [09:09<00:24,  3.04s/it]
 96%|█████████▌| 170/177 [09:12<00:21,  3.03s/it]
                                                 
{'loss': 0.0646, 'grad_norm': 0.0, 'learning_rate': 0.0001, 'epoch': 2.88}

 96%|█████████▌| 170/177 [09:12<00:21,  3.03s/it]
 97%|█████████▋| 171/177 [09:15<00:18,  3.03s/it]
 97%|█████████▋| 172/177 [09:18<00:15,  3.02s/it]
 98%|█████████▊| 173/177 [09:21<00:12,  3.02s/it]
 98%|█████████▊| 174/177 [09:24<00:09,  3.02s/it]
 99%|█████████▉| 175/177 [09:27<00:06,  3.07s/it]
 99%|█████████▉| 176/177 [09:30<00:03,  3.06s/it]
100%|██████████| 177/177 [09:33<00:00,  3.04s/it]
                                                 
{'train_runtime': 584.8471, 'train_samples_per_second': 4.837, 'train_steps_per_second': 0.303, 'train_loss': 3.3842620956106373, 'epoch': 3.0}

100%|██████████| 177/177 [09:44<00:00,  3.04s/it]
100%|██████████| 177/177 [09:44<00:00,  3.30s/it]
[2025-03-15 15:48:07,078] [INFO] [launch.py:351:main] Process 8330 exits successfully.
[2025-03-15 15:48:09,081] [INFO] [launch.py:351:main] Process 8329 exits successfully.
