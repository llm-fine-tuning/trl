{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8296cb2-b267-45d4-8ff7-c1bb5d7285c6",
   "metadata": {},
   "source": [
    "## 테스트 데이터 로드 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ede7c6f-a53b-40f2-a1c1-903b65209208",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/usr/local/lib/python3.10/dist-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_from_disk\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27a1113e-711d-4ed2-8647-0cb7a6452681",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = load_from_disk('test_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e1878c4-960e-46d6-a8ae-aeaae24da760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model tokenizer load\n",
    "model = 'Qwen/Qwen2-7B-Instruct'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdf5301-112c-4cbb-86f6-3625b7530104",
   "metadata": {},
   "source": [
    "테스트 데이터를 불러와서 입력과 레이블 형태로 전처리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c0c862f-35ea-47a4-9986-f3f6c4d04b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_lst = []\n",
    "label_lst = []\n",
    "\n",
    "for prompt in test_dataset[\"messages\"]:\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        prompt, tokenize=False, add_generation_prompt=False\n",
    "    )\n",
    "    input = text.split('<|im_start|>assistant')[0] + '<|im_start|>assistant'\n",
    "    label = text.split('<|im_start|>assistant')[1]\n",
    "    prompt_lst.append(input)\n",
    "    label_lst.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e61704-92d2-4dc9-badc-3bbdf1392a0f",
   "metadata": {},
   "source": [
    "임의로 20번 샘플을 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "237d2cd7-a64e-425c-8a06-5700c820fdc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "당신은 검색 결과를 바탕으로 질문에 답변해야 합니다.\n",
      "\n",
      "다음의 지시사항을 따르십시오.\n",
      "1. 질문과 검색 결과를 바탕으로 답변하십시오.\n",
      "2. 검색 결과에 없는 내용을 답변하려고 하지 마십시오.\n",
      "3. 질문에 대한 답이 검색 결과에 없다면 검색 결과에는 \"해당 질문~에 대한 내용이 없습니다.\" 라고 답변하십시오.\n",
      "4. 답변할 때 특정 문서를 참고하여 문장 또는 문단을 작성했다면 뒤에 출처는 이중 리스트로 해당 문서 번호를 남기십시오. 예를 들어서 특정 문장이나 문단을 1번 문서에서 인용했다면 뒤에 [[ref1]]이라고 기재하십시오.\n",
      "5. 예를 들어서 특정 문장이나 문단을 1번 문서와 5번 문서에서 동시에 인용했다면 뒤에 [[ref1]], [[ref5]]이라고 기재하십시오.\n",
      "6. 최대한 다수의 문서를 인용하여 답변하십시오.\n",
      "\n",
      "검색 결과:\n",
      "-----\n",
      "문서1: “인재 제일의 삼성이라더니 너무 실망입니다.” 김정미 제일모직 상무(43·사진)가 21년 전 삼성 본관 25층 인사팀의 방명록에 쓴 문장이다. 당시 인사 담당자는 삼성 입사 원서를 받으려고 인사팀을 찾은 그를 힐끗 쳐다보고 말했다. “군필이에요?” 얼굴이 붉어졌지만 김 상무는 지지 않고 대꾸했다. “저는 면제예요. 원서 주세요.”하지만 지원서를 받지 못했다. 여대생이라는 이유에서 거부당한 것이다. 불과 20여년 전, 삼성도 그랬다. “방명록에 학점이나 써놓고 가라”는 직원의 말에 김 상무는 화가 나서 “(삼성에) 실망했다”는 글을 남긴 채 그곳을 나왔다.지난달 30일 저녁 서울 서초동 삼성전자 본사 3층 대회의실에서 20~30대 여성 100여명이 김 상무의 얘기에 귀를 기울였다. 삼성이 여성 임직원의 경험을 외부와 공유하기 위해 만든 ‘여기(女氣) 모여라’ 현장이다. 삼성 트위터, 페이스북, 카카오플러스 등 소셜네트워크서비스(SNS)를 통해 일반인 신청을 받아 초청했다. 이번 강연엔 1000명 넘게 신청이 몰려 10 대 1의 경쟁률을 기록했다. 김 상무는 얘기를 이어갔다. 좌절의 아픔을 채 삭이기도 전 그는 ‘원서를 받으러 오라’는 연락을 받았다. 생각지도 않았지만 무척이나 반가웠다고 했다. 삼성물산으로 지원해 면접 때 받은 첫 질문은 “주량이 얼마냐”였다. “마실 만큼 마신다”고 답하자 “아프리카로 보내면 갈 거냐”는 질문이 따라왔다. “어디든 가겠다”고 답하면서 그는 생각했다. “사회생활에서는 이런 게 중요하구나.”1993년 3월 김 상무는 천신만고 끝에 삼성물산에 입사했다. 이건희 삼성 회장의 여성인재 중용 지시에 따라 그는 ‘대졸 여성 공채 1기’가 됐다. 당시 김 상무의 입사동기 139명 중 지금 현직에 남은 이는 30여명. 1999년 제일모직으로 옮겨온 김 상무는 2011년 동기 가운데 처음으로 ‘별(임원)’을 달았다. 김 상무의 강연이 이어지자 여기저기서 공감의 탄성이 터졌다. 보수적인 대구에서 태어나 집안의 반대를 무릅쓰고 동기 238명 중 233명이 남자인 서울대 경영학과에 입학한 것부터가 도전이었다. 김 상무는 “뭐든 끝까지 물고 늘어지는 근성이 필요하다”며 “당장 결실을 못 맺어도 나중에 부메랑처럼 기회로 돌아온다”고 말했다.입사 이후에도 고난의 길이었다. 1년은 공장과 매장에서 일했다. 안양의 신사복 공장에서 땀흘리며 재봉질했고, 명동매장에서는 직접 걸레질을 하고 창고에서 쪽잠도 잤다. 그는 “젊을 때는 무조건 힘든 일을 하는 것이 좋다”며 “직급이 올라가면 경험할 수 없는 부분”이라고 말했다. ‘여자는 절대 못한다’던 영업에 지원했고 상품기획과 라이선스, 마케팅과 정산까지 두루 겪었다. 외환위기 때는 사직서를 쓰겠다는 독한 각오로 새 브랜드를 론칭하기도 했다. 팀장 자리에 올랐을 때는 ‘리더십’이라는 또 다른 벽에 부딪혔다. 김 상무는 “리더십은 남녀의 문제가 아니라 인내심, 포용력, 그리고 조직에 대한 깊은 이해가 필요한 것”이라고 말했다. 이어 “전문성과 실력보다는 소통능력과 상대를 배려하는 마음이 부족해 어려움을 겪기 쉽다”고 했다. 이를 넘어서려면 ‘차별’이 아닌 ‘차이’를 인정하라고 조언했다. 남성에 비해 개인 우선이고 관계 중심적이며 스트레스에 취약한 여성의 약점을 완벽하고 섬세한 강점으로 바꿔가라는 것이다.배우자를 택할 때는 스펙(조건)보다 가치관을 따져볼 것을 권했다. 김 상무는 “배우자 조건이 좋을수록 여성은 일을 포기해야 할 확률이 높다”며 “슈퍼맘 콤플렉스에서 벗어나 일과 삶의 균형을 잡으라”고 조언했다. “아이와 함께 있는 시간은 양보다 질이 중요하다”며 “엄마가 하는 일을 자랑스럽게 여길 수 있게 하라”고도 했다. 여성복사업부를 이끌고 있는 김 상무는 제일모직에서 글로벌 여성복 브랜드를 키우는 것이 목표다. “문화산업인 패션 부문에서 선진국의 장벽은 높지만 한국의 성장 잠재력은 무한하다”고 자신한다. 그는 지금도 도전 중이다.\n",
      "-----\n",
      "문서2: ‘지원자 0명.’ 지난 2일 마감한 서울아산병원의 내년도 비뇨기과 전공의(레지던트) 모집 결과다. 모집 정원은 4명이었다.매년 12월 초 대학병원들은 전공별 레지던트 1년차를 모집한다. 이들은 4년 정도의 수련 기간을 거쳐 전문의가 된다. 전공의 지원율은 의사들이 어떤 과를 선호하는지를 알 수 있는 지표다.비뇨기과는 최근 몇 년간 외과, 산부인과와 함께 비인기과 신세를 벗어나지 못하고 있다. 하지만 올해 비뇨기과 상황은 더 심각해졌다. 전공의 지원율이 30%도 넘지 못할 것이라는 관측이 나오고 있다. 전체 임상과 중 최저 수준이다.의사들이 몰리는 서울아산병원 등 빅5 병원조차 정원을 채우지 못했다. 삼성서울병원은 3명을 모집했지만 1명밖에 지원하지 않았다. 신촌세브란스병원은 5명 모집에 1명이 지원했고 서울성모병원이 포함된 가톨릭중앙의료원은 6명 모집에 2명이 지원했다. 서울대병원만 지원자가 정원인 4명을 채웠을 뿐이다. 빅5 병원 중 한 곳의 비뇨기과 교수 A씨는 “요실금, 과민성 방광 등 비뇨기과 고유의 치료 영역을 내과, 가정의학과, 산부인과 등 다른 진료과에 뺏기면서 비뇨기과 의사들이 설 자리를 잃고 있다”고 말했다. ‘비뇨기과는 남성질환과’라는 인식이 강해져 여성들의 발걸음이 끊겼고 ‘남성질환은 정력 때문’이라는 편견 탓에 남성조차 잘 찾지 않는 과가 됐다는 것이다.\n",
      "-----\n",
      "문서3: 외모를 주로 평가하는 가입 심사에 통과해야 회원이 될 수 있는 스마트폰 애플리케이션(앱)이 등장해 논란이 일고 있다. 대학가에서 최근 온라인 소개팅인 ‘소셜데이팅’ 앱인 ‘아무나 만나지 않는다(아만다)’가 화제다. 지난 10월 첫선을 보인 이 앱은 누적 가입 신청자 수가 5만명을 넘어섰고, 특히 이달 첫주에만 2만명이 몰렸다.아만다의 회원 가입 방식은 출신 대학 등에 따라 제한을 둬 비판을 받았던 기존 소셜데이팅보다 더 까다롭다. 누구나 가입을 신청할 수 있지만, 기존 이성 회원들의 심사를 통과해야 한다. 신청자가 본인의 사진과 출신 대학·직장 등 간단한 정보가 담긴 프로필을 올리면 기존 회원 30명이 0~5점 사이 평점을 매긴다. 여기에서 평균 3점 이상을 받아야 회원 자격을 얻는다.가입 심사가 신청자의 얼굴 사진 위주로 진행되는 탓에 학생들 사이에선 ‘아만다 평점으로 본인 외모 수준을 알 수 있다’는 얘기가 퍼졌다. 1점대는 ‘오크’, 2점대는 ‘평범’, 3점대는 ‘훈남·훈녀’, 4점대는 아주 잘생겼다는 의미의 ‘존잘·존예’ 등과 같은 ‘얼평(얼굴평가)’ 척도도 유행하고 있다. 3점에 미달해 가입이 거절되면 사진을 바꿔 몇 번이고 재신청하는 경우도 있다.이 앱이 인기를 끌자 ‘외모지상주의’를 부추긴다는 비판도 커지고 있다. 대학생 정모씨(24)는 “외모가 뛰어나 합격한 사람은 다른 이의 외모를 평가할 자격이 있다는 것인가”라고 물었다. 한 여학생은 “아만다에서 떨어진 뒤 더 예뻐지기 위해 노력해야겠다고 느꼈다”고 했다.이 같은 논란에 대해 앱 개발사의 신모 대표는 “사용자들이 스스로 만나고 싶은 사람의 기준을 설정할 수 있어 사업자가 임의로 출신 대학 등 가입 자격을 제한하는 기존의 소셜데이팅과 비교해 합리적인 방식”이라고 주장했다.\n",
      "-----\n",
      "문서4: 여자 축구 종목은 보은 상무팀이다. 2014년 11월 4일 열린 2015 WK리그 드래프트에서 전체 6순위로 최유리 선수가 보은 상무로 지명되자 다른 건 몰라도 절대로 군복무만은 할 수 없다는 이유로 최유리는 이 드래프트를 거절했다. 이 이유로 인해 최유리는 '2년간 선수등록 금지'라는 중징계를 받고 무적 선수가 되었지만 대한축구협회에서는 일반적인 팀이라면 드래프트 거절에 대해 처벌이 정당하지만 이 경우 병역의 의무가 부과되지 않는 여성에게 축구선수라는 이유만으로 국방부에서 징병권을 행사한 사례라고 판단하여 최유리의 징계를 1년으로 단축시켰다. 이후 최유리는 세종 스포츠토토로 재드래프트 되어 입단했다.\n",
      "\n",
      "과거 대한민국의 여자 축구 선수는 무조건 드래프트 되는 팀대로 가야 했는데 그래서 보은 상무로 드래프트 되면 본인은 꿈에도 없던 군복무를 해야 하는 상황에 처했으며 이 때문에 드래프트에 의해 여자임에도 강제징집당해 어쩔 수 없이 군복무를 해야만 했던 보은 상무 소속의 선수들은 입단하면서 피눈물을 흘려가며 대성통곡을 해야만 했다. 하지만 최유리의 드래프트 거절로 인해 보은 상무 한정으로, '군복무'라는 특성을 감안하여 지원자를 먼저 받은 후 지원자를 채우지 못할 경우에 한정되어 드래프트를 하도록 되어 있고 다른 팀이라면 몰라도 보은 상무에 한해서는 해당 선수가 드래프트를 거절할 수 있도록 방침이 변경되었다. 이에 여자 축구 선수들은 최유리의 보은 상무 드래프트 거절 사건으로 인해 원치 않는 군복무를 하지 않아도 되는 여건이 조성되었으며 이로 인해 최유리 선수는 모든 여자 축구 선수들의 존경을 한몸에 받게 되었다.\n",
      "-----\n",
      "문서5: “취업이 안 되니 결혼을 생각할 여유가 없죠.” “굳이 결혼을 안 하겠다는 건 아니지만 (결혼이) 사회 진출 확대나 경력 관리에 큰 도움이 안되는 것은 사실이잖아요.”20대 여자대학생에게 결혼은 ‘언감생심’이다. 당장 졸업 후의 취업부터가 막막해 결혼을 꿈꾸는 건 불가능에 가깝다. ‘계륵’ 같은 것이기도 하다. 안 하면 왠지 후회할 것 같고, 그렇다고 하자니 자신이 꿈꾸는 인생에 걸림돌로 작용할 것 같은 느낌이다.이화여대 4학년 L씨(25)는 “제 또래가 생각하는 대학 졸업 후의 단계는 취업이지 결혼이 아니다”며 “일단 취업을 해야 직장 내 경력 개발과 결혼 생활을 병행할 수 있다고 생각한다”고 말했다. 자신에게 ‘졸업-취업-결혼’의 순서는 ‘불변’이라는 것이다. 마케팅 분야 취업을 준비하고 있는 그는 “각종 입사시험에 원서를 내고 있지만 1단계인 서류전형에서부터 낙방하는 일이 부지기수”라며 “내 앞길이 불투명한데 다른 사람과 가정을 꾸리는 일을 상상할 수 있겠느냐”고 반문했다.학사과정을 수료한 뒤에도 세 학기나 졸업을 연기하다 지난해 2월 미취업 상태로 숙명여대를 졸업한 K씨(27). 최근 1년여간 사귄 서른 살의 남자친구와 결별한 뒤 쓰린 속을 달래고 있다. “서로에게서 미래가 안 보인다”며 이별을 결정한 것. K씨는 “20대 초반엔 ‘27세쯤이면 직업도, 남자친구와의 관계도 안정적일 것’이라고 생각했는데 지금 보니 아무것도 이뤄진 게 없다”고 말했다.젊은 여성들의 자의식이 강해지면서 결혼이라는 울타리에 속박당하고 싶지 않다는 생각도 확산되고 있다. 홍익대 4학년에 재학 중인 P씨(26)는 결혼하지 않고 평생 연애만 하며 살고 싶다는 생각이다. 서로 의지하며 살 동반자는 필요하지만 결혼이라는 ‘제도’에 묶이긴 싫다는 것. P씨는 “나 자신을 제대로 챙기기도 어려운데 나중에 ‘시월드’(시댁을 가리키는 신조어)까지 어떻게…”라며 말끝을 흐렸다. P씨는 “결혼은 상대를 으레 그곳에 있는 ‘당연한 존재’로 만들어버린다”고도 우려했다. 연애 관계에는 비교적 긴장감이 있지만 결혼 관계는 느슨해지기 쉽다는 것이다.남자대학생들의 결혼관도 여학생들과 크게 다르지 않다. 무조건 취업이 우선이다. 남성의 경제적 역할에 대한 기대가 여전한 만큼 어쩔 수 없는 일이다. 순천향대 4학년 J씨(25)는 한 살 어린 여자친구와 ‘죽고 못 사는’ 사이라고 한다. 경제적 여건만 갖춰지면 당장 결혼하고 싶단다. 하지만 여전히 취업 문턱을 넘지 못하고 있다. 이미 직장생활을 하고 있는 여자친구가 종종 “오빠랑 결혼하려면 언제까지 기다려야 하는 거야”라고 애교를 부리며 물어오면 웃음으로 얼버무린다. 또래에 비해 대학에 오래 재학 중인 홍익대 4학년 K씨(28)도 비슷한 생각이다. 전문 자격증 취득을 위해 졸업을 미루고 있는 그는 “결혼해서 안착하고 싶지만 가정을 꾸릴 준비를 하는 데 너무 많은 시간이 소요된다”고 말했다. 결혼 적령기 남녀의 ‘상황 불일치’도 문제라고 그는 말했다. 20대 후반 남성은 한창 취업을 준비하는 경우가 많은데 그들의 여자친구 연령대인 20대 중후반 여성은 이미 직장인 중에 결혼 상대를 물색하기 시작한다는 것. 지난해 김씨가 학원강사였던 여자친구와 헤어진 이유도 그랬다. “그 친구는 결혼 얘기를 꺼내는데, 저는 응할 수가 없으니 어쩔 수 없었습니다.”<|im_end|>\n",
      "<|im_start|>user\n",
      "여대생이라는 이유로 지원서를 받지 못한 인물의 이름<|im_end|>\n",
      "<|im_start|>assistant\n"
     ]
    }
   ],
   "source": [
    "# 20번 테스트 샘플 출력\n",
    "print(prompt_lst[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "68475cf6-6696-4def-aee3-8558af6a0402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "여대생이라는 이유로 지원서를 받지 못한 인물은 김정미 제일모직 상무입니다. 김정미 상무는 21년 전 삼성 본관 인사팀을 찾아가 입사 원서를 요청했으나, 여대생이라는 이유로 거부당했습니다. 당시 인사 담당자는 \"군필이에요?\"라고 물었고, 김 상무가 \"저는 면제예요. 원서 주세요.\"라고 대답했지만, 결국 지원서를 받지 못했습니다. [[ref1]]<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 임의의 20번 테스트 샘플 레이블 출력\n",
    "print(label_lst[20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae03139-f90e-4e95-bb08-af23071d9b09",
   "metadata": {},
   "source": [
    "## 기본 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5d0276b-17c0-454c-86db-65cb6aa1378a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline 객체와 LLM의 입력을 넣으면 LLM의 답변을 출력해주는 함수\n",
    "def test_inference(pipe, prompt):\n",
    "    outputs = pipe(prompt, max_new_tokens=1024, eos_token_id=eos_token, do_sample=False)\n",
    "    return outputs[0]['generated_text'][len(prompt):].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5fabc4c4-04d6-4e99-90b7-07d669d71f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b327804092f4bbb8b13993386035e14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained('Qwen/Qwen2-7B-Instruct', device_map=\"auto\", torch_dtype=torch.float16)\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "eos_token = tokenizer(\"<|im_end|>\", add_special_tokens=False)[\"input_ids\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b9a774-645c-4e5b-9661-0cba55778124",
   "metadata": {},
   "source": [
    "기본 모델에 임의로 20번 샘플을 넣어서 출력합니다. 기본 모델은 출처를 남기지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e90e035a-5396-4bb7-8516-0112eabdb070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "김정미 제일모직 상무가 해당 질문에 대한 내용이 있습니다. 그녀는 21년 전 삼성 본관 25층 인사팀의 방명록에 \"여대생이라는 이유에서 거부당한 것\"을 언급하였습니다.\n"
     ]
    }
   ],
   "source": [
    "result = test_inference(pipe, prompt_lst[20])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642dab44-f3da-4d46-92c5-a13cb6164c8e",
   "metadata": {},
   "source": [
    "기본 모델에 임의로 400~404번 샘플을 출력합니다. 기본 모델은 지시사항에서 출처를 남기라는 지시를 따르지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "806f812b-aba1-4197-9c5f-87e069fb6a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    response:\n",
      "문서4에 따르면, 신탁통치반대운동이 찬반으로 나뉘어지게 한 언론은 '민족일보'입니다. 문서에서는 \"민족일보는 1985년에 체결된 한미경제원조협정에 대한 집중적인 비판을 통해 정권을 무너뜨리려는 시도를 했다\"고 기록하고 있습니다.\n",
      "    label:\n",
      "\n",
      "잘못된 보도로 인해 신탁통치반대운동이 찬반으로 나뉘게 한 언론은 동아일보입니다. 동아일보의 오보가 신탁 통치 반대 운동을 좌우 양측으로 나뉘게 한 주요 원인 중 하나로 기록되어 있습니다 [[ref2]].<|im_end|>\n",
      "\n",
      "--------------------------------------------------\n",
      "    response:\n",
      "인종에 따른 편향을 실험한 나라는 미국입니다. 문서5에서 언급된 TV 뉴스 실험은 미국에서 진행되었습니다. 이 실험은 가상의 뉴스를 시청하게 된 참가자들이 용의자가 백인인지 흑인인지에 따라 범죄를 우려하는 정도가 달라지는 것을 확인하였습니다.\n",
      "    label:\n",
      "\n",
      "인종에 따른 편향을 실험한 나라는 미국입니다. 문서5에 따르면, 미국에서 행해진 TV 뉴스 실험에서 참여자들을 두 그룹으로 나누어 가상으로 만들어진 뉴스를 시청하게 하였고, 아동성폭력을 보도하는 같은 뉴스에서 한 그룹은 용의자가 백인으로 제시된 뉴스를, 다른 그룹은 용의자가 흑인으로 제시된 뉴스를 시청하였습니다. 그 결과 흑인이 용의자로 지목된 뉴스를 시청한 그룹이 보다 더 범죄를 우려하는 반응을 보였고 흑인을 일반적으로 범죄와 연결시키는 편향을 보였습니다 [[ref5]].<|im_end|>\n",
      "\n",
      "--------------------------------------------------\n",
      "    response:\n",
      "2009년에 15명의 교사들이 받은 징계의 원인은 그들이 전국교직원노동조합(전교조)의 시국선언에 참여하였기 때문입니다. 이 시국선언은 국가공무원법의 집단행위 금지 조항과 교원노조법의 정치 활동 금지 조항을 어긴 것이라는 이유로 교육과학기술부로부터 징계를 받았습니다.\n",
      "    label:\n",
      "\n",
      "2009년에 15명의 교사들이 받은 징계의 원인은 \"시국선언\"을 한 것 때문입니다. 당시 교육과학기술부는 전교조의 시국선언이 국가공무원법의 집단행위 금지 조항과 교원노조법의 정치 활동 금지 조항을 위반했다고 판단하여 징계를 내렸습니다. 이 징계는 교사들의 정치적 중립을 이유로 한 것이었으며, 전교조는 이에 대해 표현의 자유를 억압하는 것이라며 반발했습니다 [[ref4]].<|im_end|>\n",
      "\n",
      "--------------------------------------------------\n",
      "    response:\n",
      "교과부의 행동에 화가 나 여러명이 사직한 기구의 이름은 '역사교육과정 개발 추진위원회'입니다. 이 기구의 9명의 위원이 교과부가 논의 없이 일방적으로 내용을 바꾼 안을 수용한 것에 대해 반발하여 집단 사퇴하였습니다.\n",
      "    label:\n",
      "\n",
      "교과부의 일방적인 역사교과 교육과정 변경에 화가 나서 여러 명이 사직한 기구는 \"역사교육과정개발추진위원회\"입니다. 이 위원회의 위원 9명은 교과부가 논의 없이 일방적으로 내용을 바꿨다며 집단 사퇴했습니다 [[ref1]].<|im_end|>\n",
      "\n",
      "--------------------------------------------------\n",
      "    response:\n",
      "이명박 대통령이 직접 찾은 학교에 대한 정보는 제공된 검색 결과에서 확인할 수 없습니다. 따라서 \"이명박 대통령이 직접 찾은 학교에 대한 내용이 없습니다.\" 라고 답변합니다.\n",
      "    label:\n",
      "\n",
      "이명박 대통령이 직접 찾은 학교는 마이스터고입니다. 이명박 정부는 '고교 다양화 300 프로젝트'의 일환으로 자율형 사립고, 기숙형 공립고, 마이스터 고교를 설립하겠다고 발표했으며, 이명박 대통령은 마이스터고를 방문하여 추진 의지를 밝힌 바 있습니다 [[ref3]].<|im_end|>\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for prompt, label in zip(prompt_lst[400:405], label_lst[400:405]):\n",
    "    print(f\"    response:\\n{test_inference(pipe, prompt)}\")\n",
    "    print(f\"    label:\\n{label}\")\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80eea975-5f02-47c6-8230-d90a35eeca88",
   "metadata": {},
   "source": [
    "## 튜닝 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efc5cfd7-6bff-4fce-b59d-b53281cebc86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "804c538e06104ee0894ab0ecd3fadabc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FalconMambaForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'GraniteForCausalLM', 'GraniteMoeForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'LlamaForCausalLM', 'MambaForCausalLM', 'Mamba2ForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MllamaForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'NemotronForCausalLM', 'OlmoForCausalLM', 'OlmoeForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
     ]
    }
   ],
   "source": [
    "peft_model_id = \"qwen2-7b-rag-ko/checkpoint-177\"\n",
    "fine_tuned_model = AutoPeftModelForCausalLM.from_pretrained(peft_model_id, device_map=\"auto\", torch_dtype=torch.float16)\n",
    "fine_tuned_pipe = pipeline(\"text-generation\", model=fine_tuned_model, tokenizer=tokenizer)\n",
    "eos_token = tokenizer(\"<|im_end|>\", add_special_tokens=False)[\"input_ids\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd0c139-3e37-4e0f-82c3-838698611697",
   "metadata": {},
   "source": [
    "튜닝 모델에 임의로 20번 샘플을 넣어서 출력합니다. 튜닝 모델은 출처를 남깁니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d2e5f8c5-86df-4eb4-8acc-38370ef822f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "지원서를 받지 못한 인물의 이름은 김정미 제일모직 상무입니다. [[ref1]]\n"
     ]
    }
   ],
   "source": [
    "result = test_inference(fine_tuned_pipe, prompt_lst[20])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb85cb2d-720b-4413-8da3-03ff17220946",
   "metadata": {},
   "source": [
    "튜닝 모델에 임의로 400~404번 샘플을 출력합니다. 튜닝 모델은 튜닝이 되었으므로 프롬프트 지시사항에 따라서 출처를 남기는 모습을 보여줍니다.  \n",
    "물론, 출처를 남기지 않는 샘플들도 존재할 것입니다. 이는 학습이 덜 된 것이므로 학습 데이터의 비율을 높이고 에포크를 높이시기 바랍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "969c8f49-2fca-4f4e-ba2b-e48c3ac9b500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    response:\n",
      "잘못된 보도로 인해 신탁통치반대운동이 찬반으로 나뉘어지게 한 언론은 동아일보입니다. 문서2에서 언급된 내용에 따르면, 동아일보의 오보가 없었더라도 빠르게 정착되던 냉전 구도는 좌우 이념 대립을 격화시켰을 것이며, 신탁 통치 반대 운동이 좌우 양측으로 나뉘어 찬반이 격렬하게 진행된 이유로 동아일보의 오보가 언급되었습니다 [[ref2]].\n",
      "    label:\n",
      "\n",
      "잘못된 보도로 인해 신탁통치반대운동이 찬반으로 나뉘게 한 언론은 동아일보입니다. 동아일보의 오보가 신탁 통치 반대 운동을 좌우 양측으로 나뉘게 한 주요 원인 중 하나로 기록되어 있습니다 [[ref2]].<|im_end|>\n",
      "\n",
      "--------------------------------------------------\n",
      "    response:\n",
      "인종에 따른 편향을 실험한 나라는 미국입니다. 문서5에서 언급된 TV 뉴스 실험은 미국에서 행해졌습니다. 이 실험은 두 그룹의 참여자들에게 동일한 가상의 뉴스를 시청하게 하였는데, 한 그룹은 용의자가 백인으로, 다른 그룹은 용의자가 흑인으로 제시된 뉴스를 시청하게 하였습니다. 이 실험을 통해 인종에 따른 편향을 연구하였습니다 [[ref5]].\n",
      "    label:\n",
      "\n",
      "인종에 따른 편향을 실험한 나라는 미국입니다. 문서5에 따르면, 미국에서 행해진 TV 뉴스 실험에서 참여자들을 두 그룹으로 나누어 가상으로 만들어진 뉴스를 시청하게 하였고, 아동성폭력을 보도하는 같은 뉴스에서 한 그룹은 용의자가 백인으로 제시된 뉴스를, 다른 그룹은 용의자가 흑인으로 제시된 뉴스를 시청하였습니다. 그 결과 흑인이 용의자로 지목된 뉴스를 시청한 그룹이 보다 더 범죄를 우려하는 반응을 보였고 흑인을 일반적으로 범죄와 연결시키는 편향을 보였습니다 [[ref5]].<|im_end|>\n",
      "\n",
      "--------------------------------------------------\n",
      "    response:\n",
      "2009년에 15명의 교사들이 받은 징계의 원인은 \"전국교직원노동조합(전교조)의 시국선언\"입니다. 2009년 6월, 이명박 정부의 교육과학기술부는 전교조에 대해 수차례 징계를 내리며 대립해왔습니다. 2009년 6월에는 1만7000명에 대해 파면, 해임 등 무더기 징계를 내렸고, 2009년 7월에도 시국선언을 한 교사 15명에 대해서 징계를 내렸습니다. 전교조의 시국선언은 국가공무원법의 집단행위 금지 조항과 교원노조법의 정치 활동 금지 조항을 어긴 것이라는 이유로 징계를 내렸습니다 [[ref4]].\n",
      "    label:\n",
      "\n",
      "2009년에 15명의 교사들이 받은 징계의 원인은 \"시국선언\"을 한 것 때문입니다. 당시 교육과학기술부는 전교조의 시국선언이 국가공무원법의 집단행위 금지 조항과 교원노조법의 정치 활동 금지 조항을 위반했다고 판단하여 징계를 내렸습니다. 이 징계는 교사들의 정치적 중립을 이유로 한 것이었으며, 전교조는 이에 대해 표현의 자유를 억압하는 것이라며 반발했습니다 [[ref4]].<|im_end|>\n",
      "\n",
      "--------------------------------------------------\n",
      "    response:\n",
      "교과부의 행동에 화가 나 여러명이 사직한 기구의 이름은 \"역사교육과정 개발 추진위원회\"입니다. 이 기구는 2011년 교육과정 개정 과정에서 교과부가 일방적으로 내용을 변경한 것에 대해 반발하여 집단 사퇴하였습니다 [[ref1]].\n",
      "    label:\n",
      "\n",
      "교과부의 일방적인 역사교과 교육과정 변경에 화가 나서 여러 명이 사직한 기구는 \"역사교육과정개발추진위원회\"입니다. 이 위원회의 위원 9명은 교과부가 논의 없이 일방적으로 내용을 바꿨다며 집단 사퇴했습니다 [[ref1]].<|im_end|>\n",
      "\n",
      "--------------------------------------------------\n",
      "    response:\n",
      "이명박 대통령이 직접 찾은 학교는 '삼각산중(서울 미아동)'입니다. 이 학교는 '기술대장정'에 참가한 학교로, 교육부와 고용노동부 산하 한국산업인력공단이 마련한 프로그램입니다 [[ref3]].\n",
      "    label:\n",
      "\n",
      "이명박 대통령이 직접 찾은 학교는 마이스터고입니다. 이명박 정부는 '고교 다양화 300 프로젝트'의 일환으로 자율형 사립고, 기숙형 공립고, 마이스터 고교를 설립하겠다고 발표했으며, 이명박 대통령은 마이스터고를 방문하여 추진 의지를 밝힌 바 있습니다 [[ref3]].<|im_end|>\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for prompt, label in zip(prompt_lst[400:405], label_lst[400:405]):\n",
    "    print(f\"    response:\\n{test_inference(fine_tuned_pipe, prompt)}\")\n",
    "    print(f\"    label:\\n{label}\")\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2aaf77-6bac-4f3a-a01d-05b4c29bb4d0",
   "metadata": {},
   "source": [
    "## Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a8eea3a7-8df7-40c7-aaa8-496053bee96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading base model: Qwen/Qwen2-7B-Instruct\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:17<00:00,  4.42s/it]\n",
      "Loading PEFT: ./qwen2-7b-rag-ko/checkpoint-177\n",
      "Running merge_and_unload\n",
      "[2025-03-15 16:03:38,654] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Model saved to ./output_dir\n"
     ]
    }
   ],
   "source": [
    "!python merge.py \\\n",
    "    --base_model_name_or_path Qwen/Qwen2-7B-Instruct \\\n",
    "    --peft_model_path ./qwen2-7b-rag-ko/checkpoint-177 \\\n",
    "    --output_dir ./output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54db3535-0bc7-46b9-86cc-6ef9ccf8ab7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실습 후에는 상단의 Kernel > Shut Down Kernel을 눌러서 종료합니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
