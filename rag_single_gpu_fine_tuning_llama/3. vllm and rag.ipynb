{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaa04369-0c54-4e0f-b81a-127e858dffd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.21)\n",
      "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.3.20)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.50.3)\n",
      "Requirement already satisfied: vllm in /usr/local/lib/python3.10/dist-packages (0.8.2)\n",
      "Requirement already satisfied: faiss-gpu in /usr/local/lib/python3.10/dist-packages (1.7.2)\n",
      "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (5.4.0)\n",
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (4.0.1)\n",
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.29.3)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.49)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.7)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.19)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.11.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.11.14)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (9.0.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.8.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from vllm) (5.5.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from vllm) (5.9.6)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from vllm) (0.2.0)\n",
      "Requirement already satisfied: blake3 in /usr/local/lib/python3.10/dist-packages (from vllm) (1.0.4)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from vllm) (9.0.0)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from vllm) (6.30.2)\n",
      "Requirement already satisfied: fastapi>=0.115.0 in /usr/local/lib/python3.10/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.115.12)\n",
      "Requirement already satisfied: openai>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (1.69.0)\n",
      "Requirement already satisfied: prometheus_client>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.18.0)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from vllm) (11.1.0)\n",
      "Requirement already satisfied: prometheus-fastapi-instrumentator>=7.0.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (7.1.0)\n",
      "Requirement already satisfied: tiktoken>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.9.0)\n",
      "Requirement already satisfied: lm-format-enforcer<0.11,>=0.10.11 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.10.11)\n",
      "Requirement already satisfied: llguidance<0.8.0,>=0.7.9 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.7.11)\n",
      "Requirement already satisfied: outlines==0.1.11 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.1.11)\n",
      "Requirement already satisfied: lark==1.2.2 in /usr/local/lib/python3.10/dist-packages (from vllm) (1.2.2)\n",
      "Requirement already satisfied: xgrammar==0.1.16 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.1.16)\n",
      "Requirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.10/dist-packages (from vllm) (4.13.0)\n",
      "Requirement already satisfied: partial-json-parser in /usr/local/lib/python3.10/dist-packages (from vllm) (0.2.1.1.post5)\n",
      "Requirement already satisfied: pyzmq in /usr/local/lib/python3.10/dist-packages (from vllm) (24.0.1)\n",
      "Requirement already satisfied: msgspec in /usr/local/lib/python3.10/dist-packages (from vllm) (0.19.0)\n",
      "Requirement already satisfied: gguf==0.10.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.10.0)\n",
      "Requirement already satisfied: importlib_metadata in /usr/lib/python3/dist-packages (from vllm) (4.6.4)\n",
      "Requirement already satisfied: mistral_common>=1.5.4 in /usr/local/lib/python3.10/dist-packages (from mistral_common[opencv]>=1.5.4->vllm) (1.5.4)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from vllm) (0.8.1)\n",
      "Requirement already satisfied: compressed-tensors==0.9.2 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.9.2)\n",
      "Requirement already satisfied: depyf==0.18.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.18.0)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from vllm) (3.1.1)\n",
      "Requirement already satisfied: watchfiles in /usr/local/lib/python3.10/dist-packages (from vllm) (1.0.4)\n",
      "Requirement already satisfied: python-json-logger in /usr/local/lib/python3.10/dist-packages (from vllm) (2.0.7)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from vllm) (1.15.2)\n",
      "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from vllm) (1.11.1.4)\n",
      "Requirement already satisfied: numba==0.60.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.60.0)\n",
      "Requirement already satisfied: ray>=2.43.0 in /usr/local/lib/python3.10/dist-packages (from ray[cgraph]>=2.43.0->vllm) (2.44.1)\n",
      "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (2.6.0)\n",
      "Requirement already satisfied: torchaudio==2.6.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (2.6.0)\n",
      "Requirement already satisfied: torchvision==0.21.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.21.0)\n",
      "Requirement already satisfied: xformers==0.0.29.post2 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.0.29.post2)\n",
      "Requirement already satisfied: astor in /usr/local/lib/python3.10/dist-packages (from depyf==0.18.0->vllm) (0.8.1)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from depyf==0.18.0->vllm) (0.3.9)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba==0.60.0->vllm) (0.43.0)\n",
      "Requirement already satisfied: interegular in /usr/local/lib/python3.10/dist-packages (from outlines==0.1.11->vllm) (0.3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from outlines==0.1.11->vllm) (3.1.6)\n",
      "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (from outlines==0.1.11->vllm) (1.5.8)\n",
      "Requirement already satisfied: diskcache in /usr/local/lib/python3.10/dist-packages (from outlines==0.1.11->vllm) (5.6.3)\n",
      "Requirement already satisfied: referencing in /usr/local/lib/python3.10/dist-packages (from outlines==0.1.11->vllm) (0.30.2)\n",
      "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from outlines==0.1.11->vllm) (4.23.0)\n",
      "Requirement already satisfied: pycountry in /usr/local/lib/python3.10/dist-packages (from outlines==0.1.11->vllm) (24.6.1)\n",
      "Requirement already satisfied: airportsdata in /usr/local/lib/python3.10/dist-packages (from outlines==0.1.11->vllm) (20250224)\n",
      "Requirement already satisfied: outlines_core==0.1.26 in /usr/local/lib/python3.10/dist-packages (from outlines==0.1.11->vllm) (0.1.26)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.6.0->vllm) (3.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.6.0->vllm) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch==2.6.0->vllm) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch==2.6.0->vllm) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch==2.6.0->vllm) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch==2.6.0->vllm) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/dist-packages (from torch==2.6.0->vllm) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.6.0->vllm) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/dist-packages (from torch==2.6.0->vllm) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.10/dist-packages (from torch==2.6.0->vllm) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/dist-packages (from torch==2.6.0->vllm) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.10/dist-packages (from torch==2.6.0->vllm) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/dist-packages (from torch==2.6.0->vllm) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch==2.6.0->vllm) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch==2.6.0->vllm) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.6.0->vllm) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.6.0->vllm) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch==2.6.0->vllm) (1.3.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm) (0.46.1)\n",
      "Requirement already satisfied: fastapi-cli>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.0.7)\n",
      "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.28.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.10/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.0.20)\n",
      "Requirement already satisfied: email-validator>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from fastapi[standard]>=0.115.0->vllm) (2.2.0)\n",
      "Requirement already satisfied: uvicorn>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.34.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (1.33)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: opencv-python-headless>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mistral_common[opencv]>=1.5.4->vllm) (4.11.0.86)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.52.0->vllm) (4.0.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.52.0->vllm) (1.7.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.52.0->vllm) (0.9.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.52.0->vllm) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray>=2.43.0->ray[cgraph]>=2.43.0->vllm) (8.1.8)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray>=2.43.0->ray[cgraph]>=2.43.0->vllm) (1.1.0)\n",
      "Requirement already satisfied: cupy-cuda12x in /usr/local/lib/python3.10/dist-packages (from ray[cgraph]>=2.43.0->vllm) (13.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.52.0->vllm) (1.1.3)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->vllm) (2.7.0)\n",
      "Requirement already satisfied: typer>=0.12.3 in /usr/local/lib/python3.10/dist-packages (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.15.2)\n",
      "Requirement already satisfied: rich-toolkit>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.14.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->outlines==0.1.11->vllm) (2.1.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain) (2.4)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->outlines==0.1.11->vllm) (2023.7.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->outlines==0.1.11->vllm) (0.12.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.6.4)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.21.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (15.0.1)\n",
      "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.10/dist-packages (from cupy-cuda12x->ray[cgraph]>=2.43.0->vllm) (0.8.3)\n",
      "Requirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.10/dist-packages (from rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (13.9.4)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (1.5.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.7.1->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.7.1->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (2.16.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain-community transformers vllm faiss-gpu pypdf sentence-transformers huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4736c7e0-3268-4c2b-bbf1-6d9d1ceb8bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 03-29 00:41:27 [__init__.py:239] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 import\n",
    "import os\n",
    "import tempfile\n",
    "import requests\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from transformers import AutoTokenizer\n",
    "from vllm import LLM, SamplingParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15a480bd-ccad-4190-bc93-0b9013631f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다운로드 중: https://raw.githubusercontent.com/llama-index-tutorial/llama-index-tutorial/main/ch06/ict_usa_2024.pdf\n",
      "PDF가 다운로드 되었습니다: /tmp/ict_usa_2024.pdf\n"
     ]
    }
   ],
   "source": [
    "# PDF 파일 다운로드\n",
    "pdf_url = \"https://raw.githubusercontent.com/llama-index-tutorial/llama-index-tutorial/main/ch06/ict_usa_2024.pdf\"\n",
    "temp_dir = tempfile.gettempdir()\n",
    "pdf_path = os.path.join(temp_dir, \"ict_usa_2024.pdf\")\n",
    "\n",
    "print(f\"다운로드 중: {pdf_url}\")\n",
    "urlretrieve(pdf_url, pdf_path)\n",
    "print(f\"PDF가 다운로드 되었습니다: {pdf_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d743472c-2226-47d1-b3a3-8e4ff8b72fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF에서 추출된 문서 수: 29\n",
      "첫 번째 문서 샘플: 미국\n"
     ]
    }
   ],
   "source": [
    "# PDF 로드\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "documents = loader.load()\n",
    "print(f\"PDF에서 추출된 문서 수: {len(documents)}\")\n",
    "print(f\"첫 번째 문서 샘플: {documents[0].page_content[:200]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9213c87b-3e70-4de8-b1ba-610867bea071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "청킹 전 청크 수: 46\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 청킹\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    ")\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "print(f\"청킹 전 청크 수: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66439225-4efb-4556-a8a0-f3437e85df4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "필터링 전 청크 수: 46\n",
      "필터링 후 청크 수: 43\n",
      "제거된 청크 샘플 (3개): [Document(metadata={'producer': 'Hancom PDF 1.3.0.538', 'creator': 'Hwp 2018 11.0.0.2129', 'creationdate': '2024-06-04T14:47:21+09:00', 'author': 'ec21rnc', 'moddate': '2024-06-04T14:47:21+09:00', 'pdfversion': '1.4', 'source': '/tmp/ict_usa_2024.pdf', 'total_pages': 29, 'page': 0, 'page_label': '1'}, page_content='미국'), Document(metadata={'producer': 'Hancom PDF 1.3.0.538', 'creator': 'Hwp 2018 11.0.0.2129', 'creationdate': '2024-06-04T14:47:21+09:00', 'author': 'ec21rnc', 'moddate': '2024-06-04T14:47:21+09:00', 'pdfversion': '1.4', 'source': '/tmp/ict_usa_2024.pdf', 'total_pages': 29, 'page': 3, 'page_label': '4'}, page_content='4'), Document(metadata={'producer': 'Hancom PDF 1.3.0.538', 'creator': 'Hwp 2018 11.0.0.2129', 'creationdate': '2024-06-04T14:47:21+09:00', 'author': 'ec21rnc', 'moddate': '2024-06-04T14:47:21+09:00', 'pdfversion': '1.4', 'source': '/tmp/ict_usa_2024.pdf', 'total_pages': 29, 'page': 16, 'page_label': '17'}, page_content='17')]\n",
      "--\n",
      "첫 번째 청크 샘플: Ⅰ ICT국가산업현황  4(*) SUMMARY1. 국가 개황2. ICT 정부기구3. ICT 주요정책4. ICT 주요법령및규제5. ICT 주요기업6. 한국 협력 및 국내기업 진출사례Ⅱ ICT이슈Top 10  16(*) SUMMARY① 미국 빅테크 기업, 인공지능 챗봇 개발에 주력② 미국, 일본과 양자컴퓨팅 개발 협력③ 미국, 우주 클라우드 컴퓨팅 시장 주도④ 미국, 드론 배송 도입 활발⑤ 미국, 긍정적인 의료 AI 인식 바탕으로 연구 활발⑥ 미국, 반도체 산업 활성화에 박차⑦ 미국, 기술 교류를 위한 국가 간 협력 활발⑧ 미국, 사이버 보안 대응 강화⑨ 미국, 6G 주도권 확보 위한 연구 추진⑩ 미 국방부, 디지털 트윈 기술 도입 확대※ 참고문헌\n"
     ]
    }
   ],
   "source": [
    "# 길이가 10 이하인 문서 필터링\n",
    "filtered_chunks = [chunk for chunk in chunks if len(chunk.page_content) > 10]\n",
    "print(f\"필터링 전 청크 수: {len(chunks)}\")\n",
    "print(f\"필터링 후 청크 수: {len(filtered_chunks)}\")\n",
    "\n",
    "# 필터링된 청크가 있으면 제거된 내용 샘플 출력\n",
    "if len(chunks) != len(filtered_chunks):\n",
    "    removed = [chunk for chunk in chunks if len(chunk.page_content) <= 10]\n",
    "    print(f\"제거된 청크 샘플 ({len(removed)}개): {removed}\")\n",
    "    print('--')\n",
    "\n",
    "chunks = filtered_chunks\n",
    "print(f\"첫 번째 청크 샘플: {chunks[0].page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ad19b7e-b73b-4f7f-b959-b562fda3bb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1834/1297578870.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "# 임베딩 모델 설정 (BAAI/bge-m3 사용, GPU 사용)\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-m3\",\n",
    "    model_kwargs={'device': 'cuda'} # GPU 사용\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "546b83fe-8969-4c1b-be31-34e1780f048d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "벡터 DB가 생성되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 벡터 DB 생성 (FAISS GPU 버전 사용)\n",
    "vectorstore = FAISS.from_documents(chunks, embeddings)\n",
    "print(f\"벡터 DB가 생성되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e58f780-2b49-4be5-ad6e-f19a29972f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색된 문서 수: 3\n",
      "첫 번째 검색 결과: 9 \n",
      "Ⅰ. ICT 국가 산업 현황 3.ICT 주요정책  ① 국가 스펙트럼 전략(National Spectrum Strategy)\n",
      " 미국 신규 주파수 공급 전략• 2023년 11월 조 바이든(Joe Biden) 행정부는 2,700MHz 이상의 신규 주파수 공급 전략인 ‘국가 스펙트럼 전략(National Spectrum Strategy)’을 발표함. 또 명확\n"
     ]
    }
   ],
   "source": [
    "# 검색 테스트\n",
    "query = \"미국의 ICT 정책의 주요 내용은 무엇인가요?\"\n",
    "docs = vectorstore.similarity_search(query, k=3)\n",
    "print(f\"검색된 문서 수: {len(docs)}\")\n",
    "print(f\"첫 번째 검색 결과: {docs[0].page_content[:200]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fefbcb2-d048-4418-a2fb-6e6b0347eeab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 03-29 00:44:26 [config.py:2614] Casting torch.float16 to torch.bfloat16.\n",
      "INFO 03-29 00:44:26 [config.py:585] This model supports multiple tasks: {'embed', 'reward', 'generate', 'score', 'classify'}. Defaulting to 'generate'.\n",
      "INFO 03-29 00:44:26 [config.py:1697] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "INFO 03-29 00:44:31 [__init__.py:239] Automatically detected platform cuda.\n",
      "INFO 03-29 00:44:32 [core.py:54] Initializing a V1 LLM engine (v0.8.2) with config: model='iamjoon/llama-3-8b-rag-ko-checkpoint-285', speculative_config=None, tokenizer='iamjoon/llama-3-8b-rag-ko-checkpoint-285', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=iamjoon/llama-3-8b-rag-ko-checkpoint-285, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":3,\"custom_ops\":[\"none\"],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\"],\"use_inductor\":true,\"compile_sizes\":[],\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":512}\n",
      "WARNING 03-29 00:44:33 [utils.py:2321] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7e89c864d4b0>\n",
      "INFO 03-29 00:44:33 [parallel_state.py:954] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0\n",
      "INFO 03-29 00:44:33 [cuda.py:220] Using Flash Attention backend on V1 engine.\n",
      "INFO 03-29 00:44:33 [gpu_model_runner.py:1174] Starting to load model iamjoon/llama-3-8b-rag-ko-checkpoint-285...\n",
      "WARNING 03-29 00:44:34 [topk_topp_sampler.py:63] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "INFO 03-29 00:44:34 [weight_utils.py:265] Using model weights format ['*.safetensors']\n",
      "INFO 03-29 00:44:35 [weight_utils.py:281] Time spent downloading weights for iamjoon/llama-3-8b-rag-ko-checkpoint-285: 0.694013 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.33it/s]\n",
      "Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:11<00:13,  6.61s/it]\n",
      "Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:22<00:08,  8.80s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:32<00:00,  9.12s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:32<00:00,  8.12s/it]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 03-29 00:45:07 [loader.py:447] Loading weights took 32.65 seconds\n",
      "INFO 03-29 00:45:08 [gpu_model_runner.py:1186] Model loading took 14.9596 GB and 33.986937 seconds\n",
      "INFO 03-29 00:45:14 [backends.py:415] Using cache directory: /root/.cache/vllm/torch_compile_cache/fe41fc8ecb/rank_0_0 for vLLM's torch.compile\n",
      "INFO 03-29 00:45:14 [backends.py:425] Dynamo bytecode transform time: 6.36 s\n",
      "INFO 03-29 00:45:17 [backends.py:132] Cache the graph of shape None for later use\n",
      "INFO 03-29 00:45:40 [backends.py:144] Compiling a graph for general shape takes 25.36 s\n",
      "INFO 03-29 00:45:53 [monitor.py:33] torch.compile takes 31.72 s in total\n",
      "INFO 03-29 00:45:53 [kv_cache_utils.py:566] GPU KV cache size: 387,520 tokens\n",
      "INFO 03-29 00:45:53 [kv_cache_utils.py:569] Maximum concurrency for 8,192 tokens per request: 47.30x\n",
      "INFO 03-29 00:46:15 [gpu_model_runner.py:1534] Graph capturing finished in 22 secs, took 0.52 GiB\n",
      "INFO 03-29 00:46:15 [core.py:151] init engine (profile, create kv cache, warmup model) took 67.84 seconds\n"
     ]
    }
   ],
   "source": [
    "# 원본 VLLM 라이브러리 직접 사용\n",
    "# VLLM 모델 설정\n",
    "vllm_model = LLM(\n",
    "    model=\"iamjoon/llama-3-8b-rag-ko-checkpoint-285\",\n",
    "    dtype=\"bfloat16\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e39be47b-696b-41aa-b35e-05043c8fcabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성 파라미터 설정\n",
    "sampling_params = SamplingParams(\n",
    "    temperature=0,\n",
    "    max_tokens=1024,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cbb6481-436e-4f21-92e4-13f18210d06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델의 기본 chat template 확인: {% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n",
      "\n",
      "'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{{ '<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "' }}\n"
     ]
    }
   ],
   "source": [
    "# 토크나이저 로드\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"iamjoon/llama-3-8b-rag-ko-checkpoint-285\")\n",
    "print(f\"모델의 기본 chat template 확인: {tokenizer.chat_template}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6211a4ee-0aa8-483e-9654-f00d946b7d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "apply_chat_template 예시:\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "당신은 도움이 되는 AI 어시스턴트입니다.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "안녕하세요, 도와주세요.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# apply_chat_template 예시 출력\n",
    "example_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"당신은 도움이 되는 AI 어시스턴트입니다.\"},\n",
    "    {\"role\": \"user\", \"content\": \"안녕하세요, 도와주세요.\"}\n",
    "]\n",
    "formatted_example = tokenizer.apply_chat_template(\n",
    "    example_messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "print(\"\\napply_chat_template 예시:\")\n",
    "print(formatted_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d417280b-52bc-443f-9aa1-c6f6dcd6a1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG 프롬프트 템플릿 정의\n",
    "system_message = \"\"\"당신은 검색 결과를 바탕으로 질문에 답변해야 합니다.\n",
    "\n",
    "다음의 지시사항을 따르십시오.\n",
    "1. 질문과 검색 결과를 바탕으로 답변하십시오.\n",
    "2. 검색 결과에 없는 내용을 답변하려고 하지 마십시오.\n",
    "3. 질문에 대한 답이 검색 결과에 없다면 검색 결과에는 \"해당 질문~에 대한 내용이 없습니다.\" 라고 답변하십시오.\n",
    "4. 답변할 때 특정 문서를 참고하여 문장 또는 문단을 작성했다면 뒤에 출처는 이중 리스트로 해당 문서 번호를 남기십시오. 예를 들어서 특정 문장이나 문단을 1번 문서에서 인용했다면 뒤에 [[ref1]]이라고 기재하십시오.\n",
    "5. 예를 들어서 특정 문장이나 문단을 1번 문서와 5번 문서에서 동시에 인용했다면 뒤에 [[ref1]], [[ref5]]이라고 기재하십시오.\n",
    "6. 최대한 다수의 문서를 인용하여 답변하십시오.\n",
    "\n",
    "검색 결과:\n",
    "-----\n",
    "{search_result}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2b8b53b-5e41-4e21-a0c8-ffe80c190c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색 결과 포맷팅 함수\n",
    "def format_docs(docs):\n",
    "    formatted_results = []\n",
    "    for i, doc in enumerate(docs):\n",
    "        formatted_results.append(f\"문서{i+1}: {doc.page_content}\")\n",
    "    return \"\\n-----\\n\".join(formatted_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5fe312f-c580-4c73-ad23-eddd7fd5b5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본 VLLM을 사용한 RAG 함수 구현\n",
    "def generate_rag_response(question, retriever, tokenizer, vllm_model, sampling_params):\n",
    "    \"\"\"\n",
    "    검색 결과와 질문을 기반으로 RAG 응답을 생성하는 함수\n",
    "    \"\"\"\n",
    "    # 검색 수행\n",
    "    retrieved_docs = retriever.invoke(question)\n",
    "    \n",
    "    # 검색 결과 포맷팅\n",
    "    formatted_results = format_docs(retrieved_docs)\n",
    "    \n",
    "    # 메시지 준비\n",
    "    formatted_system = system_message.format(search_result=formatted_results)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": formatted_system},\n",
    "        {\"role\": \"user\", \"content\": question}\n",
    "    ]\n",
    "    \n",
    "    # 토크나이저로 프롬프트 포맷팅\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    \n",
    "    # VLLM으로 생성\n",
    "    outputs = vllm_model.generate([prompt], sampling_params)\n",
    "    \n",
    "    # 응답 추출 및 반환\n",
    "    response = outputs[0].outputs[0].text\n",
    "    return response, formatted_results, retrieved_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9ff2c6-fee5-40c2-9f20-2b1889891266",
   "metadata": {},
   "source": [
    "## 답변 순서 이해하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c50c73f-10bc-4154-bfc3-cee52944fb22",
   "metadata": {},
   "source": [
    "### 질문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c6b596a9-c40d-4eb0-8c69-fcb0cf1ff0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문: 미국의 ICT 정책 중 AI 관련 주요 내용은 무엇인가?\n"
     ]
    }
   ],
   "source": [
    "# 원본 VLLM을 사용한 RAG 실행 예시\n",
    "question = \"미국의 ICT 정책 중 AI 관련 주요 내용은 무엇인가?\"\n",
    "print(\"질문:\", question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe82e20-0512-49d8-a67b-dd72cc987912",
   "metadata": {},
   "source": [
    "### 검색기 설정 및 검색 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4bd506b3-f73d-4719-a041-9aa22bda207b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색기 설정\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "83bbbfe1-f038-4ac9-b72c-4813b402d297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색된 문서 수: 3\n"
     ]
    }
   ],
   "source": [
    "# 1. 검색 수행\n",
    "retrieved_docs = retriever.invoke(question)\n",
    "print(f\"검색된 문서 수: {len(retrieved_docs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed53d7f-a064-4191-a093-d7a05d01469b",
   "metadata": {},
   "source": [
    "### 포맷팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f72396f4-555c-44cc-938e-f9866694d51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "검색 결과 (포맷팅):\n",
      "문서1: 12 \n",
      "Ⅰ. ICT 국가 산업 현황 4.ICT 주요법령 및 규제  ① AI 행정 명령\n",
      " AI 위험 관리를 위한 행정 명령• 2023년 11월 미국 정부는 AI 관련 위험을 관리하기 위한 ‘안전하고 신뢰할 수 있는 AI의 개발 및 활용에 관한 행정명령’을 발표함[표 7] AI 행정명령 주요 내용구분 주요 내용\n",
      "AI 안전 및 보안에 대한 새로운 표준 수립\n",
      "‣ 국방물자생산법에 따라 국가 안보, 경제안보, 공중보건 및 안전에 위험을 초래할 수 있는 기반 모델 개발 기업은 AI 시스템 안전 테스트 결과와 기타 중요한 정보를 미국 정부에 공유‣  AI 시스템의 안전성, 보안, 신뢰성을 확인하는 데 도움이 되는 표준, 도구, 테스트 개발‣ 생물학적 합성 스크리닝에 대한 강력한 기준 개발‣ AI가 생성한 콘텐츠를 탐지하고 공식 콘텐츠를 인증하기 위한 표준과 모범사례를 확립하여, AI를 이용한 사기 및 속임수로부터 국민을 보호‣ 중요한 소프트웨어의 취약점을 찾아 수정할 수 있는 AI 툴 개발을 위한 프로그램 수립‣ AI와 보안에 대한 추가 조치를 지시하는 국가안보각서 개발\n",
      "미국인의 개인정보 보호‣ 개인정보보호 기술의 개발과 활용을 가속화 하기 위한 연방정부의 지원을 우선시‣ 암호화 도구 등 개인정보보호 연구 및 기술 강화‣ 기관이 상업적 용도의 정보 수집 및 이용방법 평가, AI위험 고려 제고 위한 개인정보 지침 강화‣ 연방기관이 개인정보보호 기술의 효과를 평가할 수 있는 지침 개발형평성 및 시민권 증진‣ AI 알고리즘이 처벌을 유도하지 않도록 연방급여 프로그램, 연방 계약자에게 명확한 지침을 제공‣ AI와 관련된 민권 침해조사 및 모범사례 교육 등을 통해 알고리즘의 차별 해소‣ 범죄 예측, 포렌식, 위험성 평가 등 AI 사용 모범사례를 개발, 형사 사법제도 전반의 공정성 보장소비자, 환자, 학생을 위한 지원‣ 의료 분야에서 AI의 책임감 있는 사용 촉진, AI 관련 의료 분야 위험 보고 체계 수립‣ AI 지원 교육 도구 배포 지원\n",
      "-----\n",
      "문서2: 10 \n",
      "Ⅰ. ICT 국가 산업 현황 3.ICT 주요정책  ② AI 안전 서약(Summit on AI Safety)\n",
      " AI 기업의 안전한 연구개발을 위한 서약 • 2023년 7월, 조 바이든(Joe Biden) 대통령은 AI 기술을 개발하는 주요 기업이 새로운 기술과 시스템을 설계･공유･테스트하는 연구개발 과정에 필요한 3가지 원칙과 8가지 세부 조항으로 이루어진 ‘AI 안전 서약(Summit on AI Safety)’을 발표함• AI 안전 서약은 ▲안전 ▲보안 ▲신뢰 등 3가지 원칙을 기반으로 책임감 있는 AI(Responsible AI) 개발을 추진하는 것을 목적으로 함• 오픈AI(OpenAI), 구글(Google), 마이크로소프트(Microsoft), 메타(Meta), 아마존(Amazon), 앤트로픽(Anthropic), 인플렉션AI(InflectionAI) 등 대형언어모델(LLM)을 보유한 주요 기업 7곳이 AI 안전 서약에 동의함• 미국 행정부는 자국에서 AI 안전 서약 의제를 진전시키고, 동맹국 및 파트너와 협력하여 AI 개발 및 사용을 관리하기 위한 국제 프레임워크를 구축할 예정임. 백악관은 보도자료를 통해 한국, 호주, 브라질, 캐나다, 칠레, 프랑스, ​​독일, 인도, 유럽연합(EU) 등 20개국을 언급함[표 6] AI 안전 서약 3가지 원칙원칙 세부 조항출시 전 제품 안전성 보장‣ 기업은 AI 시스템 출시 전에 내·외부 보안 테스트 약속‣ 기업은 AI 위험 관리에 관한 정보를 업계 전반, 정부, 시민 사회, 학계와 공유하기 위해 최선을 다할 것 약속\n",
      "보안을 최우선으로 하는 시스템 구축‣ 회사는 독점·미공개 모델 가중치 보호를 위해 사이버보안 및 내부 위협 보호 장치에 투자하기로 약속‣ 기업은 AI 시스템의 취약점을 제3자가 쉽게 발견하고 보고할 수 있도록 전념\n",
      "대중의 신뢰 획득\n",
      "-----\n",
      "문서3: Ⅰ ICT국가산업현황  4(*) SUMMARY1. 국가 개황2. ICT 정부기구3. ICT 주요정책4. ICT 주요법령및규제5. ICT 주요기업6. 한국 협력 및 국내기업 진출사례Ⅱ ICT이슈Top 10  16(*) SUMMARY① 미국 빅테크 기업, 인공지능 챗봇 개발에 주력② 미국, 일본과 양자컴퓨팅 개발 협력③ 미국, 우주 클라우드 컴퓨팅 시장 주도④ 미국, 드론 배송 도입 활발⑤ 미국, 긍정적인 의료 AI 인식 바탕으로 연구 활발⑥ 미국, 반도체 산업 활성화에 박차⑦ 미국, 기술 교류를 위한 국가 간 협력 활발⑧ 미국, 사이버 보안 대응 강화⑨ 미국, 6G 주도권 확보 위한 연구 추진⑩ 미 국방부, 디지털 트윈 기술 도입 확대※ 참고문헌\n"
     ]
    }
   ],
   "source": [
    "# 2. 검색 결과 포맷팅\n",
    "formatted_results = format_docs(retrieved_docs)\n",
    "print(\"\\n검색 결과 (포맷팅):\")\n",
    "print(formatted_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c9be39-bf1f-4be5-a289-ee112db6da85",
   "metadata": {},
   "source": [
    "### 메시지 포맷팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dc4d3104-a66b-4dbb-8795-6196c8b821c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "메시지 형식:\n",
      "System: 당신은 검색 결과를 바탕으로 질문에 답변해야 합니다.\n",
      "\n",
      "다음의 지시사항을 따르십시오.\n",
      "1. 질문과 검색 결과를 바탕으로 답변하십시오.\n",
      "2. 검색 결과에 없는 내용을 답변하려고 하지 마십시오.\n",
      "3. 질문에 대한 답이 검색 결과에 없다면 검색 결과에는 \"해당 질문~에 대한 내용이 없습니다.\" 라고 답변하십시오.\n",
      "4. 답변할 때 특정 문서를 참고하여 문장 또는 문단을 작성했다면 뒤에 출처는 이중 리스트로 해당 문서 번호를 남기십시오. 예를 들어서 특정 문장이나 문단을 1번 문서에서 인용했다면 뒤에 [[ref1]]이라고 기재하십시오.\n",
      "5. 예를 들어서 특정 문장이나 문단을 1번 문서와 5번 문서에서 동시에 인용했다면 뒤에 [[ref1]], [[ref5]]이라고 기재하십시오.\n",
      "6. 최대한 다수의 문서를 인용하여 답변하십시오.\n",
      "\n",
      "검색 결과:\n",
      "-----\n",
      "문서1: 12 \n",
      "Ⅰ. ICT 국가 산업 현황 4.ICT 주요법령 및 규제  ① AI 행정 명령\n",
      " AI 위험 관리를 위한 행정 명령• 2023년 11월 미국 정부는 AI 관련 위험을 관리하기 위한 ‘안전하고 신뢰할 수 있는 AI의 개발 및 활용에 관한 행정명령’을 발표함[표 7] AI 행정명령 주요 내용구분 주요 내용\n",
      "AI 안전 및 보안에 대한 새로운 표준 수립\n",
      "‣ 국방물자생산법에 따라 국가 안보, 경제안보, 공중보건 및 안전에 위험을 초래할 수 있는 기반 모델 개발 기업은 AI 시스템 안전 테스트 결과와 기타 중요한 정보를 미국 정부에 공유‣  AI 시스템의 안전성, 보안, 신뢰성을 확인하는 데 도움이 되는 표준, 도구, 테스트 개발‣ 생물학적 합성 스크리닝에 대한 강력한 기준 개발‣ AI가 생성한 콘텐츠를 탐지하고 공식 콘텐츠를 인증하기 위한 표준과 모범사례를 확립하여, AI를 이용한 사기 및 속임수로부터 국민을 보호‣ 중요한 소프트웨어의 취약점을 찾아 수정할 수 있는 AI 툴 개발을 위한 프로그램 수립‣ AI와 보안에 대한 추가 조치를 지시하는 국가안보각서 개발\n",
      "미국인의 개인정보 보호‣ 개인정보보호 기술의 개발과 활용을 가속화 하기 위한 연방정부의 지원을 우선시‣ 암호화 도구 등 개인정보보호 연구 및 기술 강화‣ 기관이 상업적 용도의 정보 수집 및 이용방법 평가, AI위험 고려 제고 위한 개인정보 지침 강화‣ 연방기관이 개인정보보호 기술의 효과를 평가할 수 있는 지침 개발형평성 및 시민권 증진‣ AI 알고리즘이 처벌을 유도하지 않도록 연방급여 프로그램, 연방 계약자에게 명확한 지침을 제공‣ AI와 관련된 민권 침해조사 및 모범사례 교육 등을 통해 알고리즘의 차별 해소‣ 범죄 예측, 포렌식, 위험성 평가 등 AI 사용 모범사례를 개발, 형사 사법제도 전반의 공정성 보장소비자, 환자, 학생을 위한 지원‣ 의료 분야에서 AI의 책임감 있는 사용 촉진, AI 관련 의료 분야 위험 보고 체계 수립‣ AI 지원 교육 도구 배포 지원\n",
      "-----\n",
      "문서2: 10 \n",
      "Ⅰ. ICT 국가 산업 현황 3.ICT 주요정책  ② AI 안전 서약(Summit on AI Safety)\n",
      " AI 기업의 안전한 연구개발을 위한 서약 • 2023년 7월, 조 바이든(Joe Biden) 대통령은 AI 기술을 개발하는 주요 기업이 새로운 기술과 시스템을 설계･공유･테스트하는 연구개발 과정에 필요한 3가지 원칙과 8가지 세부 조항으로 이루어진 ‘AI 안전 서약(Summit on AI Safety)’을 발표함• AI 안전 서약은 ▲안전 ▲보안 ▲신뢰 등 3가지 원칙을 기반으로 책임감 있는 AI(Responsible AI) 개발을 추진하는 것을 목적으로 함• 오픈AI(OpenAI), 구글(Google), 마이크로소프트(Microsoft), 메타(Meta), 아마존(Amazon), 앤트로픽(Anthropic), 인플렉션AI(InflectionAI) 등 대형언어모델(LLM)을 보유한 주요 기업 7곳이 AI 안전 서약에 동의함• 미국 행정부는 자국에서 AI 안전 서약 의제를 진전시키고, 동맹국 및 파트너와 협력하여 AI 개발 및 사용을 관리하기 위한 국제 프레임워크를 구축할 예정임. 백악관은 보도자료를 통해 한국, 호주, 브라질, 캐나다, 칠레, 프랑스, ​​독일, 인도, 유럽연합(EU) 등 20개국을 언급함[표 6] AI 안전 서약 3가지 원칙원칙 세부 조항출시 전 제품 안전성 보장‣ 기업은 AI 시스템 출시 전에 내·외부 보안 테스트 약속‣ 기업은 AI 위험 관리에 관한 정보를 업계 전반, 정부, 시민 사회, 학계와 공유하기 위해 최선을 다할 것 약속\n",
      "보안을 최우선으로 하는 시스템 구축‣ 회사는 독점·미공개 모델 가중치 보호를 위해 사이버보안 및 내부 위협 보호 장치에 투자하기로 약속‣ 기업은 AI 시스템의 취약점을 제3자가 쉽게 발견하고 보고할 수 있도록 전념\n",
      "대중의 신뢰 획득\n",
      "-----\n",
      "문서3: Ⅰ ICT국가산업현황  4(*) SUMMARY1. 국가 개황2. ICT 정부기구3. ICT 주요정책4. ICT 주요법령및규제5. ICT 주요기업6. 한국 협력 및 국내기업 진출사례Ⅱ ICT이슈Top 10  16(*) SUMMARY① 미국 빅테크 기업, 인공지능 챗봇 개발에 주력② 미국, 일본과 양자컴퓨팅 개발 협력③ 미국, 우주 클라우드 컴퓨팅 시장 주도④ 미국, 드론 배송 도입 활발⑤ 미국, 긍정적인 의료 AI 인식 바탕으로 연구 활발⑥ 미국, 반도체 산업 활성화에 박차⑦ 미국, 기술 교류를 위한 국가 간 협력 활발⑧ 미국, 사이버 보안 대응 강화⑨ 미국, 6G 주도권 확보 위한 연구 추진⑩ 미 국방부, 디지털 트윈 기술 도입 확대※ 참고문헌\n",
      "User: 미국의 ICT 정책 중 AI 관련 주요 내용은 무엇인가?\n"
     ]
    }
   ],
   "source": [
    "# 3. 메시지 준비\n",
    "formatted_system = system_message.format(search_result=formatted_results)\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": formatted_system},\n",
    "    {\"role\": \"user\", \"content\": question}\n",
    "]\n",
    "print(\"\\n메시지 형식:\")\n",
    "print(f\"System: {messages[0]['content']}\")\n",
    "print(f\"User: {messages[1]['content']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488d2e0d-e8dd-49b1-8896-137bf253f00f",
   "metadata": {},
   "source": [
    "### 챗 템플릿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "52c9e8cf-5d57-4c1f-929a-82d056685047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "최종 프롬프트:\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "당신은 검색 결과를 바탕으로 질문에 답변해야 합니다.\n",
      "\n",
      "다음의 지시사항을 따르십시오.\n",
      "1. 질문과 검색 결과를 바탕으로 답변하십시오.\n",
      "2. 검색 결과에 없는 내용을 답변하려고 하지 마십시오.\n",
      "3. 질문에 대한 답이 검색 결과에 없다면 검색 결과에는 \"해당 질문~에 대한 내용이 없습니다.\" 라고 답변하십시오.\n",
      "4. 답변할 때 특정 문서를 참고하여 문장 또는 문단을 작성했다면 뒤에 출처는 이중 리스트로 해당 문서 번호를 남기십시오. 예를 들어서 특정 문장이나 문단을 1번 문서에서 인용했다면 뒤에 [[ref1]]이라고 기재하십시오.\n",
      "5. 예를 들어서 특정 문장이나 문단을 1번 문서와 5번 문서에서 동시에 인용했다면 뒤에 [[ref1]], [[ref5]]이라고 기재하십시오.\n",
      "6. 최대한 다수의 문서를 인용하여 답변하십시오.\n",
      "\n",
      "검색 결과:\n",
      "-----\n",
      "문서1: 12 \n",
      "Ⅰ. ICT 국가 산업 현황 4.ICT 주요법령 및 규제  ① AI 행정 명령\n",
      " AI 위험 관리를 위한 행정 명령• 2023년 11월 미국 정부는 AI 관련 위험을 관리하기 위한 ‘안전하고 신뢰할 수 있는 AI의 개발 및 활용에 관한 행정명령’을 발표함[표 7] AI 행정명령 주요 내용구분 주요 내용\n",
      "AI 안전 및 보안에 대한 새로운 표준 수립\n",
      "‣ 국방물자생산법에 따라 국가 안보, 경제안보, 공중보건 및 안전에 위험을 초래할 수 있는 기반 모델 개발 기업은 AI 시스템 안전 테스트 결과와 기타 중요한 정보를 미국 정부에 공유‣  AI 시스템의 안전성, 보안, 신뢰성을 확인하는 데 도움이 되는 표준, 도구, 테스트 개발‣ 생물학적 합성 스크리닝에 대한 강력한 기준 개발‣ AI가 생성한 콘텐츠를 탐지하고 공식 콘텐츠를 인증하기 위한 표준과 모범사례를 확립하여, AI를 이용한 사기 및 속임수로부터 국민을 보호‣ 중요한 소프트웨어의 취약점을 찾아 수정할 수 있는 AI 툴 개발을 위한 프로그램 수립‣ AI와 보안에 대한 추가 조치를 지시하는 국가안보각서 개발\n",
      "미국인의 개인정보 보호‣ 개인정보보호 기술의 개발과 활용을 가속화 하기 위한 연방정부의 지원을 우선시‣ 암호화 도구 등 개인정보보호 연구 및 기술 강화‣ 기관이 상업적 용도의 정보 수집 및 이용방법 평가, AI위험 고려 제고 위한 개인정보 지침 강화‣ 연방기관이 개인정보보호 기술의 효과를 평가할 수 있는 지침 개발형평성 및 시민권 증진‣ AI 알고리즘이 처벌을 유도하지 않도록 연방급여 프로그램, 연방 계약자에게 명확한 지침을 제공‣ AI와 관련된 민권 침해조사 및 모범사례 교육 등을 통해 알고리즘의 차별 해소‣ 범죄 예측, 포렌식, 위험성 평가 등 AI 사용 모범사례를 개발, 형사 사법제도 전반의 공정성 보장소비자, 환자, 학생을 위한 지원‣ 의료 분야에서 AI의 책임감 있는 사용 촉진, AI 관련 의료 분야 위험 보고 체계 수립‣ AI 지원 교육 도구 배포 지원\n",
      "-----\n",
      "문서2: 10 \n",
      "Ⅰ. ICT 국가 산업 현황 3.ICT 주요정책  ② AI 안전 서약(Summit on AI Safety)\n",
      " AI 기업의 안전한 연구개발을 위한 서약 • 2023년 7월, 조 바이든(Joe Biden) 대통령은 AI 기술을 개발하는 주요 기업이 새로운 기술과 시스템을 설계･공유･테스트하는 연구개발 과정에 필요한 3가지 원칙과 8가지 세부 조항으로 이루어진 ‘AI 안전 서약(Summit on AI Safety)’을 발표함• AI 안전 서약은 ▲안전 ▲보안 ▲신뢰 등 3가지 원칙을 기반으로 책임감 있는 AI(Responsible AI) 개발을 추진하는 것을 목적으로 함• 오픈AI(OpenAI), 구글(Google), 마이크로소프트(Microsoft), 메타(Meta), 아마존(Amazon), 앤트로픽(Anthropic), 인플렉션AI(InflectionAI) 등 대형언어모델(LLM)을 보유한 주요 기업 7곳이 AI 안전 서약에 동의함• 미국 행정부는 자국에서 AI 안전 서약 의제를 진전시키고, 동맹국 및 파트너와 협력하여 AI 개발 및 사용을 관리하기 위한 국제 프레임워크를 구축할 예정임. 백악관은 보도자료를 통해 한국, 호주, 브라질, 캐나다, 칠레, 프랑스, ​​독일, 인도, 유럽연합(EU) 등 20개국을 언급함[표 6] AI 안전 서약 3가지 원칙원칙 세부 조항출시 전 제품 안전성 보장‣ 기업은 AI 시스템 출시 전에 내·외부 보안 테스트 약속‣ 기업은 AI 위험 관리에 관한 정보를 업계 전반, 정부, 시민 사회, 학계와 공유하기 위해 최선을 다할 것 약속\n",
      "보안을 최우선으로 하는 시스템 구축‣ 회사는 독점·미공개 모델 가중치 보호를 위해 사이버보안 및 내부 위협 보호 장치에 투자하기로 약속‣ 기업은 AI 시스템의 취약점을 제3자가 쉽게 발견하고 보고할 수 있도록 전념\n",
      "대중의 신뢰 획득\n",
      "-----\n",
      "문서3: Ⅰ ICT국가산업현황  4(*) SUMMARY1. 국가 개황2. ICT 정부기구3. ICT 주요정책4. ICT 주요법령및규제5. ICT 주요기업6. 한국 협력 및 국내기업 진출사례Ⅱ ICT이슈Top 10  16(*) SUMMARY① 미국 빅테크 기업, 인공지능 챗봇 개발에 주력② 미국, 일본과 양자컴퓨팅 개발 협력③ 미국, 우주 클라우드 컴퓨팅 시장 주도④ 미국, 드론 배송 도입 활발⑤ 미국, 긍정적인 의료 AI 인식 바탕으로 연구 활발⑥ 미국, 반도체 산업 활성화에 박차⑦ 미국, 기술 교류를 위한 국가 간 협력 활발⑧ 미국, 사이버 보안 대응 강화⑨ 미국, 6G 주도권 확보 위한 연구 추진⑩ 미 국방부, 디지털 트윈 기술 도입 확대※ 참고문헌<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "미국의 ICT 정책 중 AI 관련 주요 내용은 무엇인가?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. 토크나이저로 프롬프트 포맷팅\n",
    "prompt = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "print(\"\\n최종 프롬프트:\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55c01cc-69b0-4b9f-9c30-07dd967d6549",
   "metadata": {},
   "source": [
    "### vLLM을 이용한 최종 답변"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d9575325-284e-4274-87ad-4035eb2b1775",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:05<00:00,  5.15s/it, est. speed input: 305.82 toks/s, output: 82.82 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "최종 답변:\n",
      "미국의 ICT 정책 중 AI 관련 주요 내용은 다음과 같습니다.\n",
      "\n",
      "1. **AI 행정 명령 (AI Safety and Security Executive Order)**: 2023년 11월, 미국 정부는 AI 관련 위험을 관리하기 위한 행정 명령을 발표했습니다. 이 명령은 AI 시스템의 안전성, 보안, 신뢰성을 확인하는 표준, 도구, 테스트 개발을 포함합니다. 또한, AI가 생성한 콘텐츠를 탐지하고 공식 콘텐츠를 인증하기 위한 표준과 모범사례를 확립하고, 중요한 소프트웨어의 취약점을 찾아 수정할 수 있는 AI 툴 개발을 위한 프로그램을 수립합니다. 이 명령은 국가 안보, 경제안보, 공중보건 및 안전에 위험을 초래할 수 있는 기반 모델 개발 기업이 AI 시스템 안전 테스트 결과와 기타 중요한 정보를 미국 정부에 공유하도록 요구합니다[[ref1]].\n",
      "\n",
      "2. **AI 안전 서약 (Summit on AI Safety)**: 2023년 7월, 조 바이든 대통령은 AI 기술을 개발하는 주요 기업이 새로운 기술과 시스템을 설계, 공유, 테스트하는 연구개발 과정에 필요한 3가지 원칙과 8가지 세부 조항으로 이루어진 AI 안전 서약을 발표했습니다. 이 서약은 안전, 보안, 신뢰 등 3가지 원칙을 기반으로 책임감 있는 AI 개발을 추진하는 것을 목적으로 합니다. 주요 기업 7곳이 이 서약에 동의했으며, 미국 행정부는 자국에서 AI 안전 서약 의제를 진전시키고, 동맹국 및 파트너와 협력하여 AI 개발 및 사용을 관리하기 위한 국제 프레임워크를 구축할 예정입니다[[ref2]].\n",
      "\n",
      "이 두 가지 정책은 AI의 안전성과 보안성을 강화하고, AI의 책임감 있는 개발과 사용을 촉진하는 데 중점을 두고 있습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. VLLM으로 생성\n",
    "outputs = vllm_model.generate([prompt], sampling_params)\n",
    "response = outputs[0].outputs[0].text\n",
    "\n",
    "# 6. 최종 답변 출력\n",
    "print(\"\\n최종 답변:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275ee17a-f5dc-4103-9e9d-0bc2e454601d",
   "metadata": {},
   "source": [
    "### 함수를 사용하여 한 번에 처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "66793ef7-a1e3-48c7-ba50-517f57f927c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "질문: 미국의 디지털 인프라 투자에 대해 설명해주세요.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:06<00:00,  6.60s/it, est. speed input: 287.15 toks/s, output: 81.78 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색된 문서 수: 3\n",
      "\n",
      "검색 결과:\n",
      "문서1: 5 \n",
      "Ⅰ. ICT 국가 산업 현황 1.국가 개황\n",
      " 미국, 글로벌 혁신지수 세계 3위• 미국 인터넷 사용자 비중은 97.1%이며 고정 광대역 가입자 비중은 37.8%임• 미국 글로벌 혁신지수는 세계 3위임. ‘지식 및 기술 생산’이 상대적으로 우위에 있으며, ‘인프라’가 상대적 열위를 보임\n",
      " 미국 경제 성장세 양호, 기준 금리 인하에는 신중 • 미국 상무부는 2023년 4분기 성장률이 3.2%로 집계됐다고 발표함. 이는 고금리 기조를 감안할 때 양호한 편이라는 평가임• 2024년 1월 소비자 물가는 예측치(2.9%)보다 높은 3.1%를 기록하여 연준 고위인사들은 기준금리 인하에 대해 신중한 입장을 표명함[표 1] 미국 ICT 국가 개황구분 기준년도한국 미국\n",
      "일반개황\n",
      "인구 20235,150만 5,000명3억 3,669만 명면적(1,000ha)202310,043983,151언어 2023한국어영어, 스페인어종교 2023기독교, 불교 등 개신교, 가톨릭 등정부형태 / 의회제도2023대통령제 / 단원제대통령제 / 양원제\n",
      "경제현황GDP 20231.70조 달러27.97조 달러경제 성장률20231.31%1.5%S&P 신용등급2023AA AA+\n",
      "ICT현황이동전화 가입자 수 2022149명(100명당) 110명(100명당)이동통신 가입자 수 2022120명(100명당) 174명(100명당)유선 브로드밴드 가입자 수 202245명(100명당) 38명(100명당)인터넷 사용자 비중202297%97%\n",
      "글로벌혁신지수\n",
      "총점 (순위) 202358.6 (10)63.5 (3)인적자원 및 연구202366.9 (1) 56.5 (12)인프라202360.6 (11)56.7 (25)지식 및 기술 생산202353.3 (11)63.7 (2)창조적 생산 202358.2 (5) 53.0 (12)출처 : World Bank, IMF, 국제전기통신연합(ITU), 세계지적재산권기구(WIPO)\n",
      "-----\n",
      "문서2: 미국 근로자를 위한 일자리 및 인력 파이프라인 창출\n",
      "‣ 반도체 및 기타 산업에서 양질의 일자리를 창출할 파이프라인 구축을 위해 5개의 인력 허브 초기 세트 발표‣ 최소 50개 이상의 커뮤니티 대학에서 신규 및 확장된 반도체 인력 프로그램 발표‣ 국립과학재단(NSF)은 제조 인력 및 연구자 지원, 커리큘럼 개발에 초점을 맞춘 새로운 계획을 통해 미국 반도체 인력 투자‣ 반도체 기업의 정규직 채용에 지원한 학생 수는 2022~2023년에 79% 증가\n",
      "혁신 투자‣ 상무부는 기타 부처들과 국립 반도체 기술 센터 설립 추진‣ 상무부는 110억 달러 규모의 R&D 자금을 계측 프로그램, 국립 고급 포장 제조 프로그램, 최대 3개의 신규 ‘Manufacturing USA’ 연구소 등 기타 부문에도 투자‣ 국방부는 마이크로전자공학 공용 R&D 프로그램에 대한 솔루션 요청서 발표\n",
      "지역 경제 개발 및 혁신 지원‣ 상무부는 5억 달러 규모의 기술 허브 프로그램 1단계를 위한 자금 조달 기회 발표‣ 낙후 지역 경제발전 및 일자리 창출을 위한 Recompete 프로그램 1단계에 2억 달러 자금 조달 기회 발표‣ 국립과학재단은 기술, 혁신, 파트너십을 위한 새로운 부서 설립무선 혁신 및보안 지원‣ 상무부는 개방적이고 상호 운용 가능한 무선 네트워크 개발 지원을 위해 15억 달러 규모의 공공 무선 공급망 혁신 기금의 첫 번째 보조금 발표 출처 : 미국 백악관\n",
      "-----\n",
      "문서3: 13 \n",
      "Ⅰ. ICT 국가 산업 현황 4.ICT 주요법령 및 규제  ② 반도체 과학법(CHIPS and Science Act)\n",
      " 반도체·전자 기업, $1,660억 규모 투자 유치 • 조 바이든(Joe Biden) 미국 대통령은 2022년 7월 ‘반도체 과학법(CHIPS and Science Act)’을 승인함 • 반도체 과학법은 미국의 경쟁력을 강화하고, 미국의 공급망을 탄력적으로 구축해 국가 안보를 공고히 하며 국가의 주요 기술에 대한 접근을 지원하는 것을 목표로 함. 법률 제정으로 미국 내 반도체 생산 제조사 관련 자본 투자는 25%의 세액 공제 혜택이 제공됨• 미국 백악관은 2023년 8월, 반도체 과학법이 서명된 지 1년 만에 반도체와 전자 관련 기업들이 1,660억 달러(221조6,100억 원)의 투자를 유치했다고 발표함. 바이든 행정부의 집권 이후 기업들은 미국 내 반도체와 전자 분야 투자에 총 2,310억 달러(약 308조 3,850억 원) 이상의 투자를 약속함[표 8] 반도체 과학법 주요 이정표 및 진척 현황주요 이정표 진척 현황 (23년 8월 기준)\n",
      "미국 반도체 제조 지원\n",
      "‣ 상무부는 CHIPS 통과 6개월 만에 해당 법에서 제공하는 390억 달러 반도체 제조 인센티브에 대한 첫 번째 자금 조달 기회 시작‣ 상무부는 42개 주에서 CHIPS 자금 지원에 관심 있는 460개 기업으로부터 소개서 접수‣ 상무부는 CHIPS 인센티브 프로그램 관련 140명 이상의 인력으로 구성된 ‘칩스 포 아메리카(CHIPS for America)’ 팀 구성‣ 재무부는 투자에 대한 25% 세액 공제 관련 지침 제공 위해 규칙 제안 발표국가 안보를 보호하고 동맹국 및 파트너와 협력‣ 국무부는 국제 기술 보안 및 혁신 기금 시행 계획 발표‣ 국방부와 상무부는 CHIPS 투자를 통한 안보 관련 반도체 제조를 위해 협력 확대 협의‣ CHIPS를 시행하면서 상무부는 여러 파트너 및 동맹국과 긴밀한 접촉 유지\n",
      "미국 근로자를 위한 일자리 및 인력 파이프라인 창출\n",
      "===\n",
      "\n",
      "최종 답변:\n",
      "미국의 디지털 인프라 투자에 대한 정보는 여러 출처에서 찾을 수 있습니다. 주요 내용을 요약하면 다음과 같습니다.\n",
      "\n",
      "미국은 디지털 인프라에 상당한 투자를 하고 있습니다. 이는 고속 인터넷 접근성 향상, 5G 무선 네트워크 구축, 그리고 인프라의 안정성과 보안을 강화하는 데 중점을 두고 있습니다.\n",
      "\n",
      "1. **고속 인터넷 접근성 향상**: 미국은 고속 인터넷 접근성을 높이기 위해 다양한 노력을 기울이고 있습니다. 예를 들어, 국립과학재단(National Science Foundation)은 제조 인력 및 연구자 지원, 커리큘럼 개발에 초점을 맞춘 새로운 계획을 통해 반도체 인력 투자를 확대하고 있습니다. 또한, 상무부는 기술 허브 프로그램과 Recompete 프로그램을 통해 낙후 지역의 경제 발전과 일자리 창출을 지원하고 있습니다. 이러한 프로그램들은 고속 인터넷 접근성을 향상시키는 데 중요한 역할을 합니다[[ref2]].\n",
      "\n",
      "2. **5G 무선 네트워크 구축**: 미국은 5G 무선 네트워크의 구축을 통해 디지털 인프라를 강화하고 있습니다. 상무부는 개방적이고 상호 운용 가능한 무선 네트워크 개발을 지원하기 위해 15억 달러 규모의 공공 무선 공급망 혁신 기금을 발표했습니다. 이는 5G 네트워크의 보급을 촉진하고 무선 혁신 및 보안을 지원하는 데 기여합니다[[ref2]].\n",
      "\n",
      "3. **인프라의 안정성과 보안 강화**: 미국은 디지털 인프라의 안정성과 보안을 강화하기 위해 다양한 조치를 취하고 있습니다. 예를 들어, 상무부는 반도체 과학법(CHIPS and Science Act)을 통해 반도체 및 전자 기업에 대한 투자를 유치하고, 반도체 제조 인센티브를 제공하며, 국제 기술 보안 및 혁신 기금을 시행 계획을 발표했습니다. 이는 국가 안보를 보호하고 동맹국 및 파트너와 협력하는 데 중요한 역할을 합니다[[ref3]].\n",
      "\n",
      "이러한 투자들은 미국의 디지털 인프라를 현대화하고, 경제 성장을 촉진하며, 국가 안보를 강화하는 데 기여하고 있습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 다른 질문으로 테스트 - 함수 사용\n",
    "question = \"미국의 디지털 인프라 투자에 대해 설명해주세요.\"\n",
    "print(\"\\n질문:\", question)\n",
    "\n",
    "# 1. 함수 호출하여 RAG 실행\n",
    "response, formatted_results, retrieved_docs = generate_rag_response(\n",
    "    question=question,\n",
    "    retriever=retriever,\n",
    "    tokenizer=tokenizer,\n",
    "    vllm_model=vllm_model,\n",
    "    sampling_params=sampling_params\n",
    ")\n",
    "\n",
    "# 2. 결과 출력\n",
    "print(f\"검색된 문서 수: {len(retrieved_docs)}\")\n",
    "print(\"\\n검색 결과:\")\n",
    "print(formatted_results)\n",
    "print(\"===\")\n",
    "print(\"\\n최종 답변:\")\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
