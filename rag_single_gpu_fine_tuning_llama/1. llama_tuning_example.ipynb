{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3745307-e926-4218-a6fc-9c12175805ac",
   "metadata": {},
   "source": [
    "## 1. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63702f92-6c10-4a90-9cb9-e3e950bfccc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==2.4.0 in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (4.13.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0) (12.8.93)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.0) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.0) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers==4.45.1 in /usr/local/lib/python3.10/dist-packages (4.45.1)\n",
      "Requirement already satisfied: datasets==3.0.1 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
      "Requirement already satisfied: accelerate==0.34.2 in /usr/local/lib/python3.10/dist-packages (0.34.2)\n",
      "Requirement already satisfied: trl==0.11.1 in /usr/local/lib/python3.10/dist-packages (0.11.1)\n",
      "Requirement already satisfied: peft==0.13.0 in /usr/local/lib/python3.10/dist-packages (0.13.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.1) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.1) (0.29.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.1) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.1) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.1) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.1) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.1) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.1) (0.5.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.1) (0.20.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.1) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==3.0.1) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets==3.0.1) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==3.0.1) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets==3.0.1) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets==3.0.1) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets==3.0.1) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==3.0.1) (3.11.14)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.34.2) (5.9.6)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.34.2) (2.4.0)\n",
      "Requirement already satisfied: tyro>=0.5.11 in /usr/local/lib/python3.10/dist-packages (from trl==0.11.1) (0.9.18)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.0.1) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.0.1) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.0.1) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.0.1) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.0.1) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.0.1) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.0.1) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.0.1) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.1) (4.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.1) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.1) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.1) (2022.12.7)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.34.2) (12.8.93)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl==0.11.1) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl==0.11.1) (13.9.4)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl==0.11.1) (1.7.1)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl==0.11.1) (4.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==3.0.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==3.0.1) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==3.0.1) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==3.0.1) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.11.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.11.1) (2.16.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.34.2) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate==0.34.2) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.11.1) (0.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install \"torch==2.4.0\"\n",
    "%pip install \"transformers==4.45.1\" \"datasets==3.0.1\" \"accelerate==0.34.2\" \"trl==0.11.1\" \"peft==0.13.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98eaf62e-8aee-4331-803e-20d92e6cf689",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import LoraConfig\n",
    "from trl import SFTConfig, SFTTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00e07c5-04d3-48fb-8a30-2113838c4384",
   "metadata": {},
   "source": [
    "빠른 학습을 위해 학습 데이터와 테스트 데이터를 2:8 비율로 분할합니다. 이 값을 변경하고자 하는 분은 test_ratio의 값을 변경하세요.\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67d9837a-d604-443d-9afb-7e343d0d1011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af0c6333500d4e90a32b7c9300c4546d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/909 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dd8ffdb205245d49d2d1bb9037a8970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/13.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "483046c87ccc4b7fbc28af12989a13f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1884 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 데이터의 type 분포:\n",
      "no_answer: 404\n",
      "mrc_question_with_1_to_4_negative: 296\n",
      "paraphrased_question: 196\n",
      "mrc_question: 491\n",
      "synthetic_question: 497\n",
      "\n",
      "전체 데이터 분할 결과: Train 380개, Test 1504개\n",
      "\n",
      "학습 데이터의 type 분포:\n",
      "no_answer: 81\n",
      "mrc_question_with_1_to_4_negative: 60\n",
      "paraphrased_question: 40\n",
      "mrc_question: 99\n",
      "synthetic_question: 100\n",
      "\n",
      "테스트 데이터의 type 분포:\n",
      "no_answer: 323\n",
      "mrc_question_with_1_to_4_negative: 236\n",
      "paraphrased_question: 156\n",
      "mrc_question: 392\n",
      "synthetic_question: 397\n"
     ]
    }
   ],
   "source": [
    "# 1. 허깅페이스 허브에서 데이터셋 로드\n",
    "dataset = load_dataset(\"iamjoon/klue-mrc-ko-rag-dataset\", split=\"train\")\n",
    "\n",
    "# 2. system_message 정의\n",
    "system_message = \"\"\"당신은 검색 결과를 바탕으로 질문에 답변해야 합니다.\n",
    "\n",
    "다음의 지시사항을 따르십시오.\n",
    "1. 질문과 검색 결과를 바탕으로 답변하십시오.\n",
    "2. 검색 결과에 없는 내용을 답변하려고 하지 마십시오.\n",
    "3. 질문에 대한 답이 검색 결과에 없다면 검색 결과에는 \"해당 질문~에 대한 내용이 없습니다.\" 라고 답변하십시오.\n",
    "4. 답변할 때 특정 문서를 참고하여 문장 또는 문단을 작성했다면 뒤에 출처는 이중 리스트로 해당 문서 번호를 남기십시오. 예를 들어서 특정 문장이나 문단을 1번 문서에서 인용했다면 뒤에 [[ref1]]이라고 기재하십시오.\n",
    "5. 예를 들어서 특정 문장이나 문단을 1번 문서와 5번 문서에서 동시에 인용했다면 뒤에 [[ref1]], [[ref5]]이라고 기재하십시오.\n",
    "6. 최대한 다수의 문서를 인용하여 답변하십시오.\n",
    "\n",
    "검색 결과:\n",
    "-----\n",
    "{search_result}\"\"\"\n",
    "\n",
    "# 3. 원본 데이터의 type별 분포 출력 \n",
    "print(\"원본 데이터의 type 분포:\")\n",
    "for type_name in set(dataset['type']):\n",
    "    print(f\"{type_name}: {dataset['type'].count(type_name)}\")\n",
    "\n",
    "# 4. train/test 분할 비율 설정 (0.5면 5:5로 분할)\n",
    "test_ratio = 0.8\n",
    "\n",
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "# 5. type별로 순회하면서 train/test 데이터 분할\n",
    "for type_name in set(dataset['type']):\n",
    "    # 현재 type에 해당하는 데이터의 인덱스만 추출\n",
    "    curr_type_data = [i for i in range(len(dataset)) if dataset[i]['type'] == type_name]\n",
    "    \n",
    "    # test_ratio에 따라 test 데이터 개수 계산 \n",
    "    test_size = int(len(curr_type_data) * test_ratio)\n",
    "    \n",
    "    # 현재 type의 데이터를 test_ratio 비율로 분할하여 추가\n",
    "    test_data.extend(curr_type_data[:test_size])\n",
    "    train_data.extend(curr_type_data[test_size:])\n",
    "\n",
    "# 6. OpenAI format으로 데이터 변환을 위한 함수 \n",
    "def format_data(sample):\n",
    "    # 검색 결과를 문서1, 문서2... 형태로 포매팅\n",
    "    search_result = \"\\n-----\\n\".join([f\"문서{idx + 1}: {result}\" for idx, result in enumerate(sample[\"search_result\"])])\n",
    "    \n",
    "    # OpenAI format으로 변환\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_message.format(search_result=search_result),\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": sample[\"question\"],\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": sample[\"answer\"]\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    "\n",
    "# 7. 분할된 데이터를 OpenAI format으로 변환\n",
    "train_dataset = [format_data(dataset[i]) for i in train_data]\n",
    "test_dataset = [format_data(dataset[i]) for i in test_data]\n",
    "\n",
    "# 8. 최종 데이터셋 크기 출력\n",
    "print(f\"\\n전체 데이터 분할 결과: Train {len(train_dataset)}개, Test {len(test_dataset)}개\")\n",
    "\n",
    "# 9. 분할된 데이터의 type별 분포 출력\n",
    "print(\"\\n학습 데이터의 type 분포:\")\n",
    "for type_name in set(dataset['type']):\n",
    "    count = sum(1 for i in train_data if dataset[i]['type'] == type_name)\n",
    "    print(f\"{type_name}: {count}\")\n",
    "\n",
    "print(\"\\n테스트 데이터의 type 분포:\")\n",
    "for type_name in set(dataset['type']):\n",
    "    count = sum(1 for i in test_data if dataset[i]['type'] == type_name)\n",
    "    print(f\"{type_name}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d01634b1-25ad-46ae-9d19-8923fcd3c536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': '당신은 검색 결과를 바탕으로 질문에 답변해야 합니다.\\n\\n다음의 지시사항을 따르십시오.\\n1. 질문과 검색 결과를 바탕으로 답변하십시오.\\n2. 검색 결과에 없는 내용을 답변하려고 하지 마십시오.\\n3. 질문에 대한 답이 검색 결과에 없다면 검색 결과에는 \"해당 질문~에 대한 내용이 없습니다.\" 라고 답변하십시오.\\n4. 답변할 때 특정 문서를 참고하여 문장 또는 문단을 작성했다면 뒤에 출처는 이중 리스트로 해당 문서 번호를 남기십시오. 예를 들어서 특정 문장이나 문단을 1번 문서에서 인용했다면 뒤에 [[ref1]]이라고 기재하십시오.\\n5. 예를 들어서 특정 문장이나 문단을 1번 문서와 5번 문서에서 동시에 인용했다면 뒤에 [[ref1]], [[ref5]]이라고 기재하십시오.\\n6. 최대한 다수의 문서를 인용하여 답변하십시오.\\n\\n검색 결과:\\n-----\\n문서1: 정부가 내용이 분명치 않거나 표현이 어색한 중앙행정기관의 영문 명칭을 일제히 정비해 법제화한다. 국제사회에서 부처 간 교류가 활발해지는 가운데 현 부처 영문 명칭을 외국인들이 이해하기 어렵다는 이유에서다.행정자치부는 “이 같은 내용을 담은 ‘정부조직 영어명칭에 관한 규칙’(예규)을 이르면 이달 중 제정할 계획”이라고 5일 밝혔다. 소속기관의 영문 명칭이 법제화되는 것은 1948년 대한민국 정부가 출범한 이래 처음이다.중앙부처 중 정비 대상 1순위는 기획재정부다. 전문가들은 현 ‘Ministry of Strategy and Finance’인 기재부 영문 명칭에서 ‘Strategy’를 빼야 한다고 지적한다. 국가의 미래 경제전략을 수립하는 부처라는 점을 강조하기 위해 쓰였지만 이를 보고 기재부를 떠올리는 외국인은 거의 없다는 게 전문가들의 지적이다. 행자부의 영문 명칭도 바뀔 전망이다. 현 명칭인 ‘Ministry of Government Administration and Home Affairs’는 정부 조직과 사무를 맡는다는 뜻이지만 한국식 영어표현이라는 게 전문가들의 지적이다. 미 내무부(Department of the Interior)를 벤치마킹해 ‘Ministry of Interior’ 또는 ‘Ministry of Internal Affairs’ 등이 유력하게 검토되고 있다.\\n-----\\n문서2: 조윤선 여성가족부 장관(사진)은 25일 ‘한경 밀레니엄포럼’에서 “여성가족부의 명칭에서 ‘여성’을 빼는 것은 쉽지 않은 문제”라며 “심도 있는 검토가 필요하다”고 밝혔다.조 장관은 “여성가족부 명칭 변경은 지금까지 여성 인권을 위해 노력한 분들을 고려해서라도 쉽지 않은 문제”라고 난색을 표시했다. 그는 이날 포럼에서 “남성과 여성의 동반성장 관점에서 여성가족부 이름을 동반성장부로 바꾸면 많은 국민들이 호응할 것”이라는 윤창현 한국금융연구원장 질문에 대해 이같이 답했다.조 장관은 “현재 정치권에서 현 여성발전기본법을 양성평등기본법으로 개정하는 작업을 추진 중”이라며 “관련법 명칭이 어떻게 발전하느냐에 따라 부처 이름도 연동이 될 수 있다”고 말했다. 정부의 여성정책과 예산 수립의 근거가 되는 여성발전기본법은 1995년 제정돼 이듬해부터 시행됐다. 하지만 이 법은 여성을 둘러싼 시대적 환경과 사회 여건에 적극적으로 대응하지 못한다는 지적을 받으면서 전면 개정 필요성에 대한 목소리가 높아지고 있다. 일각에선 여성만의 권리를 강조할 것이 아니라 여성과 남성을 모두 포함한 ‘양성 평등’이 강조돼야 한다는 지적도 나온다.\\n-----\\n문서3: 청와대가 정부조직법 개정 작업과 관련, △국가안전처 및 행정혁신처 위상 △안전행정부 격하 여부 △경찰청 소속 이전 문제 등을 집중 논의하고 있는 것으로 21일 전해졌다. 박근혜 대통령이 지난 19일 대국민 담화에서 신속한 재난 대응 및 국민 안전 확보를 위해 정부조직법을 개정하겠다고 밝혔는데, 신설되거나 역할이 바뀌는 부처의 지위가 그 시금석이 될 것이라는 게 청와대 관계자의 설명이다. 국무총리 산하에 신설되는 국가안전처는 장관급 기구로 사실상 확정됐다. 청와대는 설명자료를 통해 “국가안전처장을 장관급으로 하고 총리의 명을 받들도록 해 재난 안전에 대한 총리의 컨트롤타워 기능을 강화할 계획”이라고 말했다. 정부 관계자는 “국가안전처는 재난 및 안전과 관련한 컨트롤타워 역할을 해야 하는데, 그 수장이 차관급일 경우 다른 기관의 협조를 구하기 힘들 수도 있다”고 설명했다. 국가안전처와 함께 국무총리 소속으로 만들어지는 행정혁신처도 장관급 기구로 결정될 가능성이 있다. 행정혁신처가 인사와 조직관리 업무를 총괄했던 총무처와 비슷한 역할을 한다는 사실을 감안하면 그 위상도 과거 총무처와 마찬가지로 장관급이어야 한다는 이유에서다.\\n-----\\n문서4: 호조(戶曹)는 고려와 조선의 행정기관이다. 육조의 하나로, 호구, 공납, 부사, 조세 및 국가 재정과 관련된 부분을 담당하였다. 고려시대 성종 이전에는 선관이었고, 성종 이후에 호부로 개칭되었다. 원나라 지배기에는 판도사, 민조, 민부로 명칭을 변경했다가 공민왕 때 다시 호부로 개칭했고 그 뒤 다시 판도사, 민부 등으로 명칭을 변경하다가 공양왕 때 비로소 호조로 개칭된 것이다.\\n\\n대한제국 고종 31년인 1894년에 탁지아문으로 고쳤고 , 이후 탁지부가 되었다. 이후 일제강점기 때는 조선총독부의 재무부와 탁지부로 호조의 기능이 분리되었으며 대한민국 임시정부에서는 재무부와 생계부로 역시 호조의 기능이 분리되었다가 광복 후에는 미군정 재무국으로 그 기능이 합쳐졌고 이후 미군정 재무부를 거쳐서 대한민국 정부 수립 이후에 이승만 정부에서는 재무부가 호조의 기능을 이어받았다. 그러다가 군사정권(박정희-전두환-노태우) 때는 재무부와 경제기획원이 호조의 기능을 분담하면서 이어받았고 김영삼 정부 때는 다시 통합되었다가 김대중 정부 때는 기획예산처와 재정경제부로 다시 분리되면서 호조의 기능을 이어받았다. 현재는 기획재정부가 호조의 기능을 이어받는 형태가 이어지고 있다.\\n\\n고대 주나라에서 대사도(大司徒)로 불렀다하여 옛스럽게 별칭으로 부르기도 하였다. 지관(地官)이라고도 한다.\\n-----\\n문서5: 학명\\n생물의 이름은 나라에 따라서 다를 뿐 아니라 같은 나라 안에서도 지방에 따라 다르다. 이와 같은 지방명은 국한된 지역에서 쓰기에는 편리하지만 생물을 재료로 해서 학술적으로 연구하기에는 이름들이 각각 다르므로 매우 불편하다. 따라서, 국제적으로 통일된 생물명이 필요하게 되어 붙여진 것이 \\'학명\\'이다. 만일 학명이 어떤 특정한 나라의 언어로 표기된다면 그 나라 사람에게는 유리하지만, 그 외의 다른 나라 사람들에게는 매우 불공평하다. 뿐만 아니라 현재 사용되는 모든 언어는 변할 가능성이 많으므로, 이것을 사용한다면 학명도 변화되어 매우 불편할 것이다. 이와 같은 이유로 학명은 현재 사용되지 않는 불변의 라틴어로 표기되고 있다. 한편, 학명은 간결하고 요점을 내포하고 있어, 그것만으로도 식물의 대체적인 모양이나 성질을 상상할 수 있어야 한다. 이러한 목적에 알맞은 것이 현재 쓰이고 있는 \\'이명법\\'이다. 이명법은 린네가 창안한 것으로 생물의 속명과 종명을 나란히 쓰고, 그 다음에 그 학명을 처음 지은 사람의 이름(성)을 붙이는 방법이다.'},\n",
       " {'role': 'user', 'content': '역사적으로 한국의 행정기관 명칭은 어떻게 변화해왔나요?'},\n",
       " {'role': 'assistant',\n",
       "  'content': '한국의 행정기관 명칭은 역사적으로 여러 차례 변화해왔습니다. 고려와 조선 시대에는 호조(戶曹)라는 명칭을 사용했으며, 이는 호구, 공납, 부사, 조세 및 국가 재정과 관련된 업무를 담당하는 기관이었습니다. 고려 성종 이전에는 선관으로 불렸고, 성종 이후에는 호부로 개칭되었습니다. 원나라 지배기에는 판도사, 민조, 민부 등으로 명칭이 변경되었다가 공민왕 때 다시 호부로 개칭되었고, 공양왕 때 비로소 호조로 명칭이 확정되었습니다[[ref4]].\\n\\n대한제국 시기인 1894년에는 호조가 탁지아문으로 개칭되었고, 이후 탁지부로 변경되었습니다. 일제강점기에는 조선총독부의 재무부와 탁지부로 기능이 분리되었으며, 대한민국 임시정부 시기에는 재무부와 생계부로 기능이 분리되었습니다. 광복 후에는 미군정 재무국으로 기능이 합쳐졌고, 대한민국 정부 수립 이후에는 재무부가 호조의 기능을 이어받았습니다. 군사정권 시기에는 재무부와 경제기획원이 호조의 기능을 분담하였고, 김영삼 정부 때는 다시 통합되었다가 김대중 정부 때는 기획예산처와 재정경제부로 분리되었습니다. 현재는 기획재정부가 호조의 기능을 이어받고 있습니다[[ref4]].\\n\\n이와 같이 한국의 행정기관 명칭은 시대와 정치적 상황에 따라 여러 차례 변화해왔으며, 각 시기마다 그 역할과 기능에 맞게 명칭이 조정되었습니다.'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[345][\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "038167a1-0a6f-4b9c-8aa9-e4e753d36076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'datasets.arrow_dataset.Dataset'>\n",
      "<class 'datasets.arrow_dataset.Dataset'>\n"
     ]
    }
   ],
   "source": [
    "# 리스트 형태에서 다시 Dataset 객체로 변경\n",
    "print(type(train_dataset))\n",
    "print(type(test_dataset))\n",
    "train_dataset = Dataset.from_list(train_dataset)\n",
    "test_dataset = Dataset.from_list(test_dataset)\n",
    "print(type(train_dataset))\n",
    "print(type(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7285dd35-4047-415f-95f7-62abec39bfe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'content': '당신은 검색 결과를 바탕으로 질문에 답변해야 합니다.\\n\\n다음의 지시사항을 따르십시오.\\n1. 질문과 검색 결과를 바탕으로 답변하십시오.\\n2. 검색 결과에 없는 내용을 답변하려고 하지 마십시오.\\n3. 질문에 대한 답이 검색 결과에 없다면 검색 결과에는 \"해당 질문~에 대한 내용이 없습니다.\" 라고 답변하십시오.\\n4. 답변할 때 특정 문서를 참고하여 문장 또는 문단을 작성했다면 뒤에 출처는 이중 리스트로 해당 문서 번호를 남기십시오. 예를 들어서 특정 문장이나 문단을 1번 문서에서 인용했다면 뒤에 [[ref1]]이라고 기재하십시오.\\n5. 예를 들어서 특정 문장이나 문단을 1번 문서와 5번 문서에서 동시에 인용했다면 뒤에 [[ref1]], [[ref5]]이라고 기재하십시오.\\n6. 최대한 다수의 문서를 인용하여 답변하십시오.\\n\\n검색 결과:\\n-----\\n문서1: 콘코바르는 결국 죽게 되는데, 그 곡절은 이러하다. 라긴의 왕 메스 게그러의 뇌를 굳힌 겻을 울라의 코날이 전리품으로 가지고 있었는데, 코나크타의 전사 케트 막 마가크가 이를 훔쳐갔다. 그리고 케트는 무릿매로 메스 게그러의 뇌를 던져 콘코바르의 머리를 맞추었고, 메스 게그러의 뇌가 콘코바르의 머리통 깊숙히 박혀 버렸다. 이 일이 일어난 곳은 우르카르(Urchair)의 발러 아흐(Baile Ath), 곧 오늘날의 웨스트미스 주 호르셀리프라고 한다. 콘코바르의 의사들은 이 이물질을 제거할 수 없었고, 상처를 봉합만 한 뒤 왕에게 흥분하지 않으면 생명을 유지할 수 있다고 말했다. 7년이 평화롭게 흘러간 뒤 콘코바르는 그리스도가 죽었다는 소식을 듣게 되어 분노했고, 뇌가 터져 죽었다. 머리가 터진 자리에서 뿜어져나온 피의 세례를 받은 결과 그는 기독교인이 되었고 그 영혼은 천국으로 갔다. 콘코바르의 죽음에 관한 이 기록은 매우 얄팍한 기독교화가 이루어져 있는데, 한편 노르드 신화의 토르가 흐룽그니르와 싸우다 머리에 숫돌이 박힌 이야기와 유사한 점이 있다. 어쩌면 두 이야기는 하나의 기원을 공유하거나 또는 바이킹이 에린에 영향을 미치던 시기(노르드-게일)에 수입된 것일 수도 있다.\\n\\n울라인들은 아직도 코나크타에 망명 중이던 콘코바르의 아들 코르막 콘드 롱가스를 왕으로 추대하기 위해 초빙했는데, 이멘마하로 돌아오는 길에 코르막은 기아스를 어기게 되었고 다 코카(Da Choca) 여관에 묵던 중에 습격당해 피살당했다. 이에 코날 케르나크가 콘코바르의 다른 아들 쿠스라드 멘드 마하(Cúscraid Mend Macha)를 왕으로 추대했다.\\n-----\\n문서2: 케트 막 마가크(Cet mac Mágach)는 아일랜드 신화의 얼스터 대계에 등장하는 인물이다. 코나크타의 전사로, 울라의 코날 케르나크의 적수이다.\\n\\n어떤 전승들에서는 케트가 코날의 어머니 핀드코엠과 남매지간, 코날과는 숙질간이라고도 한다.\\n\\n라긴 사람 막 다 호의 집에서 연회가 벌어졌을 때, 코나크타와 울라의 여러 전사들이 쿠라드미르를 놓고 각자의 업적을 자랑하며 다투었다. 케트는 전사들 각각을 자신이 어떻게 이겼는지 들먹이며 그들 모두의 입을 다물게 만들었다. 케트가 쿠라드미르를 가져가려는 순간 코날 케르나크가 도착했다. 코날은 자신이 케트보다 우위에 있다고 주장했고, 케트는 패배를 인정했다. 그러나 자신의 동생 아늘룬이 있었다면 그가 코날의 우위에 있었을 것이라고 주장했다. 그러자 코날은 방금 잘라온 아늘룬의 머리를 케트에게 던져주는 것으로 응수했다. \\n\\n케트는 울라의 왕 콘코바르 막 네사를 죽였는데, 그 이야기는 이러하다. 코날이 라긴의 왕 메스 게그러를 죽이고 그 뇌를 굳힌 것을 트로피삼아 차고 다녔는데, 케트가 그것을 훔쳐다가 무릿매로 던져 콘코바르의 머리통에 파묻었다. 콘코바르의 의사들은 왕을 죽이지 않는 이상 이 이물질을 빼낼 방법을 찾지 못했다. 그래서 대충 봉합한 뒤 왕에게 지나치게 흥분하지 않는다면 목숨을 부지할 수 있다고 말했다. 7년이 평화롭게 흘러간 끝에 콘코바르는 그리스도가 죽었다는 소식을 듣게 되었다. 그는 분노했고, 그 바람에 뇌가 터져 죽었다.\\n\\n어느 겨울날 케트가 울라로 습격을 나가 울라 남자 스물일곱 명을 죽이고 그 수급들을 베어갔다. 눈이 내렸기에 코날은 케트의 흔적을 추적할 수 있었다. 코날은 케트를 따라잡았지만 그를 대적하기 주저했는데, 전차를 몰던 마부가 그를 겁쟁이라 비난하자 마음을 고쳐먹고 나서게 되었다. 둘이는 한 여울에서 일 대 일 결투를 벌였고, 격렬한 싸움 끝에 코날이 케트를 죽였으며 코날 본인도 빈사상태에 빠졌다.\\n-----\\n문서3: 뉴욕의 광고 회사에서 일하는 테드 크레이머는 능력 있는 일꾼이지만 워커홀릭이어서 가정에는 소홀한 가장이다. 아내 조애나는 테드의 귀가가 늦은 어느 날 갑작스럽게 이유를 밝히지 않고 이혼을 통보한 뒤 집을 나가 버린다. 테드는 애써 한순간의 변덕이고 금방 돌아오겠지 하는 생각은 하지만, 곧 아들 빌리를 돌보면서 서툰 집안일을 해야 할 처지가 된다. 일과 양육을 병행하느라 회사에서의 평판은 나빠지고, 빌리는 계속 해서 이어지는 엄마의 부재 때문에 짜증을 낸다. 다행히도 시간이 지나면서 부자는 둘만의 생활에 적응해 나간다.\\n\\n테드는 아랫집에 사는 이웃이자 조애나와 친했던 마거릿과 친해진다. 마거릿도 테드와 마찬가지로 이혼 후 자식들 혼자 키우고 있었으므로 둘은 서로의 처지에 공감했던 것이다. 하루는 잠시 한눈을 팔던 사이 빌리가 정글짐에서 추락해 머리가 찢어지는 사건이 벌어진다. 위급한 테드는 아들을 안고 먼 거리를 달려 병원에 데려가고, 부성애를 발휘해 아들의 수술을 지켜보며 아들을 안심케 한다. 수술 후 테드는 마거릿을 빌리의 대모로 삼는다.\\n\\n조애나가 떠난 지 15개월 만에 뉴욕에 돌아와 테드와 만난다. 둘은 처음에는 친밀했다. 조애나는 자기가 떠난 것은 아들을 키울 준비를 하기 위해서였으며, 이제 아들의 양육권을 달라고 한다. 그 말을 들은 테드는 크게 화를 내며 자리를 박차고 나선다. 변호사가 고용되고 곧 법정 다툼으로 발전한다. 불행히도 재판을 앞두고 테드가 직장에서 해고되는 바람에 양육권 재판에 불리하게 변하자, 테드는 연봉을 크게 낮춰가면서까지 새 직장을 구한다.\\n\\n조애나는 재판에서 결혼 생활은 원만하지 않았고 테드의 일 중독과 편견 때문에 자신은 패션디자이너로서의 꿈을 접어야 했다고 증언한다. 지금은 직업을 얻어 테드보다도 더 연봉이 높고 가정에 소홀했던 테드보다 자신이 빌리를 키우기에 더 적합하다고 말한다. 테드는 조애나의 고백에 마음이 움직이지만, 변호사가 결혼 생활의 파탄 원인은 조애나라고 몰아붙여 재판은 치열해진다. 두 번째 재판에서, 마거릿이 증인으로 나와 테드가 변했다고 옹호하지만, 조애나의 변호사가 조애나를 떠나도록 유도한 것은 바로 마거릿이었음을 밝히며 설득력이 약해진다. 결국 재판은 조애나가 승소한다. 조애나는 테드에게 변호사의 과격한 행동을 사과하지만 테드는 이미 돌아선 상태다.\\n\\n빌리가 조애나의 집으로 가는 날 부자는 이별의 포옹을 한다. 조애나가 집으로 찾아와 테드만 잠시 부른다. 조애나는 눈물을 흘리며, 빌리를 생각해서라도 데려가지 않는 것으로 결정했다고 이야기한다. 테드도 마찬가지로 눈물을 머금고 조애나와 포옹한다. 빌리를 보러 가겠다는 조애나에게 테드는 혼자 남아 있을 테니 아들과 둘이서만 보라고 한다. 조애나가 엘리베이터에 오르며 오늘 어떻게 보이냐고 묻고, 테드는 멋지다고 답한다.\\n-----\\n문서4: 이렇게 발견된 첫 번째 미라는 엑스레이 검사를 받았는데, \"기형 두개골 때문에 작은 어른처럼 보인\" 무뇌증 아기의 미라인 것으로 밝혀졌다. 1990년대 와이오밍대의 고고학자였던 조지 길과 덴버 어린이병원이 공동으로 조사한 두 번째 미라도 무뇌증에 걸린 아기인 것으로 드러났다. DNA 검사 결과 아기는 아메리카 원주민으로 밝혀졌고 탄소 연대는 1700년대로 측정됐다. \\n\\n1979년 7월 7일 <캐스퍼 스타트리뷴>에 실린 기사에 의하면 첫 번째 미라는 발견되자마자 날조된 것이다, 아기다, 전설상의 \\'소인\\'이다를 두고 논쟁이 벌어지기 시작했다고 한다. 미라는 와이오밍 주 미티츠의 한 동네 약국에 자리를 잡았고 이후 몇년간 명물로 인기를 끌다가 캐스퍼에 사는 사업가인 이반 T. 굿맨이 구입했다. 그런 다음에는 뉴욕의 사업가인 리오너드 워들러에게 넘어갔고, 그 뒤부터 현재의 행방은 아무도 모른다. 당시 캐스퍼 스타트리뷴에서는 진화론이 잘못됐음을 증명하기 위해 사라진 미라를 찾는 사람에게 10,000달러의 상금을 주겠다고 썼다\\n-----\\n문서5: ;헤쿠바\\n녹스의 네크로멘서들의 어둠의 유산의 상속자인 헤쿠바는 망각의 오브를 이용하여 새로운 죽은자의 군대를 다시 움직이려는 무서운 음모를 가지고 있다.그녀는 죽은자의 땅의 폐허에 숨어서 오우거와 좀비, 수많은 언데드들로 구성된 그녀의 군대를 보내 녹스의 주민들을 공포에 떨게 하고 있는 장본인이다.\\n\\n;공중전함 함장 (잔도)\\n세상의 관망자. 공중전함 함장은 많은 사람들에게 알려져 있지만 소수만이 그를 잘 안다고 말할 수 있다. 녹스의 여러곳을 떠돌면서 그는 녹스를 주의 깊게 관찰하고 있다.\\n\\n;소환술사 알드윈\\n녹스의 마스터 소환술사이자 네크로맨서 전쟁의 영웅인 알드윈은 익스마을의 동쪽 자그마한 오두막에서 은거하며 살고 있다. 그는 대부분의 시간을 어떻게 새로운 비스트를 매료하고 소환할 것인지를 연구하는데 종사하고 있다.\\n\\n;대마법사 호바스\\n예전의 호바스는 잔도가 네크로맨서 전쟁을 끝낼때 사용했던 아티팩트인 망각의 지팡이의 주요 제작자 중 한사람 이었다. 지금의 호바스는 갈라바 성에 살면서 마법 견습생들을 수련시키고 그곳에 사는 마법사들의 공동체에서 여러 가지 일거리를 돌보고 있으며 아직까지도 최고의 마법력을 가지고 있다.\\n\\n;워로드 호렌더스\\n던 미르 요새의 파이어 나이츠의 사나운 감독인 워로드 호렌더스는 전설적인 전사들을 훈련시키고 있다. 필연적으로 잔도와 비교되는 것에 자극받아 호렌더스는 그의 이생을 그가 만나는 어떤 사람보다도 뛰어나다는 것을 증명하려고 노력하고 있다.\\n\\n;네크로멘서\\n헤쿠바의 오른팔로서 흑마법을 쓰는 계열의 마법사이다. 그러나 자신의 영혼을 악에 팔고 그것으로 마법의 능력을 얻은 마법사이기 때문에 헤쿠바의 명령을 받아 게임상에서 주인공인 플레이어를 심심치 않게 괴롭히는 인물이다',\n",
       "   'role': 'system'},\n",
       "  {'content': '콘코바르가 왕이 된 이후 이멘마하에서 있었던 첫 번째 전투는 무엇이었나?', 'role': 'user'},\n",
       "  {'content': '검색 결과에는 콘코바르가 왕이 된 이후 이멘마하에서 있었던 첫 번째 전투를 찾을 수 없습니다.',\n",
       "   'role': 'assistant'}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6eef45da-7f4f-4bc0-b322-46390c21ebf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69f030c2d3984d2eb7a7e90adc98852e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1504 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터셋 저장\n",
    "test_dataset.save_to_disk(\"test_dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94383df4-9c95-47ab-b686-e32f8ce4f28c",
   "metadata": {},
   "source": [
    "## 2. 모델 로드 및 템플릿 적용\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "520b546c-f82f-4a44-951d-ea85dec73a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4baf4254c1d94d9b9347800618ad13c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/777 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "591051ce3d904bd7a063037fff9bb40a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3ee9b8b5b7d4f8e86bbfad56449c964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcc503cff6954e17b0bc29398a235c33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "800ab27bb180422cb3bbbd95ee5a145a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56d1db5207c74a6d886528b55aa99343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4f28d36505c41019f0a4feef6eeacd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e83d45351e340b5a7579120b3c3dade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08f333c084524b6dbeccae3d8c560c8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/51.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f1f44f33a874eb6b0dcdce55d535b0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46c6f9c128b34eeb99ae300e0fb69e31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/430 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 허깅페이스 모델 ID\n",
    "model_id = \"NCSOFT/Llama-VARCO-8B-Instruct\" \n",
    "\n",
    "# Load model and tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7aca009-8f0e-4579-b018-6fbcb2f2ad5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "당신은 검색 결과를 바탕으로 질문에 답변해야 합니다.\n",
      "\n",
      "다음의 지시사항을 따르십시오.\n",
      "1. 질문과 검색 결과를 바탕으로 답변하십시오.\n",
      "2. 검색 결과에 없는 내용을 답변하려고 하지 마십시오.\n",
      "3. 질문에 대한 답이 검색 결과에 없다면 검색 결과에는 \"해당 질문~에 대한 내용이 없습니다.\" 라고 답변하십시오.\n",
      "4. 답변할 때 특정 문서를 참고하여 문장 또는 문단을 작성했다면 뒤에 출처는 이중 리스트로 해당 문서 번호를 남기십시오. 예를 들어서 특정 문장이나 문단을 1번 문서에서 인용했다면 뒤에 [[ref1]]이라고 기재하십시오.\n",
      "5. 예를 들어서 특정 문장이나 문단을 1번 문서와 5번 문서에서 동시에 인용했다면 뒤에 [[ref1]], [[ref5]]이라고 기재하십시오.\n",
      "6. 최대한 다수의 문서를 인용하여 답변하십시오.\n",
      "\n",
      "검색 결과:\n",
      "-----\n",
      "문서1: 콘코바르는 결국 죽게 되는데, 그 곡절은 이러하다. 라긴의 왕 메스 게그러의 뇌를 굳힌 겻을 울라의 코날이 전리품으로 가지고 있었는데, 코나크타의 전사 케트 막 마가크가 이를 훔쳐갔다. 그리고 케트는 무릿매로 메스 게그러의 뇌를 던져 콘코바르의 머리를 맞추었고, 메스 게그러의 뇌가 콘코바르의 머리통 깊숙히 박혀 버렸다. 이 일이 일어난 곳은 우르카르(Urchair)의 발러 아흐(Baile Ath), 곧 오늘날의 웨스트미스 주 호르셀리프라고 한다. 콘코바르의 의사들은 이 이물질을 제거할 수 없었고, 상처를 봉합만 한 뒤 왕에게 흥분하지 않으면 생명을 유지할 수 있다고 말했다. 7년이 평화롭게 흘러간 뒤 콘코바르는 그리스도가 죽었다는 소식을 듣게 되어 분노했고, 뇌가 터져 죽었다. 머리가 터진 자리에서 뿜어져나온 피의 세례를 받은 결과 그는 기독교인이 되었고 그 영혼은 천국으로 갔다. 콘코바르의 죽음에 관한 이 기록은 매우 얄팍한 기독교화가 이루어져 있는데, 한편 노르드 신화의 토르가 흐룽그니르와 싸우다 머리에 숫돌이 박힌 이야기와 유사한 점이 있다. 어쩌면 두 이야기는 하나의 기원을 공유하거나 또는 바이킹이 에린에 영향을 미치던 시기(노르드-게일)에 수입된 것일 수도 있다.\n",
      "\n",
      "울라인들은 아직도 코나크타에 망명 중이던 콘코바르의 아들 코르막 콘드 롱가스를 왕으로 추대하기 위해 초빙했는데, 이멘마하로 돌아오는 길에 코르막은 기아스를 어기게 되었고 다 코카(Da Choca) 여관에 묵던 중에 습격당해 피살당했다. 이에 코날 케르나크가 콘코바르의 다른 아들 쿠스라드 멘드 마하(Cúscraid Mend Macha)를 왕으로 추대했다.\n",
      "-----\n",
      "문서2: 케트 막 마가크(Cet mac Mágach)는 아일랜드 신화의 얼스터 대계에 등장하는 인물이다. 코나크타의 전사로, 울라의 코날 케르나크의 적수이다.\n",
      "\n",
      "어떤 전승들에서는 케트가 코날의 어머니 핀드코엠과 남매지간, 코날과는 숙질간이라고도 한다.\n",
      "\n",
      "라긴 사람 막 다 호의 집에서 연회가 벌어졌을 때, 코나크타와 울라의 여러 전사들이 쿠라드미르를 놓고 각자의 업적을 자랑하며 다투었다. 케트는 전사들 각각을 자신이 어떻게 이겼는지 들먹이며 그들 모두의 입을 다물게 만들었다. 케트가 쿠라드미르를 가져가려는 순간 코날 케르나크가 도착했다. 코날은 자신이 케트보다 우위에 있다고 주장했고, 케트는 패배를 인정했다. 그러나 자신의 동생 아늘룬이 있었다면 그가 코날의 우위에 있었을 것이라고 주장했다. 그러자 코날은 방금 잘라온 아늘룬의 머리를 케트에게 던져주는 것으로 응수했다. \n",
      "\n",
      "케트는 울라의 왕 콘코바르 막 네사를 죽였는데, 그 이야기는 이러하다. 코날이 라긴의 왕 메스 게그러를 죽이고 그 뇌를 굳힌 것을 트로피삼아 차고 다녔는데, 케트가 그것을 훔쳐다가 무릿매로 던져 콘코바르의 머리통에 파묻었다. 콘코바르의 의사들은 왕을 죽이지 않는 이상 이 이물질을 빼낼 방법을 찾지 못했다. 그래서 대충 봉합한 뒤 왕에게 지나치게 흥분하지 않는다면 목숨을 부지할 수 있다고 말했다. 7년이 평화롭게 흘러간 끝에 콘코바르는 그리스도가 죽었다는 소식을 듣게 되었다. 그는 분노했고, 그 바람에 뇌가 터져 죽었다.\n",
      "\n",
      "어느 겨울날 케트가 울라로 습격을 나가 울라 남자 스물일곱 명을 죽이고 그 수급들을 베어갔다. 눈이 내렸기에 코날은 케트의 흔적을 추적할 수 있었다. 코날은 케트를 따라잡았지만 그를 대적하기 주저했는데, 전차를 몰던 마부가 그를 겁쟁이라 비난하자 마음을 고쳐먹고 나서게 되었다. 둘이는 한 여울에서 일 대 일 결투를 벌였고, 격렬한 싸움 끝에 코날이 케트를 죽였으며 코날 본인도 빈사상태에 빠졌다.\n",
      "-----\n",
      "문서3: 뉴욕의 광고 회사에서 일하는 테드 크레이머는 능력 있는 일꾼이지만 워커홀릭이어서 가정에는 소홀한 가장이다. 아내 조애나는 테드의 귀가가 늦은 어느 날 갑작스럽게 이유를 밝히지 않고 이혼을 통보한 뒤 집을 나가 버린다. 테드는 애써 한순간의 변덕이고 금방 돌아오겠지 하는 생각은 하지만, 곧 아들 빌리를 돌보면서 서툰 집안일을 해야 할 처지가 된다. 일과 양육을 병행하느라 회사에서의 평판은 나빠지고, 빌리는 계속 해서 이어지는 엄마의 부재 때문에 짜증을 낸다. 다행히도 시간이 지나면서 부자는 둘만의 생활에 적응해 나간다.\n",
      "\n",
      "테드는 아랫집에 사는 이웃이자 조애나와 친했던 마거릿과 친해진다. 마거릿도 테드와 마찬가지로 이혼 후 자식들 혼자 키우고 있었으므로 둘은 서로의 처지에 공감했던 것이다. 하루는 잠시 한눈을 팔던 사이 빌리가 정글짐에서 추락해 머리가 찢어지는 사건이 벌어진다. 위급한 테드는 아들을 안고 먼 거리를 달려 병원에 데려가고, 부성애를 발휘해 아들의 수술을 지켜보며 아들을 안심케 한다. 수술 후 테드는 마거릿을 빌리의 대모로 삼는다.\n",
      "\n",
      "조애나가 떠난 지 15개월 만에 뉴욕에 돌아와 테드와 만난다. 둘은 처음에는 친밀했다. 조애나는 자기가 떠난 것은 아들을 키울 준비를 하기 위해서였으며, 이제 아들의 양육권을 달라고 한다. 그 말을 들은 테드는 크게 화를 내며 자리를 박차고 나선다. 변호사가 고용되고 곧 법정 다툼으로 발전한다. 불행히도 재판을 앞두고 테드가 직장에서 해고되는 바람에 양육권 재판에 불리하게 변하자, 테드는 연봉을 크게 낮춰가면서까지 새 직장을 구한다.\n",
      "\n",
      "조애나는 재판에서 결혼 생활은 원만하지 않았고 테드의 일 중독과 편견 때문에 자신은 패션디자이너로서의 꿈을 접어야 했다고 증언한다. 지금은 직업을 얻어 테드보다도 더 연봉이 높고 가정에 소홀했던 테드보다 자신이 빌리를 키우기에 더 적합하다고 말한다. 테드는 조애나의 고백에 마음이 움직이지만, 변호사가 결혼 생활의 파탄 원인은 조애나라고 몰아붙여 재판은 치열해진다. 두 번째 재판에서, 마거릿이 증인으로 나와 테드가 변했다고 옹호하지만, 조애나의 변호사가 조애나를 떠나도록 유도한 것은 바로 마거릿이었음을 밝히며 설득력이 약해진다. 결국 재판은 조애나가 승소한다. 조애나는 테드에게 변호사의 과격한 행동을 사과하지만 테드는 이미 돌아선 상태다.\n",
      "\n",
      "빌리가 조애나의 집으로 가는 날 부자는 이별의 포옹을 한다. 조애나가 집으로 찾아와 테드만 잠시 부른다. 조애나는 눈물을 흘리며, 빌리를 생각해서라도 데려가지 않는 것으로 결정했다고 이야기한다. 테드도 마찬가지로 눈물을 머금고 조애나와 포옹한다. 빌리를 보러 가겠다는 조애나에게 테드는 혼자 남아 있을 테니 아들과 둘이서만 보라고 한다. 조애나가 엘리베이터에 오르며 오늘 어떻게 보이냐고 묻고, 테드는 멋지다고 답한다.\n",
      "-----\n",
      "문서4: 이렇게 발견된 첫 번째 미라는 엑스레이 검사를 받았는데, \"기형 두개골 때문에 작은 어른처럼 보인\" 무뇌증 아기의 미라인 것으로 밝혀졌다. 1990년대 와이오밍대의 고고학자였던 조지 길과 덴버 어린이병원이 공동으로 조사한 두 번째 미라도 무뇌증에 걸린 아기인 것으로 드러났다. DNA 검사 결과 아기는 아메리카 원주민으로 밝혀졌고 탄소 연대는 1700년대로 측정됐다. \n",
      "\n",
      "1979년 7월 7일 <캐스퍼 스타트리뷴>에 실린 기사에 의하면 첫 번째 미라는 발견되자마자 날조된 것이다, 아기다, 전설상의 '소인'이다를 두고 논쟁이 벌어지기 시작했다고 한다. 미라는 와이오밍 주 미티츠의 한 동네 약국에 자리를 잡았고 이후 몇년간 명물로 인기를 끌다가 캐스퍼에 사는 사업가인 이반 T. 굿맨이 구입했다. 그런 다음에는 뉴욕의 사업가인 리오너드 워들러에게 넘어갔고, 그 뒤부터 현재의 행방은 아무도 모른다. 당시 캐스퍼 스타트리뷴에서는 진화론이 잘못됐음을 증명하기 위해 사라진 미라를 찾는 사람에게 10,000달러의 상금을 주겠다고 썼다\n",
      "-----\n",
      "문서5: ;헤쿠바\n",
      "녹스의 네크로멘서들의 어둠의 유산의 상속자인 헤쿠바는 망각의 오브를 이용하여 새로운 죽은자의 군대를 다시 움직이려는 무서운 음모를 가지고 있다.그녀는 죽은자의 땅의 폐허에 숨어서 오우거와 좀비, 수많은 언데드들로 구성된 그녀의 군대를 보내 녹스의 주민들을 공포에 떨게 하고 있는 장본인이다.\n",
      "\n",
      ";공중전함 함장 (잔도)\n",
      "세상의 관망자. 공중전함 함장은 많은 사람들에게 알려져 있지만 소수만이 그를 잘 안다고 말할 수 있다. 녹스의 여러곳을 떠돌면서 그는 녹스를 주의 깊게 관찰하고 있다.\n",
      "\n",
      ";소환술사 알드윈\n",
      "녹스의 마스터 소환술사이자 네크로맨서 전쟁의 영웅인 알드윈은 익스마을의 동쪽 자그마한 오두막에서 은거하며 살고 있다. 그는 대부분의 시간을 어떻게 새로운 비스트를 매료하고 소환할 것인지를 연구하는데 종사하고 있다.\n",
      "\n",
      ";대마법사 호바스\n",
      "예전의 호바스는 잔도가 네크로맨서 전쟁을 끝낼때 사용했던 아티팩트인 망각의 지팡이의 주요 제작자 중 한사람 이었다. 지금의 호바스는 갈라바 성에 살면서 마법 견습생들을 수련시키고 그곳에 사는 마법사들의 공동체에서 여러 가지 일거리를 돌보고 있으며 아직까지도 최고의 마법력을 가지고 있다.\n",
      "\n",
      ";워로드 호렌더스\n",
      "던 미르 요새의 파이어 나이츠의 사나운 감독인 워로드 호렌더스는 전설적인 전사들을 훈련시키고 있다. 필연적으로 잔도와 비교되는 것에 자극받아 호렌더스는 그의 이생을 그가 만나는 어떤 사람보다도 뛰어나다는 것을 증명하려고 노력하고 있다.\n",
      "\n",
      ";네크로멘서\n",
      "헤쿠바의 오른팔로서 흑마법을 쓰는 계열의 마법사이다. 그러나 자신의 영혼을 악에 팔고 그것으로 마법의 능력을 얻은 마법사이기 때문에 헤쿠바의 명령을 받아 게임상에서 주인공인 플레이어를 심심치 않게 괴롭히는 인물이다<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "콘코바르가 왕이 된 이후 이멘마하에서 있었던 첫 번째 전투는 무엇이었나?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "검색 결과에는 콘코바르가 왕이 된 이후 이멘마하에서 있었던 첫 번째 전투를 찾을 수 없습니다.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 템플릿 적용\n",
    "text = tokenizer.apply_chat_template(\n",
    "    train_dataset[0][\"messages\"], tokenize=False, add_generation_prompt=False\n",
    ")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab6edd1-951a-4950-be9a-8d2096d2752d",
   "metadata": {},
   "source": [
    "## 3. LoRA와 SFTConfig 설정\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ad8216d-baaa-4aaa-b172-ca992c9f4bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "        lora_alpha=32,\n",
    "        lora_dropout=0.1,\n",
    "        r=8,\n",
    "        bias=\"none\",\n",
    "        target_modules=[\"q_proj\", \"v_proj\"],\n",
    "        task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7395e400-be31-4e70-afaa-b90a0573cc0a",
   "metadata": {},
   "source": [
    "- lora_alpha: LoRA(Low-Rank Adaptation)에서 사용하는 스케일링 계수를 설정합니다. LoRA의 가중치 업데이트가 모델에 미치는 영향을 조정하는 역할을 하며, 일반적으로 학습 안정성과 관련이 있습니다.\n",
    "- lora_dropout: LoRA 적용 시 드롭아웃 확률을 설정합니다. 드롭아웃은 과적합(overfitting)을 방지하기 위해 일부 뉴런을 랜덤하게 비활성화하는 정규화 기법입니다. 0.1로 설정하면 학습 중 10%의 뉴런이 비활성화.\n",
    "- r: LoRA의 랭크(rank)를 설정합니다. 이는 LoRA가 학습할 저차원 공간의 크기를 결정합니다. 작은 값일수록 계산 및 메모리 효율이 높아지지만 모델의 학습 능력이 제한될 수 있습니다.\n",
    "- bias: LoRA 적용 시 편향(bias) 처리 방식을 지정합니다. \"none\"으로 설정하면 편향이 LoRA에 의해 조정되지 않습니다. \"all\" 또는 \"lora_only\"와 같은 값으로 변경하여 편향을 조정할 수도 있습니다.\n",
    "- target_modules: LoRA를 적용할 특정 모듈(레이어)의 이름을 리스트로 지정합니다. 예제에서는 \"q_proj\"와 \"v_proj\"를 지정하여, 주로 Self-Attention 메커니즘의 쿼리와 값 프로젝션 부분에 LoRA를 적용합니다.\n",
    "- task_type: LoRA가 적용되는 작업 유형을 지정합니다. \"CAUSAL_LM\"은 Causal Language Modeling, 즉 시퀀스 생성 작업에 해당합니다. 다른 예로는 \"SEQ2SEQ_LM\"(시퀀스-투-시퀀스 언어 모델링) 등이 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbe8e9bc-92e7-41ae-b03b-253357969160",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = SFTConfig(\n",
    "    output_dir=\"llama-3-8b-rag-ko\",           # 저장될 디렉토리와 저장소 ID\n",
    "    num_train_epochs=3,                      # 학습할 총 에포크 수 \n",
    "    per_device_train_batch_size=2,           # GPU당 배치 크기\n",
    "    gradient_accumulation_steps=2,           # 그래디언트 누적 스텝 수\n",
    "    gradient_checkpointing=True,             # 메모리 절약을 위한 체크포인팅\n",
    "    optim=\"adamw_torch_fused\",               # 최적화기\n",
    "    logging_steps=10,                        # 로그 기록 주기\n",
    "    save_strategy=\"steps\",                   # 저장 전략\n",
    "    save_steps=50,                           # 저장 주기\n",
    "    bf16=True,                              # bfloat16 사용\n",
    "    learning_rate=1e-4,                     # 학습률\n",
    "    max_grad_norm=0.3,                      # 그래디언트 클리핑\n",
    "    warmup_ratio=0.03,                      # 워밍업 비율\n",
    "    lr_scheduler_type=\"constant\",           # 고정 학습률\n",
    "    push_to_hub=False,                      # 허브 업로드 안 함\n",
    "    remove_unused_columns=False,\n",
    "    dataset_kwargs={\"skip_prepare_dataset\": True},\n",
    "    report_to=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6ff34d-0256-4a1a-a1d6-728c6a74097f",
   "metadata": {},
   "source": [
    "- `output_dir`: 학습 결과가 저장될 디렉토리 또는 모델 저장소의 이름을 지정합니다. 이 디렉토리에 학습된 모델 가중치, 설정 파일, 로그 파일 등이 저장됩니다.\n",
    "\r\n",
    "- `num_train_epochs`: 모델을 학습시키는 총 에포크(epoch) 수를 지정합니다. 에포크는 학습 데이터 전체를 한 번 순회한 주기를 의미합니다. 예를 들어, `3`으로 설정하면 데이터셋을 3번 학습합니.\r\n",
    "\r\n",
    "- `per_device_train_batch_size`: GPU 한 대당 사용되는 배치(batch)의 크기를 설정합니다. 배치 크기는 모델이 한 번에 처리하는 데이터 샘플의 수를 의미합니다. 작은 크기는 메모리 사용량이 적지만 학습 시간이 증가할 수 있니다.\r\n",
    "\r\n",
    "- `gradient_accumulation_steps`: 그래디언트를 누적할 스텝(step) 수를 지정합니다. 이 값이 `2`로 설정된 경우, 두 스텝마다 그래디언트를 업데이트합니다. 배치 크기를 가상으로 늘리는 효과가 있으며, GPU 메모리 부족 문제를 해결할 때 용합니다.\r\n",
    "\r\n",
    "- `gradient_checkpointing`: 그래디언트 체크포인팅을 활성화하여 메모리를 절약합니다. 이 옵션은 계산 그래프를 일부 저장하지 않고 다시 계산하여 메모리를 절약하지만, 속도가 약간 느려질수 있습니다.\r\n",
    "\r\n",
    "- `optim`: 학습 시 사용할 최적화 알고리즘을 설정합니다. `adamw_torch_fused`는 PyTorch의 효율적인 AdamW 최적기를 사용합니다.\r\n",
    "\r\n",
    "- `logging_steps`: 로그를 기록하는 주기를 스텝 단위로 지정합니다. 예를 들어, `10`으로 설정하면 매 10 스텝마 로그를 기록합니다.\r\n",
    "\r\n",
    "- `save_strategy`: 모델을 저장하는 전략을 설정합니다. `\"steps\"`로 설정된 경우, 지정된 스마다 모델이 저장됩니다.\r\n",
    "\r\n",
    "- `save_steps`: 모델을 저장하는 주기를 스텝 단위로 설정합니다. 예를 들어, `50`으로 설정하면 매 50스텝마다 모델을 저장합니다.\r\n",
    "\r\n",
    "- `bf16`: `bfloat16` 정밀도를 사용하도록 설정합니다. `bfloat16`은 FP32와 유사한 범위를 제공하면서 모리와 계산 효율성을 높입니다.\r\n",
    "\r\n",
    "- `learning_rate`: 학습률을 지정합니다. 학습률은 모델의 가중치가 한 번의 업데이트에서 얼마나 크게 변할지를 결정합니다. 일반적으로 작은 값을 용하여 안정적인 학습을 유도합니다.\r\n",
    "\r\n",
    "- `max_grad_norm`: 그래디언트 클리핑의 임계값을 설정합니다. 이 값보다 큰 그래디언트가 발생하면, 임계값으로 정하여 폭발적 그래디언트를 방지합니다.\r\n",
    "\r\n",
    "- `warmup_ratio`: 학습 초기 단계에서 학습률을 선형으로 증가시키는 워밍업 비율을 지정합니다 학습의 안정성을 높이기 위해 사용됩니다.\r\n",
    "\r\n",
    "- `lr_scheduler_type`: 학습률 스케줄러의 유형을 설정합니다. `\"costant\"`는 학습률을 일정하게 유지합니다.\r\n",
    "\r\n",
    "- `push_to_hub`: 학습된 모델을 허브에 업로드할지 여부를 설정합니. `False`로 설정하면 업로드하지 않습니다.\r\n",
    "\r\n",
    "- `remove_unused_columns`: 사용되지 않는 열을 제거할지 여부를 설정합니다.`True`로 설정하면 메모리를 절약할 수 있습니다.\r\n",
    "\r\n",
    "- `dataset_kwargs`: 데이터셋 로딩 시 추가적인 설정을 전달합니다. 예제에서는 `skip_prepare_dataset True`로 설정하여 데이터셋 준비 단계를 건너뜁니다.\r\n",
    "\r\n",
    "- `report_to`: 학습 로그를 보고할 대상을 지정합니다. `None`으로 설정되면 로그가 기록되지 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589f0a2f-639b-4b89-852a-7a0bbcbe1203",
   "metadata": {},
   "source": [
    "## 4. 학습 중 전처리 함수: collate_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9526becf-24c6-49b9-b503-75f31f64ae0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    new_batch = {\n",
    "        \"input_ids\": [],\n",
    "        \"attention_mask\": [],\n",
    "        \"labels\": []\n",
    "    }\n",
    "\n",
    "    for example in batch:\n",
    "        messages = example[\"messages\"]\n",
    "\n",
    "        # LLaMA 3 채팅 템플릿 적용 (시작 토큰 포함)\n",
    "        prompt = \"<|begin_of_text|>\"\n",
    "        for msg in messages:\n",
    "            role = msg[\"role\"]\n",
    "            content = msg[\"content\"].strip()\n",
    "            prompt += f\"<|start_header_id|>{role}<|end_header_id|>\\n{content}<|eot_id|>\"\n",
    "\n",
    "        # 마지막 assistant 메시지는 응답으로 간주하고 레이블에 포함\n",
    "        text = prompt.strip()\n",
    "\n",
    "        # 토큰화\n",
    "        tokenized = tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            max_length=max_seq_length,\n",
    "            padding=False,\n",
    "            return_tensors=None,\n",
    "        )\n",
    "\n",
    "        input_ids = tokenized[\"input_ids\"]\n",
    "        attention_mask = tokenized[\"attention_mask\"]\n",
    "        labels = [-100] * len(input_ids)\n",
    "\n",
    "        # assistant 응답의 시작 위치 찾기\n",
    "        assistant_header = \"<|start_header_id|>assistant<|end_header_id|>\\n\"\n",
    "        assistant_tokens = tokenizer.encode(assistant_header, add_special_tokens=False)\n",
    "        eot_token = \"<|eot_id|>\"\n",
    "        eot_tokens = tokenizer.encode(eot_token, add_special_tokens=False)\n",
    "\n",
    "        # 레이블 범위 지정\n",
    "        i = 0\n",
    "        while i <= len(input_ids) - len(assistant_tokens):\n",
    "            if input_ids[i:i + len(assistant_tokens)] == assistant_tokens:\n",
    "                start = i + len(assistant_tokens)\n",
    "                end = start\n",
    "                while end <= len(input_ids) - len(eot_tokens):\n",
    "                    if input_ids[end:end + len(eot_tokens)] == eot_tokens:\n",
    "                        break\n",
    "                    end += 1\n",
    "                for j in range(start, end):\n",
    "                    labels[j] = input_ids[j]\n",
    "                for j in range(end, end + len(eot_tokens)):\n",
    "                    labels[j] = input_ids[j]  # <|eot_id|> 토큰도 포함\n",
    "                break\n",
    "            i += 1\n",
    "\n",
    "        new_batch[\"input_ids\"].append(input_ids)\n",
    "        new_batch[\"attention_mask\"].append(attention_mask)\n",
    "        new_batch[\"labels\"].append(labels)\n",
    "\n",
    "    # 패딩 처리\n",
    "    max_length = max(len(ids) for ids in new_batch[\"input_ids\"])\n",
    "    for i in range(len(new_batch[\"input_ids\"])):\n",
    "        pad_len = max_length - len(new_batch[\"input_ids\"][i])\n",
    "        new_batch[\"input_ids\"][i].extend([tokenizer.pad_token_id] * pad_len)\n",
    "        new_batch[\"attention_mask\"][i].extend([0] * pad_len)\n",
    "        new_batch[\"labels\"][i].extend([-100] * pad_len)\n",
    "\n",
    "    for k in new_batch:\n",
    "        new_batch[k] = torch.tensor(new_batch[k])\n",
    "\n",
    "    return new_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181ea71f-f642-4aed-ba4d-d142535571c4",
   "metadata": {},
   "source": [
    "- 라마 챗 템플릿\n",
    "\n",
    "```\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\r\n",
    "\r\n",
    "You are a helpful AI assistant for travel tips and recommendations.<|eot_id|><|start_header_id|>user<|end_header_id|>\r\n",
    "\r\n",
    "What can you help me with?<|eot_id|><|start_header_id|>assistant<|end_header_id|>|>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32aedd13-5447-4faf-a612-d2e0908c0833",
   "metadata": {},
   "source": [
    "collate_fn(batch) 함수는 자연어 처리 모델 학습을 위해 데이터를 전처리하는 역할을 수행합니다. 이 함수는 배치 내의 데이터를 처리하여 모델이 사용할 수 있는 입력 형식으로 변환합니다.\r\n",
    "\r\n",
    "먼저, 각 샘플의 메시지에서 개행 문자를 제거하고 필요한 정보만 남깁니다. 정리된 메시지로 텍스트를 구성하고 이를 토큰화하여 input_ids와 attention_mask를 생성합니다. 이후 레이블 데이터를 초기화한 다음, 특정 토큰 패<|start_header_id|>assistantnt 이후부터 eot_idnd|>까지)을 찾아 해당 범위에 레이블을 설정합니다. 이 범위를 제외한 나머지 위치는 -100으로 설정하여 손실 계산에서 제외되도록 합니다.\r\n",
    "\r\n",
    "최종적으로, 배치 내 모든 샘플의 길이를 동일하게 맞추기 위해 패딩 작업을 수행합니다. 이 과정에서 입력 데이터에는 패딩 토큰 ID를 추가하고, 어텐션 마스크에는 0을 추가하며, 레이블에는 -100을 추가합니다. 모든 데이터는 PyTorch 텐서로 변환되어 반환됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "397d4044-d709-4492-ab4b-63ed3ec11d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "처리된 배치 데이터:\n",
      "입력 ID 형태: torch.Size([1, 3234])\n",
      "어텐션 마스크 형태: torch.Size([1, 3234])\n",
      "레이블 형태: torch.Size([1, 3234])\n"
     ]
    }
   ],
   "source": [
    "# 최대 길이\n",
    "max_seq_length=8192\n",
    "\n",
    "# collate_fn 테스트 (배치 크기 1로)\n",
    "example = train_dataset[0]\n",
    "batch = collate_fn([example])\n",
    "\n",
    "print(\"\\n처리된 배치 데이터:\")\n",
    "print(\"입력 ID 형태:\", batch[\"input_ids\"].shape)\n",
    "print(\"어텐션 마스크 형태:\", batch[\"attention_mask\"].shape)\n",
    "print(\"레이블 형태:\", batch[\"labels\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "633a4b4e-6192-4231-a33e-3e1b35cc06fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력에 대한 정수 인코딩 결과:\n",
      "[128000, 128006, 9125, 128007, 198, 65895, 83628, 34804, 115036, 99901, 18918, 82818, 120378, 43139, 109760, 19954, 111964, 110513, 109670, 382, 13447, 49531, 21028, 67890, 30426, 115790, 18359, 103386, 100968, 119978, 627, 16, 13, 109760, 54780, 115036, 99901, 18918, 82818, 120378, 43139, 111964, 16582, 119978, 627, 17, 13, 115036, 99901, 19954, 108838, 109842, 18359, 111964, 16582, 113348, 117193, 96677, 119978, 627, 18, 13, 109760, 19954, 102597, 108386, 13094, 115036, 99901, 19954, 47782, 115300, 115036, 99901, 102772, 330, 34983, 65895, 109760, 93, 19954, 102597, 109842, 13094, 120078, 1210, 103959, 35495, 111964, 16582, 119978, 627, 19, 13, 111964, 48936, 54718, 103966, 30381, 117294, 18918, 119884, 83290, 54535, 41953, 108520, 54535, 101353, 18359, 114839, 101528, 33390, 107333, 19954, 102722, 102657, 16969, 23955, 101711, 84734, 17835, 95713, 117294, 85721, 48424, 18918, 102484, 21121, 119978, 13, 96717, 18918, 105510, 27796, 103966, 30381, 54535, 41953, 106593, 54535, 101353, 18359, 220, 16, 43144, 117294, 57575, 59777, 27797, 101528, 33390, 107333, 19954, 4416, 1116, 16, 5163, 110917, 55216, 58232, 16582, 119978, 627, 20, 13, 96717, 18918, 105510, 27796, 103966, 30381, 54535, 41953, 106593, 54535, 101353, 18359, 220, 16, 43144, 117294, 81673, 220, 20, 43144, 117294, 57575, 101604, 118472, 59777, 27797, 101528, 33390, 107333, 19954, 4416, 1116, 16, 21128, 4416, 1116, 20, 5163, 110917, 55216, 58232, 16582, 119978, 627, 21, 13, 82273, 113760, 50467, 125546, 117294, 18918, 59777, 27797, 83290, 111964, 16582, 119978, 382, 109070, 78326, 99901, 512, 35864, 52688, 27796, 16, 25, 118003, 102525, 101974, 113562, 83719, 100654, 108466, 58901, 98243, 103170, 11, 55925, 46230, 94, 104834, 34804, 118572, 108907, 13, 103959, 109743, 21028, 110400, 52491, 25941, 100027, 121775, 21028, 5251, 127802, 18918, 100487, 111, 101443, 234, 24839, 119, 18359, 111535, 51440, 21028, 103651, 106223, 13094, 57519, 29102, 101696, 43139, 120693, 107417, 103170, 11, 103651, 61415, 82233, 101109, 21028, 57519, 56154, 111704, 222, 29726, 112925, 96677, 20565, 82233, 20565, 117012, 116231, 242, 110218, 116726, 13, 107536, 111704, 222, 29726, 16969, 101480, 119357, 101518, 17835, 52491, 25941, 100027, 121775, 21028, 5251, 127802, 18918, 101012, 246, 84377, 118003, 102525, 101974, 100968, 21028, 107802, 106064, 107625, 103948, 101461, 35495, 11, 52491, 25941, 100027, 121775, 21028, 5251, 127802, 20565, 118003, 102525, 101974, 100968, 21028, 107802, 29102, 102233, 101413, 232, 112426, 101709, 104293, 113048, 87931, 108584, 13, 23955, 118860, 126985, 103777, 111003, 34804, 101834, 100968, 101436, 100968, 12597, 81, 35296, 112574, 97096, 61394, 49508, 102735, 238, 5462, 64, 458, 20277, 705, 124389, 111128, 106223, 21028, 123945, 54289, 57139, 25941, 56773, 92143, 100968, 116512, 29102, 101204, 105771, 108239, 13, 118003, 102525, 101974, 100968, 21028, 101787, 56154, 104210, 23955, 23955, 101438, 103194, 18359, 63171, 93292, 48936, 29833, 124040, 35495, 11, 59134, 102657, 18918, 118069, 100660, 73653, 62398, 107333, 110400, 102244, 103402, 98, 80816, 88525, 51796, 91040, 48918, 126546, 124208, 48936, 29833, 127423, 108537, 13, 220, 22, 100392, 13094, 101971, 57390, 120591, 58901, 103402, 246, 61394, 63375, 107333, 118003, 102525, 101974, 113562, 55925, 107752, 123360, 108466, 100904, 16969, 101228, 118156, 117512, 58901, 117455, 101968, 101687, 122196, 11, 5251, 127802, 20565, 116015, 84377, 108466, 100904, 13, 107802, 107308, 116015, 86351, 65677, 29102, 57575, 5251, 123, 250, 32179, 84377, 61415, 102837, 104064, 21028, 101852, 109065, 18918, 84696, 34804, 99901, 108154, 55216, 104841, 100848, 112215, 120789, 35495, 55925, 101603, 108970, 34804, 107340, 100654, 43139, 17196, 104828, 13, 118003, 102525, 101974, 100968, 21028, 108466, 49531, 19954, 115825, 23955, 112482, 34804, 121520, 80402, 226, 67218, 235, 24486, 55216, 104841, 100848, 57390, 20565, 120893, 32179, 84377, 125226, 11, 62398, 104790, 102058, 100968, 30446, 101327, 57390, 21028, 104689, 100968, 20565, 122040, 53987, 121, 49706, 84136, 100968, 81673, 120014, 41381, 13447, 107802, 111833, 70292, 104, 110230, 13094, 104293, 101443, 234, 116844, 81673, 101003, 56154, 24486, 106313, 13094, 91786, 13, 101139, 116115, 234, 33390, 103405, 110614, 111459, 105454, 21028, 55216, 125160, 100994, 101314, 16582, 109745, 108520, 124852, 115756, 13094, 91586, 102423, 19954, 126652, 101412, 60798, 101954, 45618, 21121, 7, 101687, 100968, 30446, 12, 58901, 33177, 121055, 29833, 44966, 53400, 72208, 33177, 116992, 91786, 382, 102275, 109317, 104210, 117686, 49085, 103651, 61415, 82233, 101109, 19954, 118974, 80732, 72043, 13094, 101954, 118003, 102525, 101974, 100968, 21028, 49508, 65950, 103651, 100968, 107725, 118003, 30446, 71685, 109, 20565, 120155, 110400, 43139, 58935, 67945, 67525, 106958, 84415, 126015, 102621, 103170, 11, 23955, 127055, 100711, 16582, 17835, 110110, 125301, 108523, 19954, 103651, 100968, 107725, 34804, 55216, 54059, 120155, 101139, 21121, 58901, 120789, 35495, 50467, 103651, 101436, 5549, 64, 921, 17270, 8, 84618, 101106, 19954, 100570, 113, 101954, 72043, 19954, 80307, 113, 102079, 65895, 34983, 104064, 108281, 65895, 101528, 13, 23955, 19954, 103651, 106223, 111704, 222, 100968, 61415, 82233, 20565, 118003, 102525, 101974, 100968, 21028, 105642, 49508, 65950, 117141, 25941, 51440, 30446, 49208, 246, 30446, 96677, 16582, 3100, 6792, 2445, 14152, 46211, 18798, 64, 124338, 110400, 43139, 58935, 67945, 101528, 627, 35864, 52688, 27796, 17, 25, 111704, 222, 29726, 112925, 96677, 20565, 82233, 3100, 295, 9155, 386, 28793, 613, 114484, 49508, 33177, 109817, 101327, 57390, 21028, 105825, 109218, 62060, 101015, 19954, 126912, 44005, 59777, 101438, 101568, 13, 103651, 61415, 82233, 101109, 21028, 57519, 56154, 17835, 11, 111535, 51440, 21028, 103651, 106223, 111704, 222, 100968, 61415, 82233, 21028, 103607, 24140, 101568, 382, 32179, 104207, 97, 57519, 104303, 65950, 107031, 111704, 222, 29726, 20565, 103651, 106223, 21028, 123742, 20740, 222, 30446, 102525, 13879, 254, 54780, 102484, 101518, 22035, 63375, 11, 103651, 106223, 54780, 16969, 120135, 103194, 63375, 110917, 49085, 108239, 382, 51440, 109743, 102745, 112925, 50467, 92143, 21028, 104441, 57575, 78453, 62841, 20565, 112734, 32179, 106872, 18359, 54718, 11, 103651, 61415, 82233, 101109, 81673, 111535, 51440, 21028, 110714, 57519, 56154, 102823, 117141, 51440, 30446, 57139, 100968, 18918, 116332, 35495, 106603, 110257, 107022, 82068, 18359, 65677, 102581, 108859, 35243, 45780, 102958, 100904, 13, 111704, 222, 29726, 16969, 57519, 56154, 65950, 127141, 18359, 106915, 13094, 112655, 23955, 122509, 120279, 102407, 115595, 112373, 55925, 65950, 109580, 21028, 39250, 18359, 50467, 101438, 58901, 108098, 100904, 13, 111704, 222, 29726, 20565, 117141, 51440, 30446, 57139, 100968, 18918, 89946, 20565, 101103, 16969, 123637, 103651, 106223, 111704, 222, 100968, 61415, 82233, 20565, 101703, 111283, 101528, 13, 103651, 106223, 34804, 106915, 13094, 111704, 222, 29726, 107988, 101834, 82001, 19954, 127423, 56773, 41953, 122196, 11, 111704, 222, 29726, 16969, 108158, 103588, 18918, 127507, 101528, 13, 113469, 115968, 101604, 77535, 49508, 105622, 53987, 105, 13094, 104816, 33390, 117028, 103651, 106223, 21028, 101834, 82001, 19954, 107417, 18359, 72208, 110917, 56773, 41953, 101528, 13, 106237, 26799, 103651, 106223, 34804, 75908, 101136, 104670, 51440, 102837, 49508, 105622, 53987, 105, 21028, 107802, 106064, 111704, 222, 29726, 102244, 101012, 246, 84377, 119087, 111590, 113914, 24140, 101528, 13, 4815, 107213, 29726, 16969, 111535, 51440, 21028, 110400, 118003, 102525, 101974, 100968, 112925, 103315, 111636, 108466, 101574, 103170, 11, 55925, 110614, 111459, 118572, 108907, 13, 103651, 106223, 13094, 103959, 109743, 21028, 110400, 52491, 25941, 100027, 121775, 18918, 108466, 109816, 55925, 5251, 127802, 18918, 100487, 111, 101443, 234, 107387, 107534, 17835, 102477, 111690, 54059, 103213, 35495, 50467, 75265, 242, 103170, 11, 111704, 222, 29726, 20565, 112767, 18359, 116231, 242, 110218, 113631, 101480, 119357, 101518, 17835, 101012, 246, 84377, 118003, 102525, 101974, 100968, 21028, 107802, 29102, 102233, 19954, 56069, 100371, 119, 100904, 13, 118003, 102525, 101974, 100968, 21028, 101787, 56154, 104210, 110400, 18359, 108466, 105870, 110661, 106751, 23955, 23955, 101438, 103194, 18359, 102558, 120, 40275, 120, 107316, 18359, 107364, 22035, 104352, 101528, 13, 123978, 62060, 112037, 118069, 100660, 24486, 107333, 110400, 102244, 118652, 60798, 58901, 103402, 98, 80816, 88525, 110661, 115300, 103504, 101392, 101, 18359, 86503, 22035, 48936, 29833, 127423, 108537, 13, 220, 22, 100392, 13094, 101971, 57390, 120591, 58901, 103402, 246, 61394, 63375, 110154, 19954, 118003, 102525, 101974, 113562, 55925, 107752, 123360, 108466, 100904, 16969, 101228, 118156, 117512, 58901, 116027, 13, 108154, 101968, 101687, 122196, 11, 55925, 124742, 19954, 5251, 127802, 20565, 116015, 84377, 108466, 100904, 382, 32179, 106833, 122358, 102275, 106223, 111704, 222, 29726, 20565, 111535, 51440, 17835, 80307, 113, 102079, 18359, 127643, 111535, 51440, 116831, 101266, 101438, 33177, 22783, 109, 104167, 18359, 108466, 109816, 55925, 29833, 102662, 105880, 105371, 32179, 116726, 13, 105195, 13094, 67236, 105543, 109509, 103651, 106223, 34804, 111704, 222, 29726, 21028, 123495, 82068, 18359, 58935, 82068, 48936, 29833, 104816, 13, 103651, 106223, 34804, 111704, 222, 29726, 18918, 106725, 107198, 101760, 102077, 126530, 62060, 82068, 67525, 56773, 101464, 102621, 103170, 11, 57519, 101532, 18918, 113424, 101954, 96677, 64189, 20565, 126530, 127217, 108955, 103292, 75086, 103777, 124295, 109882, 18359, 101254, 110218, 115595, 35495, 74618, 27796, 58901, 116027, 13, 110347, 63718, 16969, 62398, 84618, 102275, 57575, 84656, 62060, 84656, 83719, 105292, 18918, 112734, 101574, 35495, 11, 24839, 102, 127139, 24486, 120014, 108699, 110154, 19954, 103651, 106223, 13094, 111704, 222, 29726, 18918, 108466, 101574, 104429, 103651, 106223, 104414, 32428, 49085, 122292, 56154, 57002, 87472, 19954, 111531, 111340, 627, 35864, 52688, 27796, 18, 25, 111068, 119402, 21028, 112601, 127798, 57575, 84656, 44005, 107573, 30446, 105411, 105138, 103843, 16969, 122298, 29854, 65621, 84656, 166, 122, 120, 13094, 102077, 118861, 106153, 124800, 108317, 13094, 108503, 127271, 102772, 101228, 124800, 24486, 107120, 101568, 13, 49508, 96318, 66610, 105851, 110955, 107573, 30446, 21028, 110946, 20565, 20565, 103298, 99, 34804, 118030, 105605, 117403, 68611, 25941, 107496, 58901, 111436, 18918, 116283, 101709, 22035, 115768, 23955, 108970, 18359, 102681, 42771, 24486, 107333, 104441, 18359, 127643, 87931, 102423, 13447, 13, 107573, 118162, 106460, 115954, 62398, 106869, 63375, 21028, 47419, 109814, 109816, 104193, 101482, 110110, 58368, 103373, 22035, 105365, 103894, 34804, 110473, 11, 124389, 49508, 65950, 119734, 106064, 105002, 42771, 104448, 90960, 169, 230, 108, 104441, 101193, 33177, 18359, 124157, 96102, 72747, 122877, 119068, 13, 84656, 54780, 104870, 102946, 18359, 109287, 101066, 16582, 106833, 51440, 127798, 125904, 101971, 103079, 34804, 74618, 110632, 119073, 11, 119734, 104374, 116338, 61816, 27796, 121856, 107054, 126175, 21028, 86503, 58232, 109644, 49011, 250, 102249, 18359, 38295, 116, 13447, 13, 35243, 45780, 52375, 101709, 49085, 106243, 13094, 118652, 104448, 86503, 112953, 114933, 73653, 21028, 120376, 19954, 103607, 110685, 34983, 74618, 63375, 13447, 382, 102953, 118162, 49508, 124689, 102201, 19954, 33229, 16969, 23955, 120916, 126344, 66610, 105851, 61415, 81673, 108280, 118355, 96677, 93292, 119357, 54780, 108280, 34983, 86351, 13447, 13, 96677, 93292, 119357, 49085, 107573, 30446, 81673, 96677, 112003, 112852, 17835, 23955, 108970, 95415, 65677, 77437, 65950, 113832, 26799, 108652, 41381, 35495, 107417, 34609, 117622, 114933, 34804, 124697, 21028, 72747, 22035, 19954, 100994, 103655, 118355, 108137, 13, 123106, 16969, 109562, 30426, 62398, 105940, 230, 18359, 113470, 101954, 109055, 119734, 107308, 37155, 84391, 17164, 238, 57575, 58935, 105316, 34983, 107802, 107308, 63199, 95, 32179, 107054, 117906, 13094, 112734, 125441, 13447, 13, 46810, 102662, 24486, 107573, 118162, 49508, 105880, 96270, 35495, 117892, 101429, 106064, 104685, 101103, 109287, 55421, 19954, 103659, 101103, 20565, 35495, 11, 86503, 33931, 105851, 18918, 97096, 169, 115594, 34983, 49508, 106001, 29833, 102835, 18359, 67890, 115061, 42771, 101203, 49508, 105880, 96270, 102612, 107213, 108239, 13, 29833, 102835, 95415, 107573, 118162, 96677, 93292, 119357, 18359, 119734, 119626, 62060, 101555, 17835, 107455, 121969, 382, 93917, 105851, 61415, 20565, 111519, 103777, 67890, 220, 868, 125085, 63207, 19954, 111068, 119402, 19954, 110110, 81673, 107573, 30446, 81673, 63207, 103777, 13447, 13, 114933, 34804, 114489, 102772, 108280, 105711, 101528, 13, 66610, 105851, 110955, 65677, 109957, 111519, 103777, 110005, 49508, 105880, 108652, 102275, 119225, 18918, 55000, 21121, 126308, 101574, 104429, 11, 113857, 49508, 106001, 104870, 102946, 103131, 18359, 104685, 105771, 108239, 13, 55925, 113578, 102407, 34804, 107573, 118162, 105411, 58901, 104323, 18918, 67236, 101203, 65677, 106064, 104293, 101532, 35495, 74618, 101151, 13447, 13, 47419, 48424, 114333, 101254, 27797, 116039, 124389, 107849, 30381, 35243, 45780, 230, 120, 43139, 97096, 66965, 52976, 13, 102786, 101066, 101709, 49085, 102888, 103079, 18359, 107758, 103097, 35495, 107573, 30446, 20565, 105164, 41953, 57575, 61816, 35495, 107205, 124742, 19954, 104870, 102946, 103131, 102888, 103079, 19954, 102786, 29102, 102893, 47419, 124295, 11, 107573, 118162, 78453, 107801, 18359, 105411, 58901, 120889, 54596, 108, 20565, 104448, 102704, 103886, 105164, 115096, 59877, 52976, 382, 93917, 105851, 110955, 102888, 103079, 57575, 123651, 120376, 34804, 102467, 73653, 88525, 116154, 35495, 107573, 30446, 21028, 84656, 72043, 104841, 54780, 105613, 107621, 109644, 106915, 34804, 108158, 93131, 90335, 26799, 13094, 105078, 121803, 21028, 122891, 18359, 108712, 32179, 90759, 109012, 35495, 107034, 105198, 52976, 13, 109296, 34804, 105164, 101096, 18359, 119215, 32179, 107573, 30446, 107988, 49085, 102519, 78453, 107801, 13094, 108499, 35495, 127271, 19954, 101228, 124800, 118355, 107573, 30446, 107988, 106915, 13094, 119734, 106064, 108652, 41381, 109509, 102519, 103607, 100660, 16582, 105954, 101264, 52976, 13, 107573, 118162, 66610, 105851, 61415, 21028, 101254, 106113, 19954, 109882, 13094, 126256, 13094, 102077, 11, 47419, 48424, 114333, 123651, 120376, 21028, 56069, 109208, 102467, 120861, 66610, 105851, 61415, 105771, 113424, 54059, 44852, 247, 58126, 102888, 103079, 34804, 106467, 55055, 34983, 86351, 13447, 13, 103405, 122042, 102888, 103079, 57575, 11, 96677, 93292, 119357, 13094, 107034, 32428, 43139, 74618, 81673, 107573, 30446, 20565, 47419, 101528, 35495, 39623, 117, 48424, 118768, 11, 66610, 105851, 61415, 21028, 47419, 48424, 114333, 66610, 105851, 61415, 18918, 111519, 61415, 108438, 101003, 49085, 24486, 110005, 113531, 96677, 93292, 119357, 113743, 116324, 116283, 101709, 101203, 58952, 108185, 125337, 106943, 34983, 86351, 13447, 13, 83719, 100654, 102888, 103079, 34804, 66610, 105851, 61415, 20565, 107746, 44690, 52976, 13, 66610, 105851, 110955, 107573, 30446, 102244, 47419, 48424, 115296, 104219, 102079, 24486, 127224, 18359, 33229, 54780, 118768, 107573, 118162, 91767, 110110, 101151, 117132, 13447, 382, 116964, 107308, 66610, 105851, 61415, 21028, 104441, 43139, 36609, 16969, 105605, 86503, 112953, 23955, 102517, 21028, 99969, 36092, 117, 18359, 108239, 13, 66610, 105851, 61415, 20565, 104441, 43139, 115115, 81673, 107573, 30446, 73653, 109562, 30426, 86503, 84065, 13447, 13, 66610, 105851, 110955, 105195, 123402, 103402, 246, 29102, 101203, 11, 119734, 106064, 103894, 97237, 114038, 103659, 101103, 112852, 110661, 111590, 121469, 101528, 35495, 116844, 52976, 13, 107573, 30446, 49085, 96677, 112003, 112852, 17835, 105195, 123402, 107802, 101136, 35495, 66610, 105851, 61415, 81673, 99969, 36092, 117, 52976, 13, 119734, 106064, 64432, 61394, 36609, 103373, 105453, 66610, 105851, 61415, 102244, 107573, 118162, 113832, 26799, 102484, 54059, 109077, 107573, 84136, 49508, 115467, 110347, 63718, 27796, 73653, 64432, 105771, 108239, 13, 66610, 105851, 61415, 20565, 120353, 29102, 105010, 108916, 19954, 74177, 100968, 101203, 111128, 112655, 64432, 13094, 106888, 35495, 100570, 119, 35495, 11, 107573, 118162, 49208, 233, 22035, 105954, 108386, 52976, 627, 35864, 52688, 27796, 19, 25, 116816, 121712, 53400, 111915, 122042, 101412, 107739, 25493, 239, 25941, 105138, 86422, 111636, 84696, 101760, 103170, 11, 330, 21121, 102193, 103405, 60861, 112542, 109644, 120461, 101139, 84065, 107335, 64432, 32428, 1, 101480, 167, 127802, 102249, 49508, 124991, 101412, 109317, 111590, 116283, 113048, 111340, 13, 220, 2550, 15, 100392, 67945, 75984, 103618, 58368, 122468, 123094, 101254, 35495, 100508, 26799, 101574, 101954, 66610, 22035, 108523, 54780, 101012, 112, 80104, 101139, 119868, 105297, 125422, 124695, 43139, 127614, 24486, 103405, 122042, 101412, 114038, 101480, 167, 127802, 102249, 19954, 105701, 102423, 49508, 21121, 32428, 111590, 103745, 61394, 118436, 13, 15922, 86422, 56154, 99901, 49508, 111459, 49508, 85767, 119420, 102467, 55430, 101607, 43139, 116283, 113048, 106872, 35495, 120878, 44690, 78453, 67945, 16969, 220, 8258, 15, 100392, 106687, 118408, 30381, 33943, 112039, 13, 4815, 4468, 24, 100392, 220, 22, 100551, 220, 22, 33177, 366, 120463, 25941, 106413, 80307, 45780, 225, 222, 29726, 29102, 111368, 112, 29, 19954, 102326, 102423, 55216, 56154, 19954, 101787, 108302, 111915, 122042, 101412, 107739, 121712, 65219, 26799, 100711, 26799, 105605, 93917, 53400, 108137, 11, 49508, 21121, 13447, 11, 57519, 102546, 119504, 364, 44690, 32428, 6, 101568, 18918, 103405, 35495, 110709, 108955, 13094, 112734, 32179, 22035, 21121, 94821, 101528, 35495, 108239, 13, 101412, 107739, 75984, 103618, 58368, 122468, 56773, 101412, 102199, 104554, 21028, 62398, 101604, 101886, 106943, 100654, 19954, 65677, 106064, 107144, 101760, 35495, 111323, 113156, 100392, 63375, 104167, 101438, 17835, 59777, 106647, 104519, 234, 113631, 111031, 25941, 106413, 19954, 33229, 16969, 115888, 20565, 32428, 23955, 101738, 350, 13, 100487, 123, 116031, 13094, 59877, 44966, 101528, 13, 108542, 106788, 102772, 111068, 119402, 21028, 115888, 20565, 32428, 58083, 58368, 105078, 30446, 118861, 65950, 61394, 102244, 112633, 32179, 14705, 242, 35495, 11, 55925, 107333, 103551, 111530, 21028, 104652, 101482, 34804, 111304, 49085, 55170, 84065, 13447, 13, 122964, 111031, 25941, 106413, 80307, 45780, 225, 222, 29726, 29102, 111368, 112, 107031, 102464, 57390, 103778, 13094, 104670, 120669, 33943, 238, 116324, 107034, 80732, 67525, 106958, 125693, 86351, 101412, 51440, 18918, 107364, 16969, 102745, 102244, 220, 605, 11, 931, 104684, 61394, 21028, 59134, 101136, 18359, 56773, 103373, 105954, 3396, 104247, 13447, 198, 35864, 52688, 27796, 20, 25, 2652, 125519, 107872, 101974, 198, 75265, 117, 120226, 66653, 45780, 223, 105, 17835, 127055, 27796, 106001, 101139, 107194, 254, 21028, 101003, 86157, 21028, 59134, 102130, 113211, 112784, 107872, 101974, 16969, 118974, 101930, 21028, 74177, 102914, 18918, 106359, 83290, 116453, 108466, 34804, 110257, 108362, 124784, 106327, 126256, 13094, 101103, 16969, 101480, 27796, 94772, 106318, 101555, 18918, 120693, 91786, 13, 49706, 103284, 16969, 108466, 34804, 110257, 126276, 21028, 118562, 115253, 19954, 122041, 108503, 74177, 41381, 93292, 81673, 110979, 71682, 11, 29833, 40011, 236, 34804, 105797, 100933, 30446, 65950, 17835, 114702, 53400, 125450, 108362, 124784, 121599, 122659, 120226, 56773, 101607, 105880, 100994, 101796, 19954, 105136, 101, 58901, 107973, 65621, 102027, 101948, 32428, 101568, 382, 26, 79225, 101711, 66965, 79053, 52072, 41953, 320, 124333, 49085, 340, 42529, 119504, 93851, 105115, 26799, 13, 100994, 101711, 66965, 79053, 52072, 124788, 110187, 102745, 114026, 116023, 84377, 36439, 102077, 101228, 24140, 73653, 13094, 126530, 104670, 24814, 20541, 35495, 101264, 48936, 29833, 91786, 13, 122659, 120226, 110714, 109017, 18359, 111519, 110230, 104448, 108154, 122659, 120155, 56773, 21028, 101413, 232, 58901, 93851, 108168, 101360, 91786, 382, 26, 44690, 66338, 102835, 56154, 102066, 30446, 27433, 230, 198, 75265, 117, 120226, 96677, 109218, 101228, 66338, 102835, 125166, 26799, 66653, 45780, 223, 105, 17835, 116031, 27796, 124566, 21028, 101603, 126119, 32428, 102066, 30446, 27433, 230, 34804, 120958, 25941, 100711, 18359, 21028, 101604, 105678, 65677, 49706, 100711, 24486, 74177, 103097, 107725, 57575, 106673, 93292, 108859, 104657, 35495, 91786, 13, 108154, 127002, 21028, 106243, 18359, 112655, 116453, 75086, 54289, 18918, 102293, 64356, 101360, 101228, 66338, 48936, 72208, 32428, 111010, 106024, 127369, 99458, 56154, 101360, 91786, 382, 26, 67945, 100711, 101661, 56154, 92143, 101974, 25941, 198, 103415, 66965, 21028, 92143, 101974, 119524, 119873, 123360, 66653, 45780, 223, 105, 17835, 116031, 27796, 124566, 18359, 110154, 40275, 120, 106745, 41820, 118355, 49508, 102199, 67218, 102, 29726, 32428, 118974, 101930, 21028, 67890, 67218, 94, 13094, 21028, 120138, 114699, 26799, 72043, 62398, 125656, 23955, 100904, 13, 109296, 21028, 92143, 101974, 119524, 112219, 51440, 101974, 102132, 19954, 104657, 104448, 127388, 122741, 36630, 77535, 105880, 29833, 103304, 119995, 35495, 55925, 109017, 19954, 33229, 16969, 127388, 56154, 106001, 124695, 50643, 57575, 110714, 109521, 84656, 93292, 106064, 105002, 115202, 117097, 117686, 102704, 49085, 106287, 21028, 127388, 116688, 120693, 91786, 382, 26, 103430, 111614, 92143, 111932, 102913, 25941, 198, 101954, 101412, 100968, 87097, 108307, 21028, 56069, 117819, 38295, 63718, 104554, 21028, 33229, 61415, 94772, 121471, 32428, 118861, 111614, 92143, 111932, 102913, 119524, 57519, 102546, 103684, 57519, 56154, 105880, 10997, 109147, 103304, 119995, 35495, 91786, 13, 76628, 101347, 104182, 119873, 49085, 81673, 116443, 107205, 72208, 19954, 65677, 110616, 107094, 54059, 92143, 111932, 102913, 119524, 109997, 23955, 77535, 18359, 117028, 63207, 110955, 112700, 102745, 107988, 49085, 123151, 116501, 105453, 107387, 107034, 80732, 16582, 113348, 102058, 29854, 101360, 91786, 382, 26, 76242, 45780, 223, 105, 17835, 127055, 27796, 198, 125519, 107872, 101974, 21028, 74177, 84065, 124230, 121803, 103402, 239, 100711, 101661, 18359, 108533, 16969, 95303, 55055, 21028, 127388, 56154, 101568, 13, 113469, 115968, 101603, 108970, 18359, 115809, 19954, 113470, 35495, 112767, 43139, 127388, 21028, 122298, 116688, 119215, 34804, 127388, 125166, 21121, 109644, 112784, 107872, 101974, 21028, 104167, 104366, 18359, 118502, 108573, 57002, 57575, 56773, 32428, 79225, 32428, 126697, 32179, 18918, 106213, 102612, 60798, 51796, 58901, 114450, 112, 120591, 101709, 16969, 59777, 101438, 101568, 128009, 128006, 882, 128007, 198, 102766, 102525, 101974, 100968, 20565, 110400, 13094, 107382, 111323, 23955, 127055, 100711, 16582, 57575, 107417, 101954, 111915, 122042, 57519, 105292, 16969, 118947, 113743, 61415, 30, 128009, 128006, 78191, 128007, 198, 109070, 78326, 99901, 102772, 118003, 102525, 101974, 100968, 20565, 110400, 13094, 107382, 111323, 23955, 127055, 100711, 16582, 57575, 107417, 101954, 111915, 122042, 57519, 105292, 18918, 107364, 18359, 29833, 120078, 13, 128009]\n"
     ]
    }
   ],
   "source": [
    "print('입력에 대한 정수 인코딩 결과:')\n",
    "print(batch[\"input_ids\"][0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "377f9f21-5caa-417c-b549-cae18348809e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "input_ids 디코딩 결과:\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "당신은 검색 결과를 바탕으로 질문에 답변해야 합니다.\n",
      "\n",
      "다음의 지시사항을 따르십시오.\n",
      "1. 질문과 검색 결과를 바탕으로 답변하십시오.\n",
      "2. 검색 결과에 없는 내용을 답변하려고 하지 마십시오.\n",
      "3. 질문에 대한 답이 검색 결과에 없다면 검색 결과에는 \"해당 질문~에 대한 내용이 없습니다.\" 라고 답변하십시오.\n",
      "4. 답변할 때 특정 문서를 참고하여 문장 또는 문단을 작성했다면 뒤에 출처는 이중 리스트로 해당 문서 번호를 남기십시오. 예를 들어서 특정 문장이나 문단을 1번 문서에서 인용했다면 뒤에 [[ref1]]이라고 기재하십시오.\n",
      "5. 예를 들어서 특정 문장이나 문단을 1번 문서와 5번 문서에서 동시에 인용했다면 뒤에 [[ref1]], [[ref5]]이라고 기재하십시오.\n",
      "6. 최대한 다수의 문서를 인용하여 답변하십시오.\n",
      "\n",
      "검색 결과:\n",
      "-----\n",
      "문서1: 콘코바르는 결국 죽게 되는데, 그 곡절은 이러하다. 라긴의 왕 메스 게그러의 뇌를 굳힌 겻을 울라의 코날이 전리품으로 가지고 있었는데, 코나크타의 전사 케트 막 마가크가 이를 훔쳐갔다. 그리고 케트는 무릿매로 메스 게그러의 뇌를 던져 콘코바르의 머리를 맞추었고, 메스 게그러의 뇌가 콘코바르의 머리통 깊숙히 박혀 버렸다. 이 일이 일어난 곳은 우르카르(Urchair)의 발러 아흐(Baile Ath), 곧 오늘날의 웨스트미스 주 호르셀리프라고 한다. 콘코바르의 의사들은 이 이물질을 제거할 수 없었고, 상처를 봉합만 한 뒤 왕에게 흥분하지 않으면 생명을 유지할 수 있다고 말했다. 7년이 평화롭게 흘러간 뒤 콘코바르는 그리스도가 죽었다는 소식을 듣게 되어 분노했고, 뇌가 터져 죽었다. 머리가 터진 자리에서 뿜어져나온 피의 세례를 받은 결과 그는 기독교인이 되었고 그 영혼은 천국으로 갔다. 콘코바르의 죽음에 관한 이 기록은 매우 얄팍한 기독교화가 이루어져 있는데, 한편 노르드 신화의 토르가 흐룽그니르와 싸우다 머리에 숫돌이 박힌 이야기와 유사한 점이 있다. 어쩌면 두 이야기는 하나의 기원을 공유하거나 또는 바이킹이 에린에 영향을 미치던 시기(노르드-게일)에 수입된 것일 수도 있다.\n",
      "\n",
      "울라인들은 아직도 코나크타에 망명 중이던 콘코바르의 아들 코르막 콘드 롱가스를 왕으로 추대하기 위해 초빙했는데, 이멘마하로 돌아오는 길에 코르막은 기아스를 어기게 되었고 다 코카(Da Choca) 여관에 묵던 중에 습격당해 피살당했다. 이에 코날 케르나크가 콘코바르의 다른 아들 쿠스라드 멘드 마하(Cúscraid Mend Macha)를 왕으로 추대했다.\n",
      "-----\n",
      "문서2: 케트 막 마가크(Cet mac Mágach)는 아일랜드 신화의 얼스터 대계에 등장하는 인물이다. 코나크타의 전사로, 울라의 코날 케르나크의 적수이다.\n",
      "\n",
      "어떤 전승들에서는 케트가 코날의 어머니 핀드코엠과 남매지간, 코날과는 숙질간이라고도 한다.\n",
      "\n",
      "라긴 사람 막 다 호의 집에서 연회가 벌어졌을 때, 코나크타와 울라의 여러 전사들이 쿠라드미르를 놓고 각자의 업적을 자랑하며 다투었다. 케트는 전사들 각각을 자신이 어떻게 이겼는지 들먹이며 그들 모두의 입을 다물게 만들었다. 케트가 쿠라드미르를 가져가려는 순간 코날 케르나크가 도착했다. 코날은 자신이 케트보다 우위에 있다고 주장했고, 케트는 패배를 인정했다. 그러나 자신의 동생 아늘룬이 있었다면 그가 코날의 우위에 있었을 것이라고 주장했다. 그러자 코날은 방금 잘라온 아늘룬의 머리를 케트에게 던져주는 것으로 응수했다. \n",
      "\n",
      "케트는 울라의 왕 콘코바르 막 네사를 죽였는데, 그 이야기는 이러하다. 코날이 라긴의 왕 메스 게그러를 죽이고 그 뇌를 굳힌 것을 트로피삼아 차고 다녔는데, 케트가 그것을 훔쳐다가 무릿매로 던져 콘코바르의 머리통에 파묻었다. 콘코바르의 의사들은 왕을 죽이지 않는 이상 이 이물질을 빼낼 방법을 찾지 못했다. 그래서 대충 봉합한 뒤 왕에게 지나치게 흥분하지 않는다면 목숨을 부지할 수 있다고 말했다. 7년이 평화롭게 흘러간 끝에 콘코바르는 그리스도가 죽었다는 소식을 듣게 되었다. 그는 분노했고, 그 바람에 뇌가 터져 죽었다.\n",
      "\n",
      "어느 겨울날 케트가 울라로 습격을 나가 울라 남자 스물일곱 명을 죽이고 그 수급들을 베어갔다. 눈이 내렸기에 코날은 케트의 흔적을 추적할 수 있었다. 코날은 케트를 따라잡았지만 그를 대적하기 주저했는데, 전차를 몰던 마부가 그를 겁쟁이라 비난하자 마음을 고쳐먹고 나서게 되었다. 둘이는 한 여울에서 일 대 일 결투를 벌였고, 격렬한 싸움 끝에 코날이 케트를 죽였으며 코날 본인도 빈사상태에 빠졌다.\n",
      "-----\n",
      "문서3: 뉴욕의 광고 회사에서 일하는 테드 크레이머는 능력 있는 일꾼이지만 워커홀릭이어서 가정에는 소홀한 가장이다. 아내 조애나는 테드의 귀가가 늦은 어느 날 갑작스럽게 이유를 밝히지 않고 이혼을 통보한 뒤 집을 나가 버린다. 테드는 애써 한순간의 변덕이고 금방 돌아오겠지 하는 생각은 하지만, 곧 아들 빌리를 돌보면서 서툰 집안일을 해야 할 처지가 된다. 일과 양육을 병행하느라 회사에서의 평판은 나빠지고, 빌리는 계속 해서 이어지는 엄마의 부재 때문에 짜증을 낸다. 다행히도 시간이 지나면서 부자는 둘만의 생활에 적응해 나간다.\n",
      "\n",
      "테드는 아랫집에 사는 이웃이자 조애나와 친했던 마거릿과 친해진다. 마거릿도 테드와 마찬가지로 이혼 후 자식들 혼자 키우고 있었으므로 둘은 서로의 처지에 공감했던 것이다. 하루는 잠시 한눈을 팔던 사이 빌리가 정글짐에서 추락해 머리가 찢어지는 사건이 벌어진다. 위급한 테드는 아들을 안고 먼 거리를 달려 병원에 데려가고, 부성애를 발휘해 아들의 수술을 지켜보며 아들을 안심케 한다. 수술 후 테드는 마거릿을 빌리의 대모로 삼는다.\n",
      "\n",
      "조애나가 떠난 지 15개월 만에 뉴욕에 돌아와 테드와 만난다. 둘은 처음에는 친밀했다. 조애나는 자기가 떠난 것은 아들을 키울 준비를 하기 위해서였으며, 이제 아들의 양육권을 달라고 한다. 그 말을 들은 테드는 크게 화를 내며 자리를 박차고 나선다. 변호사가 고용되고 곧 법정 다툼으로 발전한다. 불행히도 재판을 앞두고 테드가 직장에서 해고되는 바람에 양육권 재판에 불리하게 변하자, 테드는 연봉을 크게 낮춰가면서까지 새 직장을 구한다.\n",
      "\n",
      "조애나는 재판에서 결혼 생활은 원만하지 않았고 테드의 일 중독과 편견 때문에 자신은 패션디자이너로서의 꿈을 접어야 했다고 증언한다. 지금은 직업을 얻어 테드보다도 더 연봉이 높고 가정에 소홀했던 테드보다 자신이 빌리를 키우기에 더 적합하다고 말한다. 테드는 조애나의 고백에 마음이 움직이지만, 변호사가 결혼 생활의 파탄 원인은 조애나라고 몰아붙여 재판은 치열해진다. 두 번째 재판에서, 마거릿이 증인으로 나와 테드가 변했다고 옹호하지만, 조애나의 변호사가 조애나를 떠나도록 유도한 것은 바로 마거릿이었음을 밝히며 설득력이 약해진다. 결국 재판은 조애나가 승소한다. 조애나는 테드에게 변호사의 과격한 행동을 사과하지만 테드는 이미 돌아선 상태다.\n",
      "\n",
      "빌리가 조애나의 집으로 가는 날 부자는 이별의 포옹을 한다. 조애나가 집으로 찾아와 테드만 잠시 부른다. 조애나는 눈물을 흘리며, 빌리를 생각해서라도 데려가지 않는 것으로 결정했다고 이야기한다. 테드도 마찬가지로 눈물을 머금고 조애나와 포옹한다. 빌리를 보러 가겠다는 조애나에게 테드는 혼자 남아 있을 테니 아들과 둘이서만 보라고 한다. 조애나가 엘리베이터에 오르며 오늘 어떻게 보이냐고 묻고, 테드는 멋지다고 답한다.\n",
      "-----\n",
      "문서4: 이렇게 발견된 첫 번째 미라는 엑스레이 검사를 받았는데, \"기형 두개골 때문에 작은 어른처럼 보인\" 무뇌증 아기의 미라인 것으로 밝혀졌다. 1990년대 와이오밍대의 고고학자였던 조지 길과 덴버 어린이병원이 공동으로 조사한 두 번째 미라도 무뇌증에 걸린 아기인 것으로 드러났다. DNA 검사 결과 아기는 아메리카 원주민으로 밝혀졌고 탄소 연대는 1700년대로 측정됐다. \n",
      "\n",
      "1979년 7월 7일 <캐스퍼 스타트리뷴>에 실린 기사에 의하면 첫 번째 미라는 발견되자마자 날조된 것이다, 아기다, 전설상의 '소인'이다를 두고 논쟁이 벌어지기 시작했다고 한다. 미라는 와이오밍 주 미티츠의 한 동네 약국에 자리를 잡았고 이후 몇년간 명물로 인기를 끌다가 캐스퍼에 사는 사업가인 이반 T. 굿맨이 구입했다. 그런 다음에는 뉴욕의 사업가인 리오너드 워들러에게 넘어갔고, 그 뒤부터 현재의 행방은 아무도 모른다. 당시 캐스퍼 스타트리뷴에서는 진화론이 잘못됐음을 증명하기 위해 사라진 미라를 찾는 사람에게 10,000달러의 상금을 주겠다고 썼다\n",
      "-----\n",
      "문서5: ;헤쿠바\n",
      "녹스의 네크로멘서들의 어둠의 유산의 상속자인 헤쿠바는 망각의 오브를 이용하여 새로운 죽은자의 군대를 다시 움직이려는 무서운 음모를 가지고 있다.그녀는 죽은자의 땅의 폐허에 숨어서 오우거와 좀비, 수많은 언데드들로 구성된 그녀의 군대를 보내 녹스의 주민들을 공포에 떨게 하고 있는 장본인이다.\n",
      "\n",
      ";공중전함 함장 (잔도)\n",
      "세상의 관망자. 공중전함 함장은 많은 사람들에게 알려져 있지만 소수만이 그를 잘 안다고 말할 수 있다. 녹스의 여러곳을 떠돌면서 그는 녹스를 주의 깊게 관찰하고 있다.\n",
      "\n",
      ";소환술사 알드윈\n",
      "녹스의 마스터 소환술사이자 네크로맨서 전쟁의 영웅인 알드윈은 익스마을의 동쪽 자그마한 오두막에서 은거하며 살고 있다. 그는 대부분의 시간을 어떻게 새로운 비스트를 매료하고 소환할 것인지를 연구하는데 종사하고 있다.\n",
      "\n",
      ";대마법사 호바스\n",
      "예전의 호바스는 잔도가 네크로맨서 전쟁을 끝낼때 사용했던 아티팩트인 망각의 지팡이의 주요 제작자 중 한사람 이었다. 지금의 호바스는 갈라바 성에 살면서 마법 견습생들을 수련시키고 그곳에 사는 마법사들의 공동체에서 여러 가지 일거리를 돌보고 있으며 아직까지도 최고의 마법력을 가지고 있다.\n",
      "\n",
      ";워로드 호렌더스\n",
      "던 미르 요새의 파이어 나이츠의 사나운 감독인 워로드 호렌더스는 전설적인 전사들을 훈련시키고 있다. 필연적으로 잔도와 비교되는 것에 자극받아 호렌더스는 그의 이생을 그가 만나는 어떤 사람보다도 뛰어나다는 것을 증명하려고 노력하고 있다.\n",
      "\n",
      ";네크로멘서\n",
      "헤쿠바의 오른팔로서 흑마법을 쓰는 계열의 마법사이다. 그러나 자신의 영혼을 악에 팔고 그것으로 마법의 능력을 얻은 마법사이기 때문에 헤쿠바의 명령을 받아 게임상에서 주인공인 플레이어를 심심치 않게 괴롭히는 인물이다<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "콘코바르가 왕이 된 이후 이멘마하에서 있었던 첫 번째 전투는 무엇이었나?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "검색 결과에는 콘코바르가 왕이 된 이후 이멘마하에서 있었던 첫 번째 전투를 찾을 수 없습니다.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "# 디코딩된 input_ids 출력\n",
    "decoded_text = tokenizer.decode(\n",
    "    batch[\"input_ids\"][0].tolist(),\n",
    "    skip_special_tokens=False,\n",
    "    clean_up_tokenization_spaces=False\n",
    ")\n",
    "\n",
    "print(\"\\ninput_ids 디코딩 결과:\")\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7c3cfef-655b-451d-9fa6-599c0397e4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레이블에 대한 정수 인코딩 결과:\n",
      "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 109070, 78326, 99901, 102772, 118003, 102525, 101974, 100968, 20565, 110400, 13094, 107382, 111323, 23955, 127055, 100711, 16582, 57575, 107417, 101954, 111915, 122042, 57519, 105292, 18918, 107364, 18359, 29833, 120078, 13, 128009]\n"
     ]
    }
   ],
   "source": [
    "print('레이블에 대한 정수 인코딩 결과:')\n",
    "print(batch[\"labels\"][0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82f7eaa4-3837-42de-a37b-8800da82462a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "labels 디코딩 결과 (-100 제외):\n",
      "검색 결과에는 콘코바르가 왕이 된 이후 이멘마하에서 있었던 첫 번째 전투를 찾을 수 없습니다.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "# -100이 아닌 부분만 골라 디코딩\n",
    "label_ids = [token_id for token_id in batch[\"labels\"][0].tolist() if token_id != -100]\n",
    "\n",
    "decoded_labels = tokenizer.decode(\n",
    "    label_ids,\n",
    "    skip_special_tokens=False,\n",
    "    clean_up_tokenization_spaces=False\n",
    ")\n",
    "\n",
    "print(\"\\nlabels 디코딩 결과 (-100 제외):\")\n",
    "print(decoded_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cbdb20-95a2-41e1-a63a-14f9f6765d6a",
   "metadata": {},
   "source": [
    "### input_ids와 labels는 어떻게 생성되는가?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cd6653-5097-4456-8a08-699687804632",
   "metadata": {},
   "source": [
    "\n",
    "LLM 학습에서 `input_ids`와 `labels`는 모델의 학습 목표에 따라 생성됩니다. 이를 예시 문장과 정수 인코딩을 통해 상세히 설명하겠습니다.\r\n",
    "\r\n",
    "예를 들어, 다음과 같은 대화 데이터를 모델이 학습해야 한다고 가정합니다.\r\n",
    "사용자가 `안녕하세요, 오늘 날씨는 어떤가요?`라고 물었고,\r\n",
    "모델은 `안녕하세요! 오늘 날씨는 맑고 화창합니다.`라고 응답해야 한다고 합시다.\r\n",
    "\r\n",
    "LLaMA 3에서는 다음과 같은 템플릿 구조를 사용합니다:\r\n",
    "\r\n",
    "`<|begin_of_text|><|start_header_id|>user<|end_header_id|>\r\n",
    "안녕하세요, 오늘 날씨는 어떤가요?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\r\n",
    "안녕하세요! 오늘 날씨는 맑고 화창합니다.<|eot_id|>`\r\n",
    "\r\n",
    "이 전체 텍스트는 토크나이저에 의해 정수 시퀀스로 변환됩니다. 예시로 단순화된 정수 시퀀스는 다음과 같다고 가정합니다:\r\n",
    "\r\n",
    "`input_ids = [1001, 2001, 3001, 4001, 5001, 6001, 7001, 1002, 1001, 8001, 9001, 1003, 2002]`\r\n",
    "\r\n",
    "여기서 모델이 예측해야 할 영역은 assistant의 응답 부분인\r\n",
    "`안녕하세요! 오늘 날씨는 맑고 화창합니다.`에 해당하는 토큰들입니다.\r\n",
    "따라서 `labels`는 다음과 같이 설정됩니다:\r\n",
    "\r\n",
    "`labels = [-100, -100, -100, -100, -100, -100, -100, -100, -100, 8001, 9001, 1003, 2002]`\r\n",
    "\r\n",
    "이처럼 `labels`는 모델의 출력이 필요한 영역만을 포함하고, 나머지 부분은 `-100`으로 채워져\r\n",
    "모델이 실제로 예측하고 오차를 계산해야 하는 대상(학습 대상)에서 제외됩니다.\r\n",
    "\r\n",
    "이를 통해 모델은 불필요한 입력 부분을 학습하지 않고, assnt 응답 부분에만 집중할 수 있습니다.\r\n",
    "\"\"\"\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d42c907-fb98-405a-9b90-5a3413199092",
   "metadata": {},
   "source": [
    "## 5. 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9ef86a9-8b8a-4aeb-809a-9d7babca9cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:283: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    max_seq_length=max_seq_length,  # 최대 시퀀스 길이 설정\n",
    "    train_dataset=train_dataset,\n",
    "    data_collator=collate_fn,\n",
    "    peft_config=peft_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1af87dc-5b07-4a0f-b922-cabf0ca549fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='285' max='285' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [285/285 31:23, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.858300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.634700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.512500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.490500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.470700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.428600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.402700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.477200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.391100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.341500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.365300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.357200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.342000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.348100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.375300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.354700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.375700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.387600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.377900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.242900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.309500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.286000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.255100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.315500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.354200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.258900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.254800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.304300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "# 학습 시작\n",
    "trainer.train()   # 모델이 자동으로 허브와 output_dir에 저장됨\n",
    "\n",
    "# 모델 저장\n",
    "trainer.save_model()   # 최종 모델을 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6f9d42-574a-4ad8-9327-7315d1a1269b",
   "metadata": {},
   "source": [
    "## 6. 테스트 데이터 준비\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795c2138-e4e5-4afb-a37d-ef8dd70b5f4c",
   "metadata": {},
   "source": [
    "실제 모델에 입력을 넣을 때에는 입력의 뒤에 '<|start_header_id|>assistant<|end_header_id|>\\n'가 부착되어서 넣는 것이 좋습니다. 그래야만 모델이 바로 답변을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "abb48dbc-646c-4a2d-ae1f-0ef824cae419",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_lst = []\n",
    "label_lst = []\n",
    "\n",
    "for messages in test_dataset[\"messages\"]:\n",
    "    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=False)\n",
    "    input = text.split('<|start_header_id|>assistant<|end_header_id|>\\n')[0] + '<|start_header_id|>assistant<|end_header_id|>\\n'\n",
    "    label = text.split('<|start_header_id|>assistant<|end_header_id|>\\n')[1].split('<|eot_id|>')[0]\n",
    "    prompt_lst.append(input)\n",
    "    label_lst.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "011e29f0-c6d9-4e90-9ebc-78a4f2ca9d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "당신은 검색 결과를 바탕으로 질문에 답변해야 합니다.\n",
      "\n",
      "다음의 지시사항을 따르십시오.\n",
      "1. 질문과 검색 결과를 바탕으로 답변하십시오.\n",
      "2. 검색 결과에 없는 내용을 답변하려고 하지 마십시오.\n",
      "3. 질문에 대한 답이 검색 결과에 없다면 검색 결과에는 \"해당 질문~에 대한 내용이 없습니다.\" 라고 답변하십시오.\n",
      "4. 답변할 때 특정 문서를 참고하여 문장 또는 문단을 작성했다면 뒤에 출처는 이중 리스트로 해당 문서 번호를 남기십시오. 예를 들어서 특정 문장이나 문단을 1번 문서에서 인용했다면 뒤에 [[ref1]]이라고 기재하십시오.\n",
      "5. 예를 들어서 특정 문장이나 문단을 1번 문서와 5번 문서에서 동시에 인용했다면 뒤에 [[ref1]], [[ref5]]이라고 기재하십시오.\n",
      "6. 최대한 다수의 문서를 인용하여 답변하십시오.\n",
      "\n",
      "검색 결과:\n",
      "-----\n",
      "문서1: 세계 3위 유통업체인 테스코가 중국에서 9년간 진행해온 독자사업을 포기했다고 텔레그래프가 11일 보도했다.테스코는 대신 중국 국영 화룬(華潤)기업과 합작법인을 설립하기로 했다. 테스코는 중국 내 121개 매장을 이 합작법인에 넘기고 지분 20%를 받을 계획이다. 이번 합작은 양사 간 윈윈으로 보이지만 사실상 테스코가 중국 시장에서 백기를 든 것이라고 로이터통신이 지적했다. 테스코는 올 들어 중국 내 매출이 4.9% 하락하는 등 중국 시장 공략에 어려움을 겪어왔다. 이 회사는 올해 미국, 지난해에는 일본 시장에서 철수키로 결정했으며 당분간 모국인 영국 투자에 집중할 계획이다.화룬은 “합작법인을 통해 단일 브랜드로 대형마트와 슈퍼마켓, 편의점 등 다양한 사업을 벌일 것”이라고 밝혔다. 화룬그룹은 중국 본토와 홍콩에 매장 3000개를 운영하고 있는 중국 최대 유통업체다.중국에서 고전하고 있는 다국적 유통업체는 테스코만이 아니다. 올해 초에는 독일 유통업체 메트로가 중국 내 가전제품 사업부를 철수시켰고, 사무용품 전문업체 홈디포도 중국 내 7개 대형 매장의 문을 닫았다. 월마트와 까르푸는 아직 공격적인 매장 확장 계획을 발표하고 있지만 수익성 악화로 고전하고 있다. 물류비용 부담이 크고, 저렴한 가격으로 무장한 현지 업체들과의 경쟁이 치열하기 때문이다. 유로모니터에 따르면 현재 중국 소매유통시장에서는 대만·프랑스 합작업체인 선아트가 13.6%의 시장점유율로 1위를 달리고 있다. 화룬그룹과 월마트가 각각 10.9%, 까르푸가 6.9%, 테스코가 2.4%의 점유율을 기록하고 있다.\n",
      "-----\n",
      "문서2: 국무총리 후보자 두 명의 연쇄 낙마에 이어 일부 장관 후보자들마저 자질 논란에 휩싸이면서 야당은 물론 여당에서도 반대 기류가 강해지자 박근혜 대통령이 선택의 기로에 몰리고 있다. 2기 내각 교체 명단을 발표한 지 한 달이 지나도록 내각이 정상 출범하지 못한 데 따른 국정공백을 막기 위해 임명을 강행할 수도 있지만, 그럴 경우 어렵사리 마련된 여의도와의 ‘소통정치’ 무드에 찬물을 끼얹을 수도 있다.국회 교육문화체육관광위원회는 11일 전체회의를 열어 김명수 부총리 겸 교육부 장관 후보자와 정성근 문화체육관광부 장관 후보자에 대한 인사청문보고서 채택을 논의할 예정이었지만, 야당이 회의 참석을 거부해 채택이 불발됐다. 안전행정위원회도 이날 정종섭 안전행정부 장관 후보자 청문보고서를 채택하려 했지만 야당 의원들의 반대로 무산됐다.여권 관계자는 “야당이 회의 자체를 거부해 강제적으로 밀어붙일 수 없는 상황”이라며 “박 대통령이 임명을 강행하든지, 아니면 지명을 철회하든지, 이것도 아니면 후보자가 스스로 사퇴하든지 하는 수밖에 없다”고 말했다.청와대와 여권에 따르면 세 명의 후보 가운데 논문 표절과 부적절한 주식거래 의혹을 받고 있는 김 후보자는 여당 내에서도 ‘부적합’이란 기류가 강해 자진사퇴 쪽으로 가닥이 잡힌 것으로 전해졌다. 여당 지도부는 이미 ‘김명수 불가’ 입장을 청와대에 전달했고, 박 대통령도 전날 여야 원내대표와의 회동에서 야당의 재고 요청에 “참고하겠다”고 한 만큼 김 후보자에 대해선 사실상 마음을 접은 것으로 알려졌다. 때문에 김 후보자는 주말을 전후로 자진사퇴 입장을 밝힐 것이란 게 유력한 관측이다.청문회에서 위증 논란을 일으킨 정성근 후보자에 대해서도 막판에 여권 내 기류가 심상치 않게 흐르고 있다. 여당 교문위 관계자는 “자진사퇴 수순으로 가는 김 후보자보다 정 후보자가 더 문제라는 의견이 여당 내에서도 많아지고 있다”고 했다. 이 때문에 당초 ‘김명수 임명 불가, 정성근 임명 강행’으로 가닥이 잡히던 청와대 내 기류도 바뀔 가능성이 거론된다. 청와대 일각에선 야당의 요구대로 세 명의 장관을 지명 철회할 경우 장기간 국정공백이 불가피하다는 점을 들어 정성근-정종섭 후보자는 임명을 강행하자는 강경론도 제기되는 것으로 알려졌다.이들 장관 후보자의 거취가 불확실해지면서 2기 내각 출범 시기도 더 늦춰질 공산이 커졌다. 청와대는 청문 보고서가 채택된 장관 후보자들에 대해서도 임명장 수여 시기를 미룰 방침이다. 이와 관련, 민경욱 청와대 대변인은 “청문 보고서가 채택된 후보자도 있고, 그렇지 못한 후보자도 있는데 임명장 수여는 절차에 따라 한꺼번에 처리할 예정”이라고 말했다. 청문 보고서가 채택되지 않은 후보자에 대해 10일 이내에 국회에 보고서 채택을 다시 요청하는 절차를 밟은 후 일괄 임명하겠다는 것이다. 이 경우 낙마하는 장관을 제외하고 최경환 부총리 겸 기획재정부 장관 후보자 등 나머지 2기 내각 교체 멤버에 대해선 이르면 다음주 초 임명장을 수여할 것으로 예상된다.\n",
      "-----\n",
      "문서3: 1956년 11월 상순에 12명의 선수와 매니저 겸 스카우트인 아오키 이치조가 '후지무라 감독 퇴진 요구서'를 구단 오너인 노다 세이조에게 제출하였고 이를 스포츠 신문이 보도하는 형태로 표면화되었다. 12월 4일에 구단 측은 후지무라 감독의 유임과 퇴진 요구에 관여된 가네다 마사야스·사나다 주조의 두 선수는 다음 시즌에 재계약을 하지 않을 것이라고 발표했다. 그 후 구단 대표인 도자와시 가즈타카가 관계자와 협상을 계속한 결과 12월 25일에 구단은 가네다와의 재계약을 발표했다. 12월 30일에는 도자와시 구단 대표, 후지무라 감독, 가네다가 각각 성명서를 발표하고 사태가 일단락되었다.\n",
      "\n",
      "한신 구단의 역사인 《한신 타이거스 쇼와의 발자취》(1991년)과 마쓰키 겐지로의 《타이거스의 성장》(고분샤, 1973년)에는 발단 부분을 제외하고는 거의 상기에 가까운 내용이 적혀 있다. 당시 최초의 요구서로부터 스포츠 신문을 중심으로 한 보도가 과열되었으나 그것은 도자와시 구단 대표가 \"현실보다 기사가 훨씬 앞서 있다\"고 평했던 것과 같은 내용이다. 따라서 발단에서 해결에까지 이르는 과정에 대한 자세한 내용은 관계자와 후년의 증언에 의존할 수 밖에 없지만 이것도 증언자나 시기에 따라 반드시 일치하지 않는다. 다음 글에서는 그 차이도 근거로 하여 서술한다.\n",
      "-----\n",
      "문서4: 영국 최대 유통업체이자 홈플러스의 모기업인 테스코가 수익성이 낮은 43개 점포를 폐쇄하기로 하는 등 구조조정 계획을 내놓았다. 관심을 모았던 홈플러스 매각 여부에 대해서는 직접적으로 언급하지 않았다.테스코는 8일 점포 폐쇄와 자산 매각 계획 등을 담은 재무구조 개선 방안을 발표했다. 수익성이 낮은 점포 43곳의 문을 닫고 출점 예정이었던 49개 점포를 내지 않기로 했다. 그러나 홈플러스를 포함한 해외 사업 철수 계획은 밝히지 않았다. 데이브 루이스 테스코 회장은 “다른 결정을 내리기 전까지 해외 사업에 최선을 다할 것”이라고 말했다. 루이스 회장은 그러나 “재무상태가 건전하고 유동성이 있지만 오늘 발표가 끝은 아니다”고 말해 앞으로 해외 자산 매각을 추진할 수 있다는 여지를 남겼다.테스코는 지난해 상반기 분식회계로 영업이익을 2억5000만파운드(약 4120억원) 부풀린 사실이 드러나면서 창사 이래 최대 위기를 겪고 있다. 분식회계를 걷어낸 지난해 상반기 매출은 전년 동기보다 4.5% 줄었고 세후 이익은 92% 급감했다. 이 때문에 업계에서는 테스코가 위기를 극복하기 위해 홈플러스를 매각할 것이라는 관측이 있었다.\n",
      "-----\n",
      "문서5: 정태수 전 한보그룹 회장의 한보철강, 가구업체 라자가구의 송자현 전 대표 등 5억원 이상의 세금을 1년 넘게 체납한 개인과 법인 2401명의 명단이 공개됐다. 조세포탈죄로 기소돼 유죄판결을 받은 표순종 씨 등 2명과 234억원의 해외금융계좌를 신고하지 않은 업체 네오트리(대표 이경민)도 공개 명단에 올랐다.국세청은 26일 고액·상습 체납자 개인 1733명과 법인 665개 업체, 조세포탈범 2명, 해외금융계좌 신고의무 위반자 1명의 명단을 홈페이지(www.nts.go.kr)와 세무서 게시판을 통해 공개했다. 상습 체납자는 5억원 이상의 국세를 1년 이상 체납한 사람·법인이다. 국세청이 조세포탈범과 해외금융계좌 신고의무 위반자 명단을 공개한 것은 이번이 처음이다.개인 체납자 가운데는 도소매업체 에이치에스메탈스크랩의 대표인 이성구 씨가 종합소득세 등 424억원을 내지 않아 체납액 1위에 올랐다. 인터넷 도박사이트 운영자 이대근 씨와 라자의 송자현 전 대표는 부가세 등을 377억원, 233억원 각각 체납해 2, 3위에 올랐다. 법인 중에는 한보철강이 부가세 등 423억원을 납부하지 않아 체납액 1위에 올랐다. 1997년 회사 정리절차에 들어갔을 당시의 세금이지만 그동안 회생절차가 진행 중이어서 대상에서 제외됐다가 공개됐다.조세포탈범으로 명단이 공개된 김경철 씨는 창현금속이라는 회사를 설립해 부가세를 납부하지 않은 채 이 회사를 폐업하는 방식으로 8억7900만원을 포탈했다가 징역 2년, 벌금 23억원 판결을 받았다. 이경민 네오트리 대표는 해외계좌에 234억원을 보유하고도 신고하지 않았다가 국세청에 적발됐다.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "테스코가 출점을 취소한 총 개수<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt_lst[700])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "500cdfe5-8e8a-4ad9-a007-7181852c0997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "테스코는 수익성이 낮은 43개 점포를 폐쇄하고 출점 예정이었던 49개 점포의 출점을 취소하기로 결정했습니다. 따라서 테스코가 출점을 취소한 총 개수는 49개입니다 [[ref4]].\n"
     ]
    }
   ],
   "source": [
    "print(label_lst[700])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20845912-3ac4-4eaa-aaa5-edebd8cc5998",
   "metadata": {},
   "source": [
    "## 7. 파인튜닝 모델 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "414b57ea-e413-4421-9235-77c324c7fa2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/usr/local/lib/python3.10/dist-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "from transformers import  AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "04c57144-194c-4c97-883a-b8c601557f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcd8134662604d0b8e5da790ef30bac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FalconMambaForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'GraniteForCausalLM', 'GraniteMoeForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'LlamaForCausalLM', 'MambaForCausalLM', 'Mamba2ForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MllamaForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'NemotronForCausalLM', 'OlmoForCausalLM', 'OlmoeForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
     ]
    }
   ],
   "source": [
    "peft_model_id = \"llama-3-8b-rag-ko/checkpoint-285\"\n",
    "fine_tuned_model = AutoPeftModelForCausalLM.from_pretrained(peft_model_id, device_map=\"auto\", low_cpu_mem_usage=True, torch_dtype=torch.float16)\n",
    "pipe = pipeline(\"text-generation\", model=fine_tuned_model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "01c8cc1a-db7a-465e-8745-e8b0b340dfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "eos_token = tokenizer(\"<|eot_id|>\",add_special_tokens=False)[\"input_ids\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2e7517c0-f227-43f8-bf2e-55dfe965866b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_inference(pipe, prompt):\n",
    "    outputs = pipe(prompt, max_new_tokens=1024, eos_token_id=eos_token, do_sample=False)\n",
    "    return outputs[0]['generated_text'][len(prompt):].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ca694c28-77a9-48be-8192-e50faba386c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    response:\n",
      "테스코가 출점을 취소한 총 개수는 49개입니다. 테스코는 수익성이 낮은 점포 43개를 폐쇄하고, 출점 예정이었던 49개 점포의 출점을 내지 않기로 결정했습니다 [[ref4]].\n",
      "    label:\n",
      "\n",
      "테스코는 수익성이 낮은 43개 점포를 폐쇄하고 출점 예정이었던 49개 점포의 출점을 취소하기로 결정했습니다. 따라서 테스코가 출점을 취소한 총 개수는 49개입니다 [[ref4]].\n",
      "--------------------------------------------------\n",
      "    response:\n",
      "검찰 내부에서 더 선호하는 검사 드라마를 방영하는 방송국은 MBC입니다. SBS의 '펀치'보다 MBC의 '오만과 편견'에 대한 선호도가 높다고 언급되었습니다. '펀치'는 부패하고 탐욕이 강한 고위급 검사를 다루는 내용이 많아 부정적인 이미지를 부각시키는 반면, '오만과 편견'은 범죄와 치열하게 싸우는 긍정적인 모습을 보여주기 때문에 검찰 내부에서 더 선호된다고 설명되었습니다 [[ref2]].\n",
      "    label:\n",
      "\n",
      "검찰 내부에서 더 선호하는 검사 드라마를 방영하는 방송국은 MBC입니다. MBC의 드라마 '오만과 편견'이 검찰 내부에서 더 긍정적인 평가를 받고 있습니다. 이는 '펀치'가 검찰을 부정적으로 그리는 대목이 많은 반면, '오만과 편견'은 범죄와 치열하게 싸우는 비교적 긍정적인 모습을 보여주기 때문입니다. 검사들 사이에서는 '펀치'가 검찰에 대한 부정적인 사건을 짜깁기해 만든 것 같다는 의견이 있으며, '오만과 편견'은 현실과 동떨어진 느낌이 덜하다는 평가를 받고 있습니다 [[ref2]].\n",
      "--------------------------------------------------\n",
      "    response:\n",
      "정부와 FTA 논의 계획 중인 국가들을 포함하는 대륙은 중미와 남미입니다. 정부는 중미 7개국(과테말라, 엘살바도르, 온두라스, 니카라과, 코스타리카, 파나마, 에콰도르)과 FTA 협상을 개시할 계획이며, 중미경제통합상설사무국(SIECA) 소속 국가들과 에콰도르를 대상으로 협상을 시작할 예정입니다. 또한, 중미통합체제(SICA)와 메르코수르(MERCOSUR) 등 여러 경제 블록이 있는 중남미 지역에서 FTA 협상을 진행할 계획입니다. [[ref1]], [[ref4]]\n",
      "    label:\n",
      "\n",
      "6월에 정부와 FTA 논의를 계획 중인 국가들이 포함된 대륙은 주로 중미와 남미입니다. 구체적으로, 한국 정부는 중미경제통합상설사무국(SIECA) 소속 6개국(과테말라, 엘살바도르, 온두라스, 니카라과, 코스타리카, 파나마)과 에콰도르와의 FTA 협상을 6월 중 공식 선언할 계획입니다. 이들 국가들은 모두 중미와 남미에 위치해 있습니다 [[ref1]].\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for prompt, label in zip(prompt_lst[700:703], label_lst[700:703]):\n",
    "    # print(f\"    prompt:\\n{prompt}\")\n",
    "    print(f\"    response:\\n{test_inference(pipe, prompt)}\")\n",
    "    print(f\"    label:\\n{label}\")\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fe0d81-3c28-4106-bdc0-843be96cde9d",
   "metadata": {},
   "source": [
    "## 8. 기본 모델 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ffe02a36-c6fb-44fc-b26d-1b2259be5f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de7c561a020c4be78805dedbefba4cd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model_id = \"NCSOFT/Llama-VARCO-8B-Instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_id, device_map=\"auto\", low_cpu_mem_usage=True, torch_dtype=torch.float16)\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4116dc56-45c8-475e-b125-e0692c469de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    response:\n",
      "테스코가 출점을 취소한 총 개수는 49개입니다.\n",
      "\n",
      "문서4에 따르면 \"수익성이 낮은 점포 43곳의 문을 닫고 출점 예정이었던 49개 점포를 내지 않기로 했다\"라고 명시되어 있습니다.\n",
      "\n",
      "따라서 출점을 취소한 총 개수는 43(폐쇄된 점포 수) + 49(출점 예정이었으나 취소된 점포 수) = 92개가 아니라, 오류로 인해 43과 49를 더한 대신 49만을 언급하면 정확한 답이 됩니다. \n",
      "\n",
      "정확한 답변: 49개\n",
      "    label:\n",
      "\n",
      "테스코는 수익성이 낮은 43개 점포를 폐쇄하고 출점 예정이었던 49개 점포의 출점을 취소하기로 결정했습니다. 따라서 테스코가 출점을 취소한 총 개수는 49개입니다 [[ref4]].\n",
      "--------------------------------------------------\n",
      "    response:\n",
      "검찰 내부에서 더 선호하는 드라마에 대해 직접적으로 언급된 부분은 없습니다. \n",
      "\n",
      "하지만 문서2에 따르면 \"검사 A씨는 ‘TV에 검사가 자주 등장하고 가족들이 ‘진짜로 저래’라고 물어보는 터라 관심을 안 가질 수가 없다’며 ‘검사나 수사관끼리 모이면 종종 가십성으로 검찰 드라마를 화제에 올린다’고 말했다.\"라는 내용이 있습니다. \n",
      "\n",
      "이는 검사들이 자신들의 직업에 대해 더 깊이 이해하고 공감할 수 있는 드라마를 선호할 수 있음을 시사합니다. \n",
      "\n",
      "하지만 특정 방송국이나 드라마를 선호하는 이유에 대해서는 명확히 언급되지 않았습니다. \n",
      "\n",
      "따라서 검찰 내부에서 가장 선호하는 방송국이나 드라마를 정확히 말하기는 어렵습니다. \n",
      "\n",
      "검사들이 선호하는 드라마의 선택 기준에 대해서는 개인의 취향, 가치관, 드라마의 내용 등 다양한 요인이 복합적으로 작용할 것으로 추측할 수 있겠습니다. \n",
      "\n",
      "더 구체적인 정보가 필요하다면 직접 검찰 관계자나 관련 전문가에게 조사를 해볼 필요가 있을 것 같습니다.\n",
      "    label:\n",
      "\n",
      "검찰 내부에서 더 선호하는 검사 드라마를 방영하는 방송국은 MBC입니다. MBC의 드라마 '오만과 편견'이 검찰 내부에서 더 긍정적인 평가를 받고 있습니다. 이는 '펀치'가 검찰을 부정적으로 그리는 대목이 많은 반면, '오만과 편견'은 범죄와 치열하게 싸우는 비교적 긍정적인 모습을 보여주기 때문입니다. 검사들 사이에서는 '펀치'가 검찰에 대한 부정적인 사건을 짜깁기해 만든 것 같다는 의견이 있으며, '오만과 편견'은 현실과 동떨어진 느낌이 덜하다는 평가를 받고 있습니다 [[ref2]].\n",
      "--------------------------------------------------\n",
      "    response:\n",
      "중미 6개국(파나마, 코스타리카, 과테말라, 온두라스, 엘살바도르, 도미니카공화국)과 에콰도르, 멕시코, 메르코수르(아르헨티나, 브라질, 파라과이, 우루과이, 베네수엘라) 총 9개국이 포함됩니다.\n",
      "\n",
      "참고문서:\n",
      "- \"정부가 차기 FTA 대상으로 상정한 곳은 중미 6개국 경제공동체인 SIECA 소속 국가들과 에콰도르... 등이다.\"\n",
      "- \"현재 FTA 체결과 관련해 한국과 공동 연구를 마친 국가는 파나마 코스타리카 과테말라 온두라스 엘살바도르 도미니카공화국과 메르코수르 회원국이다.\"\n",
      "- \"SICA는 파나마 코스타리카 엘살바도르 과테말라 니카라과 도미니카공화국 벨리즈 온두라스 등 중앙아메리카 8개 국가가 참여하는 경제기구이며, SIECA는 SICA 참여국 가운데 도미니카공화국과 벨리즈 등 2개를 제외한 6개 국가가 회원이다.\"\n",
      "- \"메르코수르는 아르헨티나 브라질 파라과이 우루과이 베네수엘라 등 4개국이 포함된 경제 공동체다.\" \n",
      "\n",
      "따라서 FTA 협상 계획에 포함된 국가들을 대륙별로 정리하면 다음과 같습니다:\n",
      "- 북아메리카: 멕시코\n",
      "- 중앙아메리카: 파나마, 코스타리카, 과테말라, 온두라스, 엘살바도르, 도미니카공화국\n",
      "- 남아메리카: 아르헨티나, 브라질, 파라과이, 우루과이, 베네수엘라\n",
      "- 에콰도르 (남아메리카와 북아메리카 경계 지역에 위치)\n",
      "    label:\n",
      "\n",
      "6월에 정부와 FTA 논의를 계획 중인 국가들이 포함된 대륙은 주로 중미와 남미입니다. 구체적으로, 한국 정부는 중미경제통합상설사무국(SIECA) 소속 6개국(과테말라, 엘살바도르, 온두라스, 니카라과, 코스타리카, 파나마)과 에콰도르와의 FTA 협상을 6월 중 공식 선언할 계획입니다. 이들 국가들은 모두 중미와 남미에 위치해 있습니다 [[ref1]].\n",
      "--------------------------------------------------\n",
      "    response:\n",
      "작년 3분기에 삼성전자는 사상 최대인 10조1600억원의 영업이익을 기록했습니다. 이는 회사의 분기 영업이익 기록상 최고치였습니다.\n",
      "\n",
      "출처:\n",
      "1. 문서1: \"삼성전자는 2013년 3분기에 사상 최대인 10조2000억원의 영업이익을 냈다.\"\n",
      "2. 문서4: \"작년 3분기에 분기 기준 사상 최대인 10조1600억원의 영업이익을 올린 점에 비춰...\"\n",
      "\n",
      "따라서 질문에 대한 답변은 다음과 같습니다:\n",
      "\"삼성전자의 작년 3분기 영업이익은 10조1600억원입니다.\"\n",
      "    label:\n",
      "\n",
      "삼성전자의 작년 3분기 영업이익은 10조1600억원이었습니다. 이는 삼성전자가 사상 처음으로 10조원을 넘는 영업이익을 기록한 분기였습니다 [[ref2]].\n",
      "--------------------------------------------------\n",
      "    response:\n",
      "검색 결과에 따르면 임영록 KB금융지주 회장과 임종룡 농협금융지주 회장의 나이에 대한 정보는 명시되어 있지 않습니다. \n",
      "\n",
      "임영록 회장의 출신과 경력에 대해 언급된 문서에서는 그의 나이를 직접적으로 언급하지 않았습니다.\n",
      " \n",
      "임종룡 회장 역시 그의 이력과 경력에 대해 설명된 문서에서는 나이에 대한 정보가 제공되지 않았습니다.\n",
      "\n",
      "따라서 현재 제공된 정보만으로는 두 회장의 나이를 정확히 알 수 없습니다. 추가적인 검색이나 직접적인 언급이 필요한 것 같습니다.\n",
      "    label:\n",
      "\n",
      "KB금융지주와 농협금융지주의 회장 중 행정고시에 먼저 합격한 사람은 임영록 KB금융지주 회장입니다. 임영록 회장은 제20회 행정고시에 합격했으며, 임종룡 농협금융지주 회장은 제24회 행정고시에 합격했습니다. 따라서 임영록 회장이 행정고시에 먼저 합격했습니다. \n",
      "\n",
      "임영록 회장은 58세, 임종룡 회장은 54세로, 임영록 회장이 더 나이가 많습니다 [[ref2]].\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for prompt, label in zip(prompt_lst[700:705], label_lst[700:705]):\n",
    "    # print(f\"    prompt:\\n{prompt}\")\n",
    "    print(f\"    response:\\n{test_inference(pipe, prompt)}\")\n",
    "    print(f\"    label:\\n{label}\")\n",
    "    print(\"-\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
