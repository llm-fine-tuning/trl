{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e948789d-5b0f-48a1-a5d3-0e35c8056f48",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "62ce3870e58c4f259b9334cb638b9a2b"
          ]
        },
        "id": "e948789d-5b0f-48a1-a5d3-0e35c8056f48",
        "outputId": "d523083b-34ef-4646-d257-419e81b6d35f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading base model from: NCSOFT/Llama-VARCO-8B-Instruct\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "62ce3870e58c4f259b9334cb638b9a2b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading and merging PEFT from: llama-3-8b-persona-chatbot/checkpoint-279\n",
            "Saving merged model to: llama-3-8b-persona-chatbot/merged\n",
            "✅ 모델과 토크나이저 저장 완료\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from peft import PeftModel\n",
        "\n",
        "# 경로 설정\n",
        "base_model_path = \"NCSOFT/Llama-VARCO-8B-Instruct\"\n",
        "adapter_path = \"llama-3-8b-persona-chatbot/checkpoint-279\"\n",
        "merged_model_path = \"llama-3-8b-persona-chatbot/merged\"\n",
        "\n",
        "# 디바이스 설정\n",
        "device_arg = {\"device_map\": \"auto\"}\n",
        "\n",
        "# 베이스 모델 로드\n",
        "print(f\"Loading base model from: {base_model_path}\")\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model_path,\n",
        "    return_dict=True,\n",
        "    torch_dtype=torch.float16,\n",
        "    **device_arg\n",
        ")\n",
        "\n",
        "# LoRA 어댑터 로드 및 병합\n",
        "print(f\"Loading and merging PEFT from: {adapter_path}\")\n",
        "model = PeftModel.from_pretrained(base_model, adapter_path, **device_arg)\n",
        "model = model.merge_and_unload()\n",
        "\n",
        "# 토크나이저 로드\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model_path)\n",
        "\n",
        "# 저장\n",
        "print(f\"Saving merged model to: {merged_model_path}\")\n",
        "model.save_pretrained(merged_model_path)\n",
        "tokenizer.save_pretrained(merged_model_path)\n",
        "print(\"✅ 모델과 토크나이저 저장 완료\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88b44472-24fd-467a-8616-cfa1a9c7f16e",
      "metadata": {
        "id": "88b44472-24fd-467a-8616-cfa1a9c7f16e"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import HfApi\n",
        "api = HfApi()\n",
        "\n",
        "username = \"iamjoon\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5363b9ad-dbff-4917-9bd1-709cc0976726",
      "metadata": {
        "id": "5363b9ad-dbff-4917-9bd1-709cc0976726"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = 'llama3-8b-persona-chatbot'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1a48ddf-e096-47fa-aaf7-8a8db1baf450",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "da1455cb5e1e4f37aca85c84bb2565a4",
            "313334b28e7e41b59b3a53d10b195643",
            "74223f56ac2b48f9b78be4a950f9920d",
            "bb482b47b7ff40f4a7fc4486c0bd6707",
            "c16d2e8e70fc47549fb7d25b3cde35de",
            "d41e40b454564c258533df2200ec453d"
          ]
        },
        "id": "f1a48ddf-e096-47fa-aaf7-8a8db1baf450",
        "outputId": "a526ed10-e7ca-4826-e81a-9203c5d613b9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "da1455cb5e1e4f37aca85c84bb2565a4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "313334b28e7e41b59b3a53d10b195643",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "74223f56ac2b48f9b78be4a950f9920d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Upload 5 LFS files:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb482b47b7ff40f4a7fc4486c0bd6707",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c16d2e8e70fc47549fb7d25b3cde35de",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d41e40b454564c258533df2200ec453d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/iamjoon/llama3-8b-persona-chatbot/commit/2d6b6eeff3c5d607392f5368d8efab09729d6800', commit_message='Upload folder using huggingface_hub', commit_description='', oid='2d6b6eeff3c5d607392f5368d8efab09729d6800', pr_url=None, repo_url=RepoUrl('https://huggingface.co/iamjoon/llama3-8b-persona-chatbot', endpoint='https://huggingface.co', repo_type='model', repo_id='iamjoon/llama3-8b-persona-chatbot'), pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "api.create_repo(\n",
        "    token=\"hf_허깅페이스 키 값\",\n",
        "    repo_id=f\"{username}/{MODEL_NAME}\",\n",
        "    repo_type=\"model\"\n",
        ")\n",
        "\n",
        "api.upload_folder(\n",
        "    token=\"hf_허깅페이스 키 값\",\n",
        "    repo_id=f\"{username}/{MODEL_NAME}\",\n",
        "    folder_path=\"llama-3-8b-persona-chatbot/merged\",\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}